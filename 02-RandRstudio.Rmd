
# (PART) Programming in R {-} 

# First Steps
***

## Why R

We focus on R because it is good for complex stats, concise figures, and coherent organization. It is built and developed by applied statisticians for statistics, and used by many in academia and industry. For students, think about labor demand and what may be good for getting a job. Do some of your own research to best understand how much to invest.

## Install R

First Install [R](https://cloud.r-project.org/).
Then Install [Rstudio](https://www.rstudio.com/products/rstudio/download/).

For help setting up

* https://learnr-examples.shinyapps.io/ex-setup-r/
* https://rstudio-education.github.io/hopr/starting.html
* https://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/installr.html
* https://cran.r-project.org/doc/manuals/R-admin.html

* https://courses.edx.org/courses/UTAustinX/UT.7.01x/3T2014/56c5437b88fa43cf828bff5371c6a924/
* https://owi.usgs.gov/R/training-curriculum/installr/
* https://www.earthdatascience.org/courses/earth-analytics/document-your-science/setup-r-rstudio/


Make sure you have the latest version of R and Rstudio for class. If not, then reinstall. 

## Interfacing with R

Rstudio is easiest to get going with. (There are other GUI's.) There are 4 panes. The top left is where you write and save code

 * Create and save a new `R Script` file *My_First_Script.R*
 * could also use a plain .txt file.

```{r, echo=FALSE}
knitr::include_graphics("./Figures_Manual/Rstudio.svg")
```

The pane below is where your code is executed. For all following examples, make sure to both execute and store your code.


Note that the coded examples generally have inputs, outputs, and comments. For example, 
```{r, eval=TRUE, echo=TRUE}
## This is a comment
CodeInput <- c('output looks like this')
CodeInput
```


# Mathematics
***


## Scalars

```{r}
xs <- 2 ## Your first scalar
xs  ## Print the scalar

(xs+1)^2 ## Perform and print a simple calculation
xs + NA ## often used for missing values
xs*2
```

## Vectors
 
```{r}
x <- c(0,1,3,10,6) ## Your First Vector
x ## Print the vector
x[2] ## Print the 2nd Element; 1
x+2 ## Print simple calculation; 2,3,5,8,12
x*2
x^2
```


```{r}
x+x
x*x
x^x
```

```{r}
c(1) ## scalars are vectors

1:7
seq(0,1,by=.1)
```


##  Functions

Function of a vector
```{r}
## Add two to any vector
add2 <- function(x1) {
    x1+2
}
add2(x)

## Generalization
addn <- function(x1,n=2) {
    x1+n
}
addn(x)
addn(x,3)
```



Function for two vectors
```{r}
sum_squared <- function(x1, x2) {
	y <- (x1 + x2)^2
	return(y)
}

sum_squared(1, 3)
sum_squared(x, 2)
sum_squared(x, NA) 
sum_squared(x, x)
sum_squared(x, 2*x)
```

Applying the same function over and over again
```{r}
sapply(1:3, exp)
exp(1:3)

## mapply takes multiple vectors
mapply(sum, 1:3, exp(1:3) )
```

recursive functions
```{r}
## For Loop
x <- rep(1, 3)
for(i in 2:length(x) ){
    x[i] <- (x[i-1]+1)^2
}
x

r_fun <- function(n){
    x <- rep(1,n)
    for(i in 2:length(x) ){
        x[i] <- (x[i-1]+1)^2
    }
    return(x)
}
r_fun(5)
```

Functions can take functions as arguments 
```{r}
fun_of_seq <- function(f){
    x <- seq(1,3, length.out=12)
    y <- f(x)
    return(y)
}

fun_of_seq(mean)

fun_of_seq(mean)
```



##  Matrices

```{r}
x1 <- c(1,4,9)
x2 <- c(3,0,2)
x_mat <- rbind(x1, x2)

x_mat       ## Print full matrix
x_mat[2,]   ## Print Second Row
x_mat[,2]   ## Print Second Column
x_mat[2,2]  ## Print Element in Second Column and Second Row

## 
x_mat+2
x_mat*2
x_mat^2

x_mat + x_mat
x_mat*x_mat
x_mat^x_mat
```


```{r}
y <- apply(x_mat, 1, sum)^2 ## Apply function to each row
## ?apply  #checks the function details
y - sum_squared(x, x) ## tests if there are any differences
```

Many Other Functions
```{r}
x_mat1 <- matrix(2:7,2,3)
x_mat1

x_mat2 <- matrix(4:-1,2,3)
x_mat2

##
x_mat1 * x_mat2

tcrossprod(x_mat1, x_mat2) ##x_mat1 %*% t(x_mat2)

crossprod(x_mat1, x_mat2)
```


Example Calculations

```{r}
## Return Y-value with minimum absolute difference from 3
abs_diff_y <- abs( y - 3 ) 
abs_diff_y ## is this the luckiest number?

min(abs_diff_y)
which.min(abs_diff_y)
y[ which.min(abs_diff_y) ]
```



## Arrays

Generalization of matrices used in spatial econometrics

```{r}
a <- array(data = 1:24, dim = c(2, 3, 4))
a

a[1, , , drop = FALSE]  # Row 1
a[, 1, , drop = FALSE]  # Column 1
a[, , 1, drop = FALSE]  # Layer 1

a[ 1, 1,  ]  # Row 1, column 1
a[ 1,  , 1]  # Row 1, "layer" 1
a[  , 1, 1]  # Column 1, "layer" 1
a[1 , 1, 1]  # Row 1, column 1, "layer" 1
```

Apply extends to arrays
```{r}
apply(a, 1, mean)    # Row means
apply(a, 2, mean)    # Column means
apply(a, 3, mean)    # "Layer" means
apply(a, 1:2, mean)  # Row/Column combination 
```


Outer Products yield arrays
```{r}
x <- c(1,2,3)
x_mat1 <- outer(x, x) ## x %o% x
x_mat1
is.array(x_mat) ## Matrices are arrays


x_mat2 <- matrix(6:1,2,3)
outer(x_mat2, x)
## outer(x_mat2, matrix(x))
## outer(x_mat2, t(x))
## outer(x_mat1, x_mat2)
```

# Statistics

## Data Types

The most commom types are
```{r}
l1 <- 1:3 ## cardinal numbers
l1

l2 <- factor(c('A','B','C'), ordered=T) ## ordinal numbers
l2

l3 <- factor(c('Leipzig','Los Angeles','Logan'), ordered=F) ## categorical numbers
l3

l4 <- c('hello world', 'hi mom')  ## character strings
l4

l5 <- list(l1, l2, list(l3, list('...inception...'))) ## lists
l5

## data.frames: your most common data type
    ## matrix of different data-types
    ## well-ordered lists
l5 <- data.frame(x=l1, y=l2, z=l3)
l5
```


## Random Variables

The different types of data can be randomly generated on your computer. Random variables are vectors that appear to be generated from a probabilistic process.

```{r}
## Random bernoulli (Coin Flip: Heads=1)
rbinom(1, 1, 0.5) ## 1 Flip
rbinom(4, 1, 0.5) ## 4 Flips in row
x0 <- rbinom(1000, 1, 0.5)
hist(x0)

## random standard-normal
rnorm(4) 
x1 <- rnorm(1000)
hist(x1)

## random uniform
runif(4)
x2 <- runif(1000)
hist(x2)
```


## Functions of Data

Two definitions to remember

* *statistic* a function of data
* *sampling distribution* how a statistic varies from sample to sample

The mean is a statistic
```{r}
## compute the mean of a random sample
x <- runif(100)
hist(x)
m <- mean(x)
abline(v=m, col=2)

## is m close to it's true value (1-0)/2=.5?
## what about mean(runif(1000)) ?
## what about mean( rbinom(100, 1, 0.5) )?
```

see how the mean varies from sample to sample to sample
```{r}
par(mfrow=c(1,3))
sapply(1:3, function(i){
    x <- runif(100) 
    m <-  mean(x)
    hist(x,
        main=paste0('mean= ', round(m,4)),
        breaks=seq(0,1,by=.1))
    abline(v=m, col=2)
    return(m)
})
```

examine the sampling distribution of the mean
```{r}
sample_means <- sapply(1:1000, function(i) mean(runif(100)) )
hist(sample_means, breaks=50, col=2, main='Sampling Distribution of the mean')
```

examine the sampling distribution of the standard deviation
```{r}
three_sds <- c(  sd(runif(100)),  sd(runif(100)),  sd(runif(100))  )
three_sds

sample_sds <- sapply(1:1000, function(i) sd(runif(100)) )
hist(sample_sds, breaks=50, col=4, main='Sampling Distribution of the sd')
```

examine the sampling distribution of "order statistics"
```{r}
## Create 300 samples, each with 1000 random uniform variables
x <- sapply(1:300, function(i) runif(1000) )

## Median also looks normal
xmed <- apply(x,1,quantile, probs=.5)
hist(xmed,breaks=100)

## Maximum and Minumum do not!
xmin <- apply(x,1,quantile, probs=0)
xmax <- apply(x,1,quantile, probs=1)
par(mfrow=c(1,2))
hist(xmin,breaks=100)
hist(xmax,breaks=100)


## Upper and Lower Quantiles
xq <- apply(x,1,quantile, probs=c(.05,.95))
bks <- seq(0,1,by=.01)
hist(xq[1,], main='quantile estimates', col=rgb(0,0,1,.5), xlim=c(0,1), breaks=bks)
hist(xq[2,], col=rgb(1,0,0,.5), add=T, breaks=seq(0,1,by=.01))

## Coverage
xcov <- sapply(bks, function(b){
    bl <- b >= xq[1,]
    bu <- b <= xq[2,]
    mean( bl&bu )
})
plot.new()
plot.window(xlim=c(0,1), ylim=c(0,1))
polygon( c(bks, rev(bks)), c(xcov, xcov*0), col=grey(.5,.5), border=NA)
title('coverage frequency')
axis(1)
axis(2)
```


```{r}
## Try any function!
fun_of_rv <- function(f, n=100){
  x <- runif(n)
  y <- f(x)
  return(y)
}
fun_of_rv( function(i){range(exp(i))})
```



## Value of More Data

Each additional data point you have provides more information, which ultimately decreases the standard error of your estimates. However, it does so at a decreasing rate (known in economics as diminishing marginal returns).

```{r}
Nseq <- seq(1,100, by=1) ## Sample sizes
B <- 1000 ## Number of draws per sample

SE <- sapply(Nseq, function(n){
    sample_statistics <- sapply(1:B, function(b){
        x <- rnorm(n) ## Sample of size N
        quantile(x,probs=.4) ## Statistic
    })
    sd(sample_statistics)
})

par(mfrow=c(1,2))
plot(Nseq, SE, pch=16, col=grey(0,.5), main='Absolute Gain',
    ylab='standard error', xlab='sample size')
plot(Nseq[-1], abs(diff(SE)), pch=16, col=grey(0,.5), main='Marginal Gain', 
    ylab='decrease in standard error', xlab='sample size')
```


## Further Reading

Many introductory econometrics textbooks have a good appendix on probability and statistics. There are many useful texts online too

* https://bookdown.org/probability/statistics/
* https://bookdown.org/probability/beta/
* https://bookdown.org/a_shaker/STM1001_Topic_3/
* https://bookdown.org/fsancier/bookdown-demo/
* https://bookdown.org/kevin_davisross/probsim-book/
* https://bookdown.org/machar1991/ITER/2-pt.html




# Data Analysis
***


Reading in

```{r, eval=FALSE}
## Install R Data Package and Load in
install.packages('wooldridge')
library(wooldridge)
data('crime2')
data('crime4')

## Read in csv from online
dat_csv <- read.csv('http://www.stern.nyu.edu/~wgreene/Text/Edition7/TableF19-3.csv')
dat_csv <- as.data.frame(dat_csv)

## Read in csv from online
dat_stata <- haven::read_dta('https://www.ssc.wisc.edu/~bhansen/econometrics/DS2004.dta')
dat_stata <- as.data.frame(dat_stata)

## For More Introductory Econometrics Data, see 
# https://www.ssc.wisc.edu/~bhansen/econometrics/Econometrics%20Data.zip
# https://pages.stern.nyu.edu/~wgreene/Text/Edition7/tablelist8new.htm
# R packages: wooldridge, causaldata, Ecdat, AER, ....
```


Read in some historical data on crime in the US
```{r}
head(USArrests)
```

```{r}
summary(USArrests)
```



## Cleaning Data

Data transformation is often necessary before analysis, so remember to be careful and check your code is doing what you want. (If you have large datasets, you can always test out the code on a sample.)

```{r}
## Function to Create Sample Datasets
make_noisy_data <- function(n, b=0){
    ## Simple Data Generating Process
    x <- seq(1,10, length.out=n) 
    e <- rnorm(length(x), mean=0, sd=10)
    y <- b*x + e 
    ## Obervations
    xy_mat <- data.frame(ID=seq(x), x=x, y=y)
    return(xy_mat)
}

## Two simulated datasets
dat1 <- make_noisy_data(6)
dat2 <- make_noisy_data(6)

## Merging data in long format
dat_merged_long <- rbind( cbind(dat1,DF=1), cbind(dat2,DF=2))
```
Now suppose we want to transform into long format
```{r}
## Merging data in wide format, First Attempt
dat_merged_wide <- cbind( dat1, dat2)
names(dat_merged_wide) <- c(paste0(names(dat1),'.1'), paste0(names(dat2),'.2'))

## Merging data in wide format, Second Attempt
## higher performance
dat_merged_wide2 <- merge(dat1, dat2,
    by='ID', suffixes=c('.1','.2'))
## CHECK they are the same.
identical(dat_merged_wide, dat_merged_wide2)

## Merging data in wide format, Third Attempt
## more flexibility
dat_melted <- reshape2::melt(dat_merged_long, id.vars=c('ID', 'DF'))
dat_merged_wide3 <- reshape2::dcast(dat_melted, ID~DF+variable)

## Merging data in wide format, Fourth Attempt
## highest performance but with new type of object
library(data.table)
dat_merged_longDT <- as.data.table(dat_merged_long)
dat_melted <- data.table::melt(dat_merged_longDT, id.vars=c('ID', 'DF'))
dat_merged_wide4 <- data.table::dcast(dat_melted, ID~DF+variable)
## dat_merged_wide4 <- as.data.frame(dat_merged_wide4)

## CHECK they are the same.
identical(dat_merged_wide3, dat_merged_wide4)
```
Often, however, we ultimately want data in long format
```{r}
## Merging data in long format, Second Attempt 
dat_melted2 <- data.table::melt(dat_merged_wide4, measure=c("1_x","1_y","2_x","2_y"))
melt_vars <- strsplit(as.character(dat_melted2$variable),'_')
dat_melted2$DF <- sapply(melt_vars, `[[`,1)
dat_melted2$variable <- sapply(melt_vars, `[[`,2)
dat_merged_long2 <- data.table::dcast(dat_melted2, DF+ID~variable)
dat_merged_long2 <- as.data.frame(dat_merged_long2)

## CHECK they are the same.
identical( dat_merged_long2, dat_merged_long)

## Further Inspect
dat_merged_long2 <- dat_merged_long2[,c('ID','x','y','DF')]
mapply( identical, dat_merged_long2, dat_merged_long)
```

For more tips, see https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf and https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html
<!--\url{https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf}-->


## Static Plots

### Histograms 

Histograms Summarize Distributions. Easy to show data splits. Can glue together to convey more information all at once

```{r}
par(mfrow=c(1,2))

## All Data
xbks <-  seq(min(USArrests$Murder), max(USArrests$Murder), length.out=10)
hist(USArrests$Murder, main='All Data', xlab='Murder Arrests',  breaks=xbks)

## Split Data by Urban Population above/below mean
u <- mean(USArrests$UrbanPop)
m1 <- USArrests[USArrests$UrbanPop<u,'Murder']
m2 <- USArrests[USArrests$UrbanPop>=u,'Murder']
cols <- c(rgb(0,0,1,.5), rgb(1,0,0,.5))
hist(m1, col=cols[1], breaks=xbks, xlab='Murder Arrests', main='Split Data')
hist(m2, add=T, col=cols[2], breaks=xbks)
legend('topright', col=cols, pch=15, bty='n',
    title='% Urban Pop.', legend=c('Above Mean', 'Below Mean'))
```

Sometimes it is better to make separate figures for each data split
```{r}
par(fig=c(0,1,0,0.5), new=F)
hist(USArrests$Murder, breaks=xbks, main='All Data', xlab='Murder Arrests')
par(fig=c(0,.5,0.5,1), new=TRUE)
hist(m1, breaks=xbks, col=rgb(0,0,1,.5),
    main='Urban Pop >= Mean', xlab='Murder Arrests')
par(fig=c(0.5,1,0.5,1), new=TRUE)
hist(m2,breaks=xbks, col=rgb(1,0,0,.5),
    main='Urban Pop < Mean', xlab='Murder Arrests')
```

For more histogram visuals, see https://r-graph-gallery.com/histogram.html


### Boxplots

Boxplots show median, interquartile range, and outliers. As with histograms, you can also split data into groups and glue together
```{r}
layout( t(c(1,2,2)))
boxplot(USArrests$Murder, main='',
    xlab='All Data', ylab='Murder Arrests')

## 3 Groups with even spacing
USArrests$UrbanPop_cut <- cut(USArrests$UrbanPop,3)
boxplot(Murder~UrbanPop_cut, USArrests,
    main='', col=hcl.colors(3,alpha=.5),
    xlab='Urban Population', ylab='')
    
## 4 Groups with equal observations
#qcuts <- c(
#    '0%'=min(USArrests$UrbanPop)-10*.Machine$double.eps,
#    quantile(USArrests$UrbanPop, probs=c(.25,.5,.75,1)))
#USArrests$UrbanPop_cut <- cut(USArrests$UrbanPop, qcuts)
```

### Scatterplots

Scatterplots are used frequently to summarize the relationship between two variables. They can be enhanced in several ways.


**Fit Lines and Color** You can add regression lines (and confidence intervals). As a default, use semi-transparent points to see where your observations are concentrated. You can also use color to distinguish subsets.

```{r}

## High Assault Areas
cols <- ifelse(USArrests$Assault>median(USArrests$Assault), rgb(1,0,0,.5), rgb(0,0,1,.5))

## Scatterplot
plot(Murder~UrbanPop, USArrests, pch=16, col=cols)

## Add the line of best fit for pooled data
## Could also do separately for each data split
reg <- lm(Murder~UrbanPop, data=USArrests)
abline(reg, lty=2)

## Can Also Add Confidence Intervals
## https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals
```


Your first plot is typically standard. For others to easily comprehend your work, you must polish the plot.
```{r}
## Data Generating Process
x <- seq(1, 10, by=.0002)
e <- rnorm(length(x), mean=0, sd=1)
y <- .25*x + e 
xy_dat <- data.frame(x=x, y=y)

## Plot
par(fig=c(0,1,0,0.9), new=F)
plot(y~x, xy_dat, pch=16, col=rgb(0,0,0,.05), cex=.5,
    xlab='', ylab='') ## Format Axis Labels Seperately
mtext( 'y=0.25 x + e\n e ~ standard-normal', 2, line=2.2)
mtext( expression(x%in%~'[0,10]'), 1, line=2.2)

abline( lm(y~x, data=xy_dat), lty=2)

title('Plot with good features and excessive notation', adj=0)

## Outer Legend (https://stackoverflow.com/questions/3932038/)
outer_legend <- function(...) {
  opar <- par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), 
    mar=c(0, 0, 0, 0), new=TRUE)
  on.exit(par(opar))
  plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')
  legend(...)
}
outer_legend('topright', legend='single data point',
    title='do you see the normal distribution?',
    pch=16, col=rgb(0,0,0,.1), cex=1, bty='n')
```


Can export figure with specific dimensions
```{r, eval=FALSE}
pdf( 'Figures/plot_example.pdf', height=5, width=5)
## plot goes here
dev.off()
```

For plotting math, see
https://astrostatistics.psu.edu/su07/R/html/grDevices/html/plotmath.html
https://library.virginia.edu/data/articles/mathematical-annotation-in-r

For exporting options, see `?pdf`.
For saving other types of files, see `png("*.png")`, `tiff("*.tiff")`, and  `jpeg("*.jpg")`



**Marginal distributions**

```{r}
par(fig=c(0,0.8,0,0.8), new=F)
plot(Murder~UrbanPop, USArrests, pch=16, col=rgb(0,0,0,.5))
par(fig=c(0,0.8,0.55,1), new=TRUE)
boxplot(USArrests$Murder, horizontal=TRUE, axes=FALSE)
par(fig=c(0.65,1,0,0.8),new=TRUE)
boxplot(USArrests$UrbanPop, axes=FALSE)
```

```{r}
## https://www.r-bloggers.com/2011/06/example-8-41-scatterplot-with-marginal-histograms/

## Setup Plot
layout( matrix(c(2,0,1,3), ncol=2, byrow=TRUE),
    widths=c(4/5,1/5), heights=c(1/5,4/5))

## Scatterplot
par(mar=c(4,4,1,1))
plot(Murder~UrbanPop, USArrests, pch=16, col=rgb(0,0,0,.5))

## Add Marginals
par(mar=c(0,4,1,1))
xhist <- hist(USArrests$UrbanPop, plot=FALSE)
barplot(xhist$counts, axes=FALSE, space=0)

par(mar=c(4,0,1,1))
yhist <- hist(USArrests$Murder, plot=FALSE)
barplot(yhist$counts, axes=FALSE, space=0, horiz=TRUE)
```

For plotting marginals, see https://r-graph-gallery.com/74-margin-and-oma-cheatsheet.html and https://jtr13.github.io/cc21fall2/tutorial-for-scatter-plot-with-marginal-distribution.html


## Interactive Plots


Especially for data exploration, your plots can also be [interactive](https://r-graph-gallery.com/interactive-charts.html) via https://plotly.com/r/. For more details, see https://plotly-r.com/

```{r, message=FALSE, warning=FALSE}
#install.packages("plotly")
library(plotly)
```


**Histograms**  https://plotly.com/r/histograms/
```{r, message=FALSE, warning=FALSE}
u <- mean(USArrests$UrbanPop)
m1 <- USArrests[USArrests$UrbanPop<u,'Murder']
m2 <- USArrests[USArrests$UrbanPop>=u,'Murder']

fig <- plot_ly(alpha=0.6, 
    hovertemplate="%{y}")
fig <- fig %>% add_histogram(m1, name='< Mean')
fig <- fig %>% add_histogram(m2, name='>= Mean')
fig <- fig %>% layout(barmode="stack") ## barmode="overlay"
fig <- fig %>% layout(
    title="Crime and Urbanization in America 1975",
    xaxis = list(title='Murders Arrests per 100,000 People'),
    yaxis = list(title='Number of States'),
    legend=list(title=list(text='<b> Urban Pop. </b>'))
)
fig
```

**Boxplots** https://plotly.com/r/box-plots/
```{r, message=FALSE, warning=FALSE}
USArrests$ID <- rownames(USArrests)
fig <- plot_ly(USArrests, y=~Murder, color=~cut(UrbanPop,4),
    alpha=0.6, type="box",
    pointpos=0, boxpoints = 'all',
    hoverinfo='text',    
    text = ~paste('<b>', ID, '</b>',
        "<br>Urban  :", UrbanPop,
        "<br>Assault:", Assault,
        "<br>Murder :", Murder))    
fig <- plotly::layout(fig,
    showlegend=FALSE,
    title='Crime and Urbanization in America 1975',
    xaxis = list(title = 'Percent of People in an Urban Area'),
    yaxis = list(title = 'Murders Arrests per 100,000 People'))
fig
```

**Scatterplots**  https://plotly.com/r/bubble-charts/

```{r, message=FALSE, warning=FALSE}
## Simple Scatter Plot
#plot(Assault~UrbanPop, USArrests, col=grey(0,.5), pch=16,
#    cex=USArrests$Murder/diff(range(USArrests$Murder))*2,
#    main='US Murder arrests (per 100,000)')

# Scatter Plot
USArrests$ID <- rownames(USArrests)
fig <- plotly::plot_ly(
    USArrests, x = ~UrbanPop, y = ~Assault,
    mode='markers',
    type='scatter',
    hoverinfo='text',
    text = ~paste('<b>', ID, '</b>',
        "<br>Urban  :", UrbanPop,
        "<br>Assault:", Assault,
        "<br>Murder :", Murder),
    color=~Murder,
    marker=list(
        size=~Murder,
        opacity=0.5,
        showscale=T,  
        colorbar = list(title='Murder Arrests (per 100,000)')))
fig <- plotly::layout(fig,
    showlegend=F,
    title='Crime and Urbanization in America 1975',
    xaxis = list(title = 'Percent of People in an Urban Area'),
    yaxis = list(title = 'Assault Arrests per 100,000 People'))
fig
```

# Beyond Basics
***


## The R Ecosystem

Use expansion "packages" for common procedures and more functionality

### Packages

**CRAN**
Most packages can be found on CRAN and can be easily installed
```{r, eval=FALSE}
## commonly used packages
install.packages("stargazer")
install.packages("data.table")
## install.packages("purrr")
## install.packages("reshape2")
```

The most common tasks also have [cheatsheets](https://www.rstudio.com/resources/cheatsheets/) you can use. E.g., https://github.com/rstudio/cheatsheets/blob/main/rstudio-ide.pdf


**Github**
Sometimes you will want to install a package from GitHub. For this, you can use [devtools](https://devtools.r-lib.org/) or its light-weight version [remotes](https://remotes.r-lib.org/)
```{r, eval=FALSE}
install.packages("devtools")
install.packages("remotes")
```

Note that to install `devtools`, you also need to have developer tools installed on your computer.

* Windows: [Rtools](https://cran.r-project.org/bin/windows/Rtools/rtools42/rtools.html)
* Mac: [Xcode](https://apps.apple.com/us/app/xcode/id497799835?mt=12)

To color terminal output on Linux systems, you can use the colorout package
```{r, eval=FALSE}
library(remotes)
# Install https://github.com/jalvesaq/colorout
# to .libPaths()[1]
install_github('jalvesaq/colorout')
library(colorout)
```

**Base**
While additional packages can make your code faster, they also create dependancies that can lead to problems. So learn base R well before becoming dependant on other packages

* https://bitsofanalytics.org/posts/base-vs-tidy/
* https://jtr13.github.io/cc21fall2/comparison-among-base-r-tidyverse-and-datatable.html


### Task Views

Task views list relevant packages. 

For all students and early researchers, 

* https://cran.r-project.org/web/views/ReproducibleResearch.html

For microeconometrics,

* https://cran.r-project.org/web/views/Econometrics.html

For spatial econometrics 

* https://cran.r-project.org/web/views/Spatial.html
* https://cran.r-project.org/web/views/SpatioTemporal.html


Multiple packages may have the same function name for different commands. In this case use the syntax ``package::function`` to specify the package. For example
```{r, eval=FALSE}
devtools::install_github
remotes::install_github
```


**Don't fret** Sometimes there is not a specific package for your data.

Odds are, you can do most of what you want with base code.

* Packages just wrap base code in convient formats
* see https://cran.r-project.org/web/views/ for topical overviews

Statisticians might have different naming conventions

* if the usual software just spits out a nice plot
you might have to dig a little to know precisely what you want
* your data are fundamentally numbers, strings, etc...
You only have to figure out how to read it in.


## Introductions to R

There are many good yet free programming books online. Some of my examples originally come from https://r4ds.had.co.nz/ and I recommend https://intro2r.com. But I have used online material from many places over the years, including  

* https://cran.r-project.org/doc/manuals/R-intro.html
* R Graphics Cookbook, 2nd edition. Winston Chang. 2021. https://r-graphics.org/
* R for Data Science. H. Wickham and G. Grolemund. 2017. https://r4ds.had.co.nz/index.html
* An Introduction to R. W. N. Venables, D. M. Smith, R Core Team. 2017. https://colinfay.me/intro-to-r/
* Introduction to R for Econometrics. Kieran Marray. https://bookdown.org/kieranmarray/intro_to_r_for_econometrics/
* Wollschläger, D. (2020). Grundlagen der Datenanalyse mit R: eine anwendungsorientierte Einführung. http://www.dwoll.de/rexrepos/
* Spatial Data Science with R: Introduction to R. Robert J. Hijmans. 2021. https://rspatial.org/intr/index.html


What we cover in this primer should be enough to get you going. But there are also many good yet free-online tutorials and courses. 

* https://www.econometrics-with-r.org/1.2-a-very-short-introduction-to-r-and-rstudio.html
* https://rafalab.github.io/dsbook/
* https://moderndive.com/foreword.html
* https://rstudio.cloud/learn/primers/1.2
* https://cran.r-project.org/manuals.html
* https://stats.idre.ucla.edu/stat/data/intro_r/intro_r_interactive_flat.html
* https://cswr.nrhstat.org/app-r




## Custom Figures

Many of the best plots are custom made (see https://www.r-graph-gallery.com/). Here are some ones that I have made over the years.

<!-- ## CONVERT IMAGES
for pdfile in *.pdf ; do 
convert -verbose -density 500  "${pdfile}" "${pdfile%.*}".png;
done
-->


```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Vegetation.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Balances_Trial.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/PopulationDensity2.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/SampleExample.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/SemiInclusive_Example.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Stability_3.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/EvolutionaryDynamics.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Experiment_Timeline.png")
```

