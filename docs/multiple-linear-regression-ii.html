<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> 13 Multiple Linear Regression II | index</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content=" 13 Multiple Linear Regression II | index" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" 13 Multiple Linear Regression II | index" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-regression.html"/>
<link rel="next" href="observational-data.html"/>
<script src="libs/jquery-3.7.1/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/core-js-2.5.3/shim.min.js"></script>
<script src="libs/react-18.2.0/react.min.js"></script>
<script src="libs/react-18.2.0/react-dom.min.js"></script>
<script src="libs/reactwidget-2.0.0/react-tools.js"></script>
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="libs/reactable-0.4.4/reactable.css" rel="stylesheet" />
<script src="libs/reactable-binding-0.4.4/reactable.js"></script>
<script src="libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.6.9000/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.6.9000/profvis.js"></script>
<script src="libs/profvis-0.3.6.9000/scroll.js"></script>
<link href="libs/highlight-11.10.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-11.10.0/highlight.min.js"></script>
<script src="libs/profvis-binding-0.4.0/profvis.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Rbooks</a></li>
<li class="toc-logo"><a href="./"><img src="Figures_Manual/Logo.png" width="140" height="100"></a></li>        

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="part"><span><b>I Data Analysis in R</b></span></li>
<li class="chapter" data-level="2" data-path="first-steps.html"><a href="first-steps.html"><i class="fa fa-check"></i><b>2</b> First Steps</a>
<ul>
<li class="chapter" data-level="2.1" data-path="first-steps.html"><a href="first-steps.html#why-r"><i class="fa fa-check"></i><b>2.1</b> Why R</a></li>
<li class="chapter" data-level="2.2" data-path="first-steps.html"><a href="first-steps.html#install-r"><i class="fa fa-check"></i><b>2.2</b> Install R</a></li>
<li class="chapter" data-level="2.3" data-path="first-steps.html"><a href="first-steps.html#interfacing-with-r"><i class="fa fa-check"></i><b>2.3</b> Interfacing with R</a></li>
<li class="chapter" data-level="2.4" data-path="first-steps.html"><a href="first-steps.html#introductions-to-r"><i class="fa fa-check"></i><b>2.4</b> Introductions to R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mathematics.html"><a href="mathematics.html"><i class="fa fa-check"></i><b>3</b> Mathematics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mathematics.html"><a href="mathematics.html#scalars"><i class="fa fa-check"></i><b>3.1</b> Scalars</a></li>
<li class="chapter" data-level="3.2" data-path="mathematics.html"><a href="mathematics.html#vectors"><i class="fa fa-check"></i><b>3.2</b> Vectors</a></li>
<li class="chapter" data-level="3.3" data-path="mathematics.html"><a href="mathematics.html#functions"><i class="fa fa-check"></i><b>3.3</b> Functions</a></li>
<li class="chapter" data-level="3.4" data-path="mathematics.html"><a href="mathematics.html#loops"><i class="fa fa-check"></i><b>3.4</b> Loops</a></li>
<li class="chapter" data-level="3.5" data-path="mathematics.html"><a href="mathematics.html#logic"><i class="fa fa-check"></i><b>3.5</b> Logic</a></li>
<li class="chapter" data-level="3.6" data-path="mathematics.html"><a href="mathematics.html#matrices"><i class="fa fa-check"></i><b>3.6</b> Matrices</a></li>
<li class="chapter" data-level="3.7" data-path="mathematics.html"><a href="mathematics.html#arrays"><i class="fa fa-check"></i><b>3.7</b> Arrays</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data.html"><a href="data.html#types"><i class="fa fa-check"></i><b>4.1</b> Types</a></li>
<li class="chapter" data-level="4.2" data-path="data.html"><a href="data.html#empirical-distributions"><i class="fa fa-check"></i><b>4.2</b> Empirical Distributions</a></li>
<li class="chapter" data-level="4.3" data-path="data.html"><a href="data.html#joint-distributions"><i class="fa fa-check"></i><b>4.3</b> Joint Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="data.html"><a href="data.html#conditional-distributions"><i class="fa fa-check"></i><b>4.4</b> Conditional Distributions</a></li>
<li class="chapter" data-level="4.5" data-path="data.html"><a href="data.html#random-variables"><i class="fa fa-check"></i><b>4.5</b> Random Variables</a></li>
<li class="chapter" data-level="4.6" data-path="data.html"><a href="data.html#further-reading"><i class="fa fa-check"></i><b>4.6</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>5</b> Statistics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="statistics.html"><a href="statistics.html#mean-and-variance"><i class="fa fa-check"></i><b>5.1</b> Mean and Variance</a></li>
<li class="chapter" data-level="5.2" data-path="statistics.html"><a href="statistics.html#shape-statistics"><i class="fa fa-check"></i><b>5.2</b> Shape Statistics</a></li>
<li class="chapter" data-level="5.3" data-path="statistics.html"><a href="statistics.html#other-centerspread-statistics"><i class="fa fa-check"></i><b>5.3</b> Other Center/Spread Statistics</a></li>
<li class="chapter" data-level="5.4" data-path="statistics.html"><a href="statistics.html#associations"><i class="fa fa-check"></i><b>5.4</b> Associations</a></li>
<li class="chapter" data-level="5.5" data-path="statistics.html"><a href="statistics.html#beyond-basics"><i class="fa fa-check"></i><b>5.5</b> Beyond Basics</a></li>
<li class="chapter" data-level="5.6" data-path="statistics.html"><a href="statistics.html#further-reading-1"><i class="fa fa-check"></i><b>5.6</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>6</b> (Re)Sampling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="resampling.html"><a href="resampling.html#sample-distributions"><i class="fa fa-check"></i><b>6.1</b> Sample Distributions</a></li>
<li class="chapter" data-level="6.2" data-path="resampling.html"><a href="resampling.html#intervals"><i class="fa fa-check"></i><b>6.2</b> Intervals</a></li>
<li class="chapter" data-level="6.3" data-path="resampling.html"><a href="resampling.html#resampling-1"><i class="fa fa-check"></i><b>6.3</b> Resampling</a></li>
<li class="chapter" data-level="6.4" data-path="resampling.html"><a href="resampling.html#value-of-more-data"><i class="fa fa-check"></i><b>6.4</b> Value of More Data</a></li>
<li class="chapter" data-level="6.5" data-path="resampling.html"><a href="resampling.html#further-reading-2"><i class="fa fa-check"></i><b>6.5</b> Further Reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#basic-ideas"><i class="fa fa-check"></i><b>7.1</b> Basic Ideas</a></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#default-statistics"><i class="fa fa-check"></i><b>7.2</b> Default Statistics</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-tests.html"><a href="hypothesis-tests.html#two-sample-differences"><i class="fa fa-check"></i><b>7.3</b> Two-Sample Differences</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>8</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-analysis.html"><a href="data-analysis.html#reading-in"><i class="fa fa-check"></i><b>8.1</b> Reading In</a></li>
<li class="chapter" data-level="8.2" data-path="data-analysis.html"><a href="data-analysis.html#cleaning-data"><i class="fa fa-check"></i><b>8.2</b> Cleaning Data</a></li>
<li class="chapter" data-level="8.3" data-path="data-analysis.html"><a href="data-analysis.html#polishing"><i class="fa fa-check"></i><b>8.3</b> Polishing</a></li>
<li class="chapter" data-level="8.4" data-path="data-analysis.html"><a href="data-analysis.html#interactive"><i class="fa fa-check"></i><b>8.4</b> Interactive</a></li>
<li class="chapter" data-level="8.5" data-path="data-analysis.html"><a href="data-analysis.html#custom-figures"><i class="fa fa-check"></i><b>8.5</b> Custom Figures</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="reporting.html"><a href="reporting.html"><i class="fa fa-check"></i><b>9</b> Reporting</a>
<ul>
<li class="chapter" data-level="9.1" data-path="reporting.html"><a href="reporting.html#r-and-r-markdown"><i class="fa fa-check"></i><b>9.1</b> R and R-Markdown</a></li>
<li class="chapter" data-level="9.2" data-path="reporting.html"><a href="reporting.html#simple-reports"><i class="fa fa-check"></i><b>9.2</b> Simple Reports</a></li>
<li class="chapter" data-level="9.3" data-path="reporting.html"><a href="reporting.html#posters-and-slides"><i class="fa fa-check"></i><b>9.3</b> Posters and Slides</a></li>
<li class="chapter" data-level="9.4" data-path="reporting.html"><a href="reporting.html#more-literature"><i class="fa fa-check"></i><b>9.4</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>10</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="10.1" data-path="probability-theory.html"><a href="probability-theory.html#mean-and-variance-1"><i class="fa fa-check"></i><b>10.1</b> Mean and Variance</a></li>
<li class="chapter" data-level="10.2" data-path="probability-theory.html"><a href="probability-theory.html#bivariate-distributions"><i class="fa fa-check"></i><b>10.2</b> Bivariate Distributions</a></li>
<li class="chapter" data-level="10.3" data-path="probability-theory.html"><a href="probability-theory.html#further-reading-3"><i class="fa fa-check"></i><b>10.3</b> Further Reading</a></li>
</ul></li>
<li class="part"><span><b>II Linear Regression in R</b></span></li>
<li class="chapter" data-level="11" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#simple-linear-regression-1"><i class="fa fa-check"></i><b>11.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="11.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#variability-estimates"><i class="fa fa-check"></i><b>11.2</b> Variability Estimates</a></li>
<li class="chapter" data-level="11.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>11.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="11.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#local-linear-regression"><i class="fa fa-check"></i><b>11.4</b> Local Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>12</b> Multiple Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="multiple-regression.html"><a href="multiple-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="12.2" data-path="multiple-regression.html"><a href="multiple-regression.html#variability-and-hypothesis-tests"><i class="fa fa-check"></i><b>12.2</b> Variability and Hypothesis Tests</a></li>
<li class="chapter" data-level="12.3" data-path="multiple-regression.html"><a href="multiple-regression.html#factor-variables"><i class="fa fa-check"></i><b>12.3</b> Factor Variables</a></li>
<li class="chapter" data-level="12.4" data-path="multiple-regression.html"><a href="multiple-regression.html#coefficient-interpretation"><i class="fa fa-check"></i><b>12.4</b> Coefficient Interpretation</a></li>
<li class="chapter" data-level="12.5" data-path="multiple-regression.html"><a href="multiple-regression.html#more-literature-1"><i class="fa fa-check"></i><b>12.5</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html"><i class="fa fa-check"></i><b>13</b> Multiple Linear Regression II</a>
<ul>
<li class="chapter" data-level="13.1" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#diagnostics"><i class="fa fa-check"></i><b>13.1</b> Diagnostics</a></li>
<li class="chapter" data-level="13.2" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#transformations"><i class="fa fa-check"></i><b>13.2</b> Transformations</a></li>
<li class="chapter" data-level="13.3" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#regressograms"><i class="fa fa-check"></i><b>13.3</b> Regressograms</a></li>
<li class="chapter" data-level="13.4" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#locally-linear"><i class="fa fa-check"></i><b>13.4</b> Locally Linear</a></li>
<li class="chapter" data-level="13.5" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#gradient-summaries-gof"><i class="fa fa-check"></i><b>13.5</b> Gradient Summaries, GoF</a></li>
<li class="chapter" data-level="13.6" data-path="multiple-linear-regression-ii.html"><a href="multiple-linear-regression-ii.html#more-literature-2"><i class="fa fa-check"></i><b>13.6</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="observational-data.html"><a href="observational-data.html"><i class="fa fa-check"></i><b>14</b> Observational Data</a>
<ul>
<li class="chapter" data-level="14.1" data-path="observational-data.html"><a href="observational-data.html#temporal-interdependence"><i class="fa fa-check"></i><b>14.1</b> Temporal Interdependence</a></li>
<li class="chapter" data-level="14.2" data-path="observational-data.html"><a href="observational-data.html#spatial-interdependence"><i class="fa fa-check"></i><b>14.2</b> Spatial Interdependence</a></li>
<li class="chapter" data-level="14.3" data-path="observational-data.html"><a href="observational-data.html#endogeneity-issues"><i class="fa fa-check"></i><b>14.3</b> Endogeneity Issues</a></li>
<li class="chapter" data-level="14.4" data-path="observational-data.html"><a href="observational-data.html#historical-event-studies-natural-experiments"><i class="fa fa-check"></i><b>14.4</b> Historical Event Studies (“Natural Experiments”)</a></li>
<li class="chapter" data-level="14.5" data-path="observational-data.html"><a href="observational-data.html#regression-discontinuitieskink-rdrk"><i class="fa fa-check"></i><b>14.5</b> Regression Discontinuities/Kink (RD/RK)</a></li>
<li class="chapter" data-level="14.6" data-path="observational-data.html"><a href="observational-data.html#difference-in-differences-did"><i class="fa fa-check"></i><b>14.6</b> Difference in Differences (DID)</a></li>
<li class="chapter" data-level="14.7" data-path="observational-data.html"><a href="observational-data.html#more-literature-3"><i class="fa fa-check"></i><b>14.7</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="experimental-data.html"><a href="experimental-data.html"><i class="fa fa-check"></i><b>15</b> Experimental Data</a></li>
<li class="chapter" data-level="16" data-path="data-scientism.html"><a href="data-scientism.html"><i class="fa fa-check"></i><b>16</b> Data Scientism</a>
<ul>
<li class="chapter" data-level="16.1" data-path="data-scientism.html"><a href="data-scientism.html#data-errors"><i class="fa fa-check"></i><b>16.1</b> Data Errors</a></li>
<li class="chapter" data-level="16.2" data-path="data-scientism.html"><a href="data-scientism.html#p-hacking"><i class="fa fa-check"></i><b>16.2</b> P-Hacking</a></li>
<li class="chapter" data-level="16.3" data-path="data-scientism.html"><a href="data-scientism.html#spurious-regression"><i class="fa fa-check"></i><b>16.3</b> Spurious Regression</a></li>
<li class="chapter" data-level="16.4" data-path="data-scientism.html"><a href="data-scientism.html#spurious-causal-impacts"><i class="fa fa-check"></i><b>16.4</b> Spurious Causal Impacts</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="misc.-topics.html"><a href="misc.-topics.html"><i class="fa fa-check"></i><b>17</b> Misc. Topics</a>
<ul>
<li class="chapter" data-level="17.1" data-path="misc.-topics.html"><a href="misc.-topics.html#nonparametric-tests"><i class="fa fa-check"></i><b>17.1</b> Nonparametric Tests</a></li>
<li class="chapter" data-level="17.2" data-path="misc.-topics.html"><a href="misc.-topics.html#distributional-comparisons"><i class="fa fa-check"></i><b>17.2</b> Distributional Comparisons</a></li>
<li class="chapter" data-level="17.3" data-path="misc.-topics.html"><a href="misc.-topics.html#prediction"><i class="fa fa-check"></i><b>17.3</b> Prediction</a></li>
<li class="chapter" data-level="17.4" data-path="misc.-topics.html"><a href="misc.-topics.html#decision-analysis"><i class="fa fa-check"></i><b>17.4</b> Decision Analysis</a></li>
</ul></li>
<li class="part"><span><b>III Reproducible Research in R</b></span></li>
<li class="chapter" data-level="18" data-path="why.html"><a href="why.html"><i class="fa fa-check"></i><b>18</b> Why?</a>
<ul>
<li class="chapter" data-level="18.1" data-path="why.html"><a href="why.html#an-example-workflow"><i class="fa fa-check"></i><b>18.1</b> An example workflow</a></li>
<li class="chapter" data-level="18.2" data-path="why.html"><a href="why.html#an-alternative-workflow"><i class="fa fa-check"></i><b>18.2</b> An alternative workflow</a></li>
<li class="chapter" data-level="18.3" data-path="why.html"><a href="why.html#task-views"><i class="fa fa-check"></i><b>18.3</b> Task Views</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="large-projects.html"><a href="large-projects.html"><i class="fa fa-check"></i><b>19</b> Large Projects</a>
<ul>
<li class="chapter" data-level="19.1" data-path="large-projects.html"><a href="large-projects.html#scripting"><i class="fa fa-check"></i><b>19.1</b> Scripting</a></li>
<li class="chapter" data-level="19.2" data-path="large-projects.html"><a href="large-projects.html#organization"><i class="fa fa-check"></i><b>19.2</b> Organization</a></li>
<li class="chapter" data-level="19.3" data-path="large-projects.html"><a href="large-projects.html#loggingsinking"><i class="fa fa-check"></i><b>19.3</b> Logging/Sinking</a></li>
<li class="chapter" data-level="19.4" data-path="large-projects.html"><a href="large-projects.html#class-projects"><i class="fa fa-check"></i><b>19.4</b> Class Projects</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="performance.html"><a href="performance.html"><i class="fa fa-check"></i><b>20</b> Performance</a>
<ul>
<li class="chapter" data-level="20.1" data-path="performance.html"><a href="performance.html#debugging"><i class="fa fa-check"></i><b>20.1</b> Debugging</a></li>
<li class="chapter" data-level="20.2" data-path="performance.html"><a href="performance.html#optimizing"><i class="fa fa-check"></i><b>20.2</b> Optimizing</a></li>
<li class="chapter" data-level="20.3" data-path="performance.html"><a href="performance.html#advanced-optimizing"><i class="fa fa-check"></i><b>20.3</b> Advanced Optimizing</a></li>
<li class="chapter" data-level="20.4" data-path="performance.html"><a href="performance.html#more-literature-4"><i class="fa fa-check"></i><b>20.4</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>21</b> Applications</a>
<ul>
<li class="chapter" data-level="21.1" data-path="applications.html"><a href="applications.html#more-literature-5"><i class="fa fa-check"></i><b>21.1</b> More Literature</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>22</b> Software</a>
<ul>
<li class="chapter" data-level="22.1" data-path="software.html"><a href="software.html#latest-versions"><i class="fa fa-check"></i><b>22.1</b> Latest versions</a></li>
<li class="chapter" data-level="22.2" data-path="software.html"><a href="software.html#general-workflow"><i class="fa fa-check"></i><b>22.2</b> General Workflow</a></li>
<li class="chapter" data-level="22.3" data-path="software.html"><a href="software.html#sweave"><i class="fa fa-check"></i><b>22.3</b> Sweave</a></li>
<li class="chapter" data-level="22.4" data-path="software.html"><a href="software.html#stata"><i class="fa fa-check"></i><b>22.4</b> Stata</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://sites.google.com/view/jordan-adamson" target="blank">Jordan Adamson</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-linear-regression-ii" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number"> 13</span> Multiple Linear Regression II<a href="multiple-linear-regression-ii.html#multiple-linear-regression-ii" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<hr />
<div id="diagnostics" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Diagnostics<a href="multiple-linear-regression-ii.html#diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There’s little sense in getting great standard errors for a terrible model. Plotting your regression object a simple and easy step to help diagnose whether your model is in some way bad. We next go through what each of these figures show.</p>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="multiple-linear-regression-ii.html#cb463-1" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Murder<span class="sc">~</span>Assault<span class="sc">+</span>UrbanPop, <span class="at">data=</span>USArrests)</span>
<span id="cb463-2"><a href="multiple-linear-regression-ii.html#cb463-2" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb463-3"><a href="multiple-linear-regression-ii.html#cb463-3" tabindex="-1"></a><span class="fu">plot</span>(reg, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="fu">grey</span>(<span class="dv">0</span>,.<span class="dv">5</span>))</span></code></pre></div>
<p><img src="03-LinearRegression_files/figure-html/unnamed-chunk-32-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Outliers</strong>.
The first diagnostic plot examines outliers in terms the outcome <span class="math inline">\(y_i\)</span> being far from its prediction <span class="math inline">\(\hat{y}_i\)</span>. You may be interested in such outliers because they can (but do not have to) unduly influence your estimates.</p>
<p>The third diagnostic plot examines another type of outlier, where an observation with the explanatory variable <span class="math inline">\(x_i\)</span> is far from the center of mass of the other <span class="math inline">\(x\)</span>’s. A point has high <em>leverage</em> if the estimates change dramatically when you estimate the model without that data point.</p>
<div class="sourceCode" id="cb464"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb464-1"><a href="multiple-linear-regression-ii.html#cb464-1" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">40</span></span>
<span id="cb464-2"><a href="multiple-linear-regression-ii.html#cb464-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="fu">runif</span>(N<span class="dv">-1</span>,<span class="dv">3</span>,<span class="dv">8</span>))</span>
<span id="cb464-3"><a href="multiple-linear-regression-ii.html#cb464-3" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="dv">0</span>,<span class="fl">0.4</span>)</span>
<span id="cb464-4"><a href="multiple-linear-regression-ii.html#cb464-4" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">3</span> <span class="sc">+</span> <span class="fl">0.6</span><span class="sc">*</span><span class="fu">sqrt</span>(x) <span class="sc">+</span> e</span>
<span id="cb464-5"><a href="multiple-linear-regression-ii.html#cb464-5" tabindex="-1"></a><span class="fu">plot</span>(y<span class="sc">~</span>x, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="fu">grey</span>(<span class="dv">0</span>,.<span class="dv">5</span>))</span>
<span id="cb464-6"><a href="multiple-linear-regression-ii.html#cb464-6" tabindex="-1"></a><span class="fu">points</span>(x[<span class="dv">1</span>],y[<span class="dv">1</span>], <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="fu">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,.<span class="dv">5</span>))</span>
<span id="cb464-7"><a href="multiple-linear-regression-ii.html#cb464-7" tabindex="-1"></a></span>
<span id="cb464-8"><a href="multiple-linear-regression-ii.html#cb464-8" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x), <span class="at">col=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb464-9"><a href="multiple-linear-regression-ii.html#cb464-9" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y[<span class="sc">-</span><span class="dv">1</span>]<span class="sc">~</span>x[<span class="sc">-</span><span class="dv">1</span>]))</span></code></pre></div>
<p><img src="03-LinearRegression_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>See <a href="https://www.rwi-essen.de/fileadmin/user_upload/RWI/Publikationen/I4R_Discussion_Paper_Series/032_I4R_Haddad_Kattan_Wochner-updateJune28.pdf">AEJ-leverage</a> and <a href="https://statmodeling.stat.columbia.edu/2025/02/28/the-r-squared-on-this-is-kinda-low-no/">NBER-leverage</a> for examples of leverage in economics.</p>
<p>Standardized residuals are
<span class="math display">\[
r_i=\frac{\hat{\epsilon}_i}{s_{[i]}\sqrt{1-h_i}},
\]</span>
where <span class="math inline">\(s_{[i]}\)</span> is the root mean squared error of a regression with the <span class="math inline">\(i\)</span>th observation removed and <span class="math inline">\(h_i\)</span> is the leverage of residual <span class="math inline">\(\hat{\epsilon_i}\)</span>.</p>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="multiple-linear-regression-ii.html#cb465-1" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">hatvalues</span>(reg))</span>
<span id="cb465-2"><a href="multiple-linear-regression-ii.html#cb465-2" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">rstandard</span>(reg))</span></code></pre></div>
<p>(See <a href="https://www.r-bloggers.com/2016/06/leverage-and-influence-in-a-nutshell/" class="uri">https://www.r-bloggers.com/2016/06/leverage-and-influence-in-a-nutshell/</a> for a good interactive explanation, and <a href="https://online.stat.psu.edu/stat462/node/87/" class="uri">https://online.stat.psu.edu/stat462/node/87/</a> for detail.)</p>
<p>The fourth plot further assesses outlier <span class="math inline">\(X\)</span> using <em>Cook’s Distance</em>, which sums of all prediction changes when observation i is removed and scales proportionally to the mean square error <span class="math inline">\(s^2 = \frac{\sum_{i} (e_{i})^2 }{n-K}.\)</span>$
D_{i} =
= $$</p>
<div class="sourceCode" id="cb466"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb466-1"><a href="multiple-linear-regression-ii.html#cb466-1" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">cooks.distance</span>(reg))</span>
<span id="cb466-2"><a href="multiple-linear-regression-ii.html#cb466-2" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">influencePlot</span>(reg)</span></code></pre></div>
<p><strong>Normality</strong>.
The second plot examines whether the residuals are normally distributed. Your OLS coefficient estimates do not depend on the normality of the residuals. (Good thing, because there’s no reason the residuals of economic phenomena should be so well behaved.) Many hypothesis tests are, however, affected by the distribution of the residuals. For these reasons, you may be interested in assessing normality</p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="multiple-linear-regression-ii.html#cb467-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb467-2"><a href="multiple-linear-regression-ii.html#cb467-2" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">resid</span>(reg), <span class="at">main=</span><span class="st">&#39;Histogram of Residuals&#39;</span>,</span>
<span id="cb467-3"><a href="multiple-linear-regression-ii.html#cb467-3" tabindex="-1"></a>    <span class="at">font.main=</span><span class="dv">1</span>, <span class="at">border=</span><span class="cn">NA</span>)</span>
<span id="cb467-4"><a href="multiple-linear-regression-ii.html#cb467-4" tabindex="-1"></a></span>
<span id="cb467-5"><a href="multiple-linear-regression-ii.html#cb467-5" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">resid</span>(reg), <span class="at">main=</span><span class="st">&quot;Normal Q-Q Plot of Residuals&quot;</span>,</span>
<span id="cb467-6"><a href="multiple-linear-regression-ii.html#cb467-6" tabindex="-1"></a>    <span class="at">font.main=</span><span class="dv">1</span>, <span class="at">col=</span><span class="fu">grey</span>(<span class="dv">0</span>,.<span class="dv">5</span>), <span class="at">pch=</span><span class="dv">16</span>)</span>
<span id="cb467-7"><a href="multiple-linear-regression-ii.html#cb467-7" tabindex="-1"></a><span class="fu">qqline</span>(<span class="fu">resid</span>(reg), <span class="at">col=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb467-8"><a href="multiple-linear-regression-ii.html#cb467-8" tabindex="-1"></a></span>
<span id="cb467-9"><a href="multiple-linear-regression-ii.html#cb467-9" tabindex="-1"></a><span class="co">#shapiro.test(resid(reg))</span></span></code></pre></div>
<p>Heterskedasticity may also matters for variability estimates. This is not shown in the plot, but you can conduct a simple test</p>
<div class="sourceCode" id="cb468"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb468-1"><a href="multiple-linear-regression-ii.html#cb468-1" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb468-2"><a href="multiple-linear-regression-ii.html#cb468-2" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">bptest</span>(reg)</span></code></pre></div>
<p><strong>Collinearity</strong>.
This is when one explanatory variable in a multiple linear regression model can be linearly predicted from the others with a substantial degree of accuracy. Coefficient estimates may change erratically in response to small changes in the model or the data. (In the extreme case where there are more variables than observations <span class="math inline">\(K&gt;N\)</span>, the inverse of <span class="math inline">\(X&#39;X\)</span> has an infinite number of solutions.) To diagnose collinearity, we can use the <em>Variance Inflation Factor</em>
<span class="math display">\[
VIF_{k}=\frac{1}{1-R^2_k},
\]</span>
where <span class="math inline">\(R^2_k\)</span> is the <span class="math inline">\(R^2\)</span> for the regression of <span class="math inline">\(X_k\)</span> on the other covariates <span class="math inline">\(X_{-k}\)</span> (a regression that does not involve the response variable Y)</p>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="multiple-linear-regression-ii.html#cb469-1" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(reg) </span>
<span id="cb469-2"><a href="multiple-linear-regression-ii.html#cb469-2" tabindex="-1"></a><span class="fu">sqrt</span>(car<span class="sc">::</span><span class="fu">vif</span>(reg)) <span class="sc">&gt;</span> <span class="dv">2</span> <span class="co"># problem?</span></span></code></pre></div>
</div>
<div id="transformations" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Transformations<a href="multiple-linear-regression-ii.html#transformations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Transforming variables can often improve your model fit while still allowing it estimated via OLS. This is because OLS only requires the model to be linear in the parameters. Under the assumptions of the model is correctly specified, the following table is how we can interpret the coefficients of the transformed data. (Note for small changes, <span class="math inline">\(\Delta ln(x) \approx \Delta x / x = \Delta x \% \cdot 100\)</span>.)</p>
<table>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th><em>Specification</em></th>
<th><em>Regressand</em></th>
<th><em>Regressor</em></th>
<th><em>Derivative</em></th>
<th><em>Interpretation (If True)</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>linear–linear</td>
<td><span class="math inline">\(y\)</span></td>
<td><span class="math inline">\(x\)</span></td>
<td><span class="math inline">\(\Delta y = \beta_1\cdot\Delta x\)</span></td>
<td>Change <span class="math inline">\(x\)</span> by one unit <span class="math inline">\(\rightarrow\)</span> change <span class="math inline">\(y\)</span> by <span class="math inline">\(\beta_1\)</span> units.</td>
</tr>
<tr class="even">
<td>log–linear</td>
<td><span class="math inline">\(ln(y)\)</span></td>
<td><span class="math inline">\(x\)</span></td>
<td><span class="math inline">\(\Delta y \% \cdot 100 \approx \beta_1 \cdot \Delta x\)</span></td>
<td>Change <span class="math inline">\(x\)</span> by one unit <span class="math inline">\(\rightarrow\)</span> change <span class="math inline">\(y\)</span> by <span class="math inline">\(100 \cdot \beta_1\)</span> percent.</td>
</tr>
<tr class="odd">
<td>linear–log</td>
<td><span class="math inline">\(y\)</span></td>
<td><span class="math inline">\(ln(x)\)</span></td>
<td><span class="math inline">\(\Delta y \approx  \frac{\beta_1}{100}\cdot \Delta x \%\)</span></td>
<td>Change <span class="math inline">\(x\)</span> by one percent <span class="math inline">\(\rightarrow\)</span> change <span class="math inline">\(y\)</span> by <span class="math inline">\(\frac{\beta_1}{100}\)</span> units</td>
</tr>
<tr class="even">
<td>log–log</td>
<td><span class="math inline">\(ln(y)\)</span></td>
<td><span class="math inline">\(ln(x)\)</span></td>
<td><span class="math inline">\(\Delta y \% \approx \beta_1\cdot \Delta x \%\)</span></td>
<td>Change <span class="math inline">\(x\)</span> by one percent <span class="math inline">\(\rightarrow\)</span> change <span class="math inline">\(y\)</span> by <span class="math inline">\(\beta_1\)</span> percent</td>
</tr>
</tbody>
</table>
<p>Now recall from micro theory that an additively seperable and linear production function is referred to as ``perfect substitutes’‘. With a linear model and untranformed data, you have implicitly modelled the different regressors <span class="math inline">\(X\)</span> as perfect substitutes. Further recall that the’‘perfect substitutes’’ model is a special case of the constant elasticity of substitution production function. Here, we will build on <a href="http://dx.doi.org/10.2139/ssrn.3917397" class="uri">http://dx.doi.org/10.2139/ssrn.3917397</a>, and consider box-cox transforming both <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>. Specifically, apply the box-cox transform of <span class="math inline">\(y\)</span> using parameter <span class="math inline">\(\lambda\)</span> and apply another box-cox transform to each <span class="math inline">\(x\)</span> using the same parameter <span class="math inline">\(\rho\)</span> so that
<span class="math display">\[
y^{(\lambda)}_{i} = \sum_{k=1}^{K}\beta_{k} x^{(\rho)}_{ik} + \epsilon_{i}\\
y^{(\lambda)}_{i} =
\begin{cases}
\lambda^{-1}[ (y_i+1)^{\lambda}- 1] &amp; \lambda \neq 0 \\
log(y_i+1) &amp;  \lambda=0
\end{cases}.\\
x^{(\rho)}_{i} =
\begin{cases}
\rho^{-1}[ (x_i)^{\rho}- 1] &amp; \rho \neq 0 \\
log(x_{i}+1) &amp;  \rho=0
\end{cases}.
\]</span></p>
<p>Notice that this nests:</p>
<ul>
<li>linear-linear <span class="math inline">\((\rho=\lambda=1)\)</span>.</li>
<li>linear-log <span class="math inline">\((\rho=1, \lambda=0)\)</span>.</li>
<li>log-linear <span class="math inline">\((\rho=0, \lambda=1)\)</span>.</li>
<li>log-log <span class="math inline">\((\rho=\lambda=0)\)</span>.</li>
</ul>
<p>If <span class="math inline">\(\rho=\lambda\)</span>, we get the CES production function. This nests the ‘’perfect substitutes’’ linear-linear model (<span class="math inline">\(\rho=\lambda=1\)</span>) , the ‘’cobb-douglas’’ log-log model (<span class="math inline">\(\rho=\lambda=0\)</span>), and many others. We can define <span class="math inline">\(\lambda=\rho/\lambda&#39;\)</span> to be clear that this is indeed a CES-type transformation where</p>
<ul>
<li><span class="math inline">\(\rho \in (-\infty,1]\)</span> controls the “substitutability” of explanatory variables. E.g., <span class="math inline">\(\rho &lt;0\)</span> is ‘’complementary’’.</li>
<li><span class="math inline">\(\lambda\)</span> determines ‘’returns to scale’‘. E.g., <span class="math inline">\(\lambda&lt;1\)</span> is’‘decreasing returns’’.</li>
</ul>
<p>We compute the mean squared error in the original scale by inverting the predictions;
<span class="math display">\[
\widehat{y}_{i} =
\begin{cases}
[ \widehat{y}_{i}^{(\lambda)} \cdot \lambda ]^{1/\lambda} -1 &amp; \lambda  \neq 0 \\
exp( \widehat{y}_{i}^{(\lambda)}) -1 &amp;  \lambda=0
\end{cases}.
\]</span></p>
<p>It is easiest to optimize parameters in a 2-step procedure called `concentrated optimization’. We first solve for <span class="math inline">\(\widehat{\beta}(\rho,\lambda)\)</span> and compute the mean squared error <span class="math inline">\(MSE(\rho,\lambda)\)</span>. We then find the <span class="math inline">\((\rho,\lambda)\)</span> which minimizes <span class="math inline">\(MSE\)</span>.</p>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="multiple-linear-regression-ii.html#cb470-1" tabindex="-1"></a><span class="co"># Box-Cox Transformation Function</span></span>
<span id="cb470-2"><a href="multiple-linear-regression-ii.html#cb470-2" tabindex="-1"></a>bxcx <span class="ot">&lt;-</span> <span class="cf">function</span>( xy, rho){</span>
<span id="cb470-3"><a href="multiple-linear-regression-ii.html#cb470-3" tabindex="-1"></a>    <span class="cf">if</span> (rho <span class="sc">==</span> <span class="dv">0</span><span class="dt">L</span>) {</span>
<span id="cb470-4"><a href="multiple-linear-regression-ii.html#cb470-4" tabindex="-1"></a>      <span class="fu">log</span>(xy<span class="sc">+</span><span class="dv">1</span>)</span>
<span id="cb470-5"><a href="multiple-linear-regression-ii.html#cb470-5" tabindex="-1"></a>    } <span class="cf">else</span> <span class="cf">if</span>(rho <span class="sc">==</span> <span class="dv">1</span><span class="dt">L</span>){</span>
<span id="cb470-6"><a href="multiple-linear-regression-ii.html#cb470-6" tabindex="-1"></a>      xy</span>
<span id="cb470-7"><a href="multiple-linear-regression-ii.html#cb470-7" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb470-8"><a href="multiple-linear-regression-ii.html#cb470-8" tabindex="-1"></a>      ((xy<span class="sc">+</span><span class="dv">1</span>)<span class="sc">^</span>rho <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">/</span>rho</span>
<span id="cb470-9"><a href="multiple-linear-regression-ii.html#cb470-9" tabindex="-1"></a>    }</span>
<span id="cb470-10"><a href="multiple-linear-regression-ii.html#cb470-10" tabindex="-1"></a>}</span>
<span id="cb470-11"><a href="multiple-linear-regression-ii.html#cb470-11" tabindex="-1"></a>bxcx_inv <span class="ot">&lt;-</span> <span class="cf">function</span>( xy, rho){</span>
<span id="cb470-12"><a href="multiple-linear-regression-ii.html#cb470-12" tabindex="-1"></a>    <span class="cf">if</span> (rho <span class="sc">==</span> <span class="dv">0</span><span class="dt">L</span>) {</span>
<span id="cb470-13"><a href="multiple-linear-regression-ii.html#cb470-13" tabindex="-1"></a>      <span class="fu">exp</span>(xy) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb470-14"><a href="multiple-linear-regression-ii.html#cb470-14" tabindex="-1"></a>    } <span class="cf">else</span> <span class="cf">if</span>(rho <span class="sc">==</span> <span class="dv">1</span><span class="dt">L</span>){</span>
<span id="cb470-15"><a href="multiple-linear-regression-ii.html#cb470-15" tabindex="-1"></a>      xy</span>
<span id="cb470-16"><a href="multiple-linear-regression-ii.html#cb470-16" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb470-17"><a href="multiple-linear-regression-ii.html#cb470-17" tabindex="-1"></a>     (xy <span class="sc">*</span> rho <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span>rho) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb470-18"><a href="multiple-linear-regression-ii.html#cb470-18" tabindex="-1"></a>    }</span>
<span id="cb470-19"><a href="multiple-linear-regression-ii.html#cb470-19" tabindex="-1"></a>}</span>
<span id="cb470-20"><a href="multiple-linear-regression-ii.html#cb470-20" tabindex="-1"></a></span>
<span id="cb470-21"><a href="multiple-linear-regression-ii.html#cb470-21" tabindex="-1"></a><span class="co"># Which Variables</span></span>
<span id="cb470-22"><a href="multiple-linear-regression-ii.html#cb470-22" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(Murder<span class="sc">~</span>Assault<span class="sc">+</span>UrbanPop, <span class="at">data=</span>USArrests)</span>
<span id="cb470-23"><a href="multiple-linear-regression-ii.html#cb470-23" tabindex="-1"></a>X <span class="ot">&lt;-</span> USArrests[,<span class="fu">c</span>(<span class="st">&#39;Assault&#39;</span>,<span class="st">&#39;UrbanPop&#39;</span>)]</span>
<span id="cb470-24"><a href="multiple-linear-regression-ii.html#cb470-24" tabindex="-1"></a>Y <span class="ot">&lt;-</span> USArrests[,<span class="st">&#39;Murder&#39;</span>]</span>
<span id="cb470-25"><a href="multiple-linear-regression-ii.html#cb470-25" tabindex="-1"></a></span>
<span id="cb470-26"><a href="multiple-linear-regression-ii.html#cb470-26" tabindex="-1"></a><span class="co"># Simple Grid Search over potential (Rho,Lambda) </span></span>
<span id="cb470-27"><a href="multiple-linear-regression-ii.html#cb470-27" tabindex="-1"></a>rl_df <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">rho=</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">by=</span>.<span class="dv">5</span>),<span class="at">lambda=</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">by=</span>.<span class="dv">5</span>))</span>
<span id="cb470-28"><a href="multiple-linear-regression-ii.html#cb470-28" tabindex="-1"></a></span>
<span id="cb470-29"><a href="multiple-linear-regression-ii.html#cb470-29" tabindex="-1"></a><span class="co"># Compute Mean Squared Error</span></span>
<span id="cb470-30"><a href="multiple-linear-regression-ii.html#cb470-30" tabindex="-1"></a><span class="co"># from OLS on Transformed Data</span></span>
<span id="cb470-31"><a href="multiple-linear-regression-ii.html#cb470-31" tabindex="-1"></a>errors <span class="ot">&lt;-</span> <span class="fu">apply</span>(rl_df,<span class="dv">1</span>,<span class="cf">function</span>(rl){</span>
<span id="cb470-32"><a href="multiple-linear-regression-ii.html#cb470-32" tabindex="-1"></a>    Xr <span class="ot">&lt;-</span> <span class="fu">bxcx</span>(X,rl[[<span class="dv">1</span>]])</span>
<span id="cb470-33"><a href="multiple-linear-regression-ii.html#cb470-33" tabindex="-1"></a>    Yr <span class="ot">&lt;-</span> <span class="fu">bxcx</span>(Y,rl[[<span class="dv">2</span>]])</span>
<span id="cb470-34"><a href="multiple-linear-regression-ii.html#cb470-34" tabindex="-1"></a>    Datr <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">Murder=</span>Yr,Xr)</span>
<span id="cb470-35"><a href="multiple-linear-regression-ii.html#cb470-35" tabindex="-1"></a>    Regr <span class="ot">&lt;-</span> <span class="fu">lm</span>(Murder<span class="sc">~</span>Assault<span class="sc">+</span>UrbanPop, <span class="at">data=</span>Datr)</span>
<span id="cb470-36"><a href="multiple-linear-regression-ii.html#cb470-36" tabindex="-1"></a>    Predr <span class="ot">&lt;-</span> <span class="fu">bxcx_inv</span>(<span class="fu">predict</span>(Regr),rl[[<span class="dv">2</span>]])</span>
<span id="cb470-37"><a href="multiple-linear-regression-ii.html#cb470-37" tabindex="-1"></a>    Resr  <span class="ot">&lt;-</span> (Y <span class="sc">-</span> Predr)</span>
<span id="cb470-38"><a href="multiple-linear-regression-ii.html#cb470-38" tabindex="-1"></a>    <span class="fu">return</span>(Resr)</span>
<span id="cb470-39"><a href="multiple-linear-regression-ii.html#cb470-39" tabindex="-1"></a>})</span>
<span id="cb470-40"><a href="multiple-linear-regression-ii.html#cb470-40" tabindex="-1"></a>rl_df<span class="sc">$</span>mse <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(errors<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb470-41"><a href="multiple-linear-regression-ii.html#cb470-41" tabindex="-1"></a></span>
<span id="cb470-42"><a href="multiple-linear-regression-ii.html#cb470-42" tabindex="-1"></a><span class="co"># Want Small MSE and Interpretable</span></span>
<span id="cb470-43"><a href="multiple-linear-regression-ii.html#cb470-43" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,<span class="at">ncol=</span><span class="dv">2</span>), <span class="at">width=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>), <span class="at">height=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb470-44"><a href="multiple-linear-regression-ii.html#cb470-44" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb470-45"><a href="multiple-linear-regression-ii.html#cb470-45" tabindex="-1"></a><span class="fu">plot</span>(lambda<span class="sc">~</span>rho,rl_df, <span class="at">cex=</span><span class="dv">8</span>, <span class="at">pch=</span><span class="dv">15</span>,</span>
<span id="cb470-46"><a href="multiple-linear-regression-ii.html#cb470-46" tabindex="-1"></a>    <span class="at">xlab=</span><span class="fu">expression</span>(rho),</span>
<span id="cb470-47"><a href="multiple-linear-regression-ii.html#cb470-47" tabindex="-1"></a>    <span class="at">ylab=</span><span class="fu">expression</span>(lambda),</span>
<span id="cb470-48"><a href="multiple-linear-regression-ii.html#cb470-48" tabindex="-1"></a>    <span class="at">col=</span><span class="fu">hcl.colors</span>(<span class="dv">25</span>)[<span class="fu">cut</span>(<span class="dv">1</span><span class="sc">/</span>rl_df<span class="sc">$</span>mse,<span class="dv">25</span>)])</span>
<span id="cb470-49"><a href="multiple-linear-regression-ii.html#cb470-49" tabindex="-1"></a><span class="co"># Which min</span></span>
<span id="cb470-50"><a href="multiple-linear-regression-ii.html#cb470-50" tabindex="-1"></a>rl0 <span class="ot">&lt;-</span> rl_df[<span class="fu">which.min</span>(rl_df<span class="sc">$</span>mse),<span class="fu">c</span>(<span class="st">&#39;rho&#39;</span>,<span class="st">&#39;lambda&#39;</span>)]</span>
<span id="cb470-51"><a href="multiple-linear-regression-ii.html#cb470-51" tabindex="-1"></a><span class="fu">points</span>(rl0<span class="sc">$</span>rho, rl0<span class="sc">$</span>lambda, <span class="at">pch=</span><span class="dv">0</span>, <span class="at">col=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="dv">8</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb470-52"><a href="multiple-linear-regression-ii.html#cb470-52" tabindex="-1"></a><span class="co"># Legend</span></span>
<span id="cb470-53"><a href="multiple-linear-regression-ii.html#cb470-53" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">2</span>),<span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">type=</span><span class="st">&#39;n&#39;</span>, <span class="at">axes=</span>F,</span>
<span id="cb470-54"><a href="multiple-linear-regression-ii.html#cb470-54" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&#39;&#39;</span>,<span class="at">ylab=</span><span class="st">&#39;&#39;</span>, <span class="at">cex.main=</span>.<span class="dv">8</span>,</span>
<span id="cb470-55"><a href="multiple-linear-regression-ii.html#cb470-55" tabindex="-1"></a>    <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">frac</span>(<span class="dv">1</span>,<span class="st">&#39;Mean Square Error&#39;</span>)))</span>
<span id="cb470-56"><a href="multiple-linear-regression-ii.html#cb470-56" tabindex="-1"></a><span class="fu">rasterImage</span>(<span class="fu">as.raster</span>(<span class="fu">matrix</span>(<span class="fu">hcl.colors</span>(<span class="dv">25</span>), <span class="at">ncol=</span><span class="dv">1</span>)), <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb470-57"><a href="multiple-linear-regression-ii.html#cb470-57" tabindex="-1"></a><span class="fu">text</span>(<span class="at">x=</span><span class="fl">1.5</span>, <span class="at">y=</span><span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="at">l=</span><span class="dv">10</span>), <span class="at">cex=</span>.<span class="dv">5</span>,</span>
<span id="cb470-58"><a href="multiple-linear-regression-ii.html#cb470-58" tabindex="-1"></a>    <span class="at">labels=</span><span class="fu">levels</span>(<span class="fu">cut</span>(<span class="dv">1</span><span class="sc">/</span>rl_df<span class="sc">$</span>mse,<span class="dv">10</span>)))</span></code></pre></div>
<p><img src="03-LinearRegression_files/figure-html/unnamed-chunk-39-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>The parameters <span class="math inline">\(-1,0,1,2\)</span> are easy to interpret and might be selected instead if there is only a small loss in fit. (In the above example, we might choose <span class="math inline">\(\lambda=0\)</span> instead of the <span class="math inline">\(\lambda\)</span> which minimized the mean square error). You can also plot the specific predictions to better understand the effect of data transformation beyond mean squared error.</p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="multiple-linear-regression-ii.html#cb471-1" tabindex="-1"></a><span class="co"># Plot for Specific Comparisons</span></span>
<span id="cb471-2"><a href="multiple-linear-regression-ii.html#cb471-2" tabindex="-1"></a>Xr <span class="ot">&lt;-</span> <span class="fu">bxcx</span>(X,rl0[[<span class="dv">1</span>]])</span>
<span id="cb471-3"><a href="multiple-linear-regression-ii.html#cb471-3" tabindex="-1"></a>Yr <span class="ot">&lt;-</span> <span class="fu">bxcx</span>(Y,rl0[[<span class="dv">2</span>]])</span>
<span id="cb471-4"><a href="multiple-linear-regression-ii.html#cb471-4" tabindex="-1"></a>Datr <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">Murder=</span>Yr,Xr)</span>
<span id="cb471-5"><a href="multiple-linear-regression-ii.html#cb471-5" tabindex="-1"></a>Regr <span class="ot">&lt;-</span> <span class="fu">lm</span>(Murder<span class="sc">~</span>Assault<span class="sc">+</span>UrbanPop, <span class="at">data=</span>Datr)</span>
<span id="cb471-6"><a href="multiple-linear-regression-ii.html#cb471-6" tabindex="-1"></a>Predr <span class="ot">&lt;-</span> <span class="fu">bxcx_inv</span>(<span class="fu">predict</span>(Regr),rl0[[<span class="dv">2</span>]])</span>
<span id="cb471-7"><a href="multiple-linear-regression-ii.html#cb471-7" tabindex="-1"></a></span>
<span id="cb471-8"><a href="multiple-linear-regression-ii.html#cb471-8" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,.<span class="dv">5</span>), <span class="at">col=</span><span class="fu">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">5</span>))</span>
<span id="cb471-9"><a href="multiple-linear-regression-ii.html#cb471-9" tabindex="-1"></a><span class="fu">plot</span>(Y, Predr, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">1</span>], <span class="at">ylab=</span><span class="st">&#39;Prediction&#39;</span>, </span>
<span id="cb471-10"><a href="multiple-linear-regression-ii.html#cb471-10" tabindex="-1"></a>    <span class="at">ylim=</span><span class="fu">range</span>(Y,Predr))</span>
<span id="cb471-11"><a href="multiple-linear-regression-ii.html#cb471-11" tabindex="-1"></a><span class="fu">points</span>(Y, <span class="fu">predict</span>(reg), <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">2</span>])</span>
<span id="cb471-12"><a href="multiple-linear-regression-ii.html#cb471-12" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;topleft&#39;</span>, <span class="at">pch=</span><span class="fu">c</span>(<span class="dv">16</span>), <span class="at">col=</span>cols,</span>
<span id="cb471-13"><a href="multiple-linear-regression-ii.html#cb471-13" tabindex="-1"></a>    <span class="at">title=</span><span class="fu">expression</span>(rho<span class="sc">~</span><span class="st">&#39;, &#39;</span><span class="sc">~</span>lambda),</span>
<span id="cb471-14"><a href="multiple-linear-regression-ii.html#cb471-14" tabindex="-1"></a>    <span class="at">legend=</span><span class="fu">c</span>(  <span class="fu">paste0</span>(rl0, <span class="at">collapse=</span><span class="st">&#39;, &#39;</span>),<span class="st">&#39;1, 1&#39;</span>) )</span>
<span id="cb471-15"><a href="multiple-linear-regression-ii.html#cb471-15" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a=</span><span class="dv">0</span>,<span class="at">b=</span><span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="03-LinearRegression_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p>When explicitly transforming data according to <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\rho\)</span>, these parameters increase the degrees of freedom by two. The default hypothesis testing procedures do not account for you trying out different transformations, and should be adjusted by the increased degrees of freedom. Specification searches deflate standard errors and are a major source for false discoveries.</p>
</div>
<div id="regressograms" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Regressograms<a href="multiple-linear-regression-ii.html#regressograms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="locally-linear" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Locally Linear<a href="multiple-linear-regression-ii.html#locally-linear" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="gradient-summaries-gof" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Gradient Summaries, GoF<a href="multiple-linear-regression-ii.html#gradient-summaries-gof" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="more-literature-2" class="section level2 hasAnchor" number="13.6">
<h2><span class="header-section-number">13.6</span> More Literature<a href="multiple-linear-regression-ii.html#more-literature-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Diagnostics</p>
<ul>
<li><a href="https://book.stat420.org/model-diagnostics.html#leverage" class="uri">https://book.stat420.org/model-diagnostics.html#leverage</a></li>
<li><a href="https://socialsciences.mcmaster.ca/jfox/Books/RegressionDiagnostics/index.html" class="uri">https://socialsciences.mcmaster.ca/jfox/Books/RegressionDiagnostics/index.html</a></li>
<li><a href="https://bookdown.org/ripberjt/labbook/diagnosing-and-addressing-problems-in-linear-regression.html" class="uri">https://bookdown.org/ripberjt/labbook/diagnosing-and-addressing-problems-in-linear-regression.html</a></li>
<li>Belsley, D. A., Kuh, E., and Welsch, R. E. (1980). Regression Diagnostics: Identifying influential data and sources of collinearity. Wiley. <a href="https://doi.org/10.1002/0471725153" class="uri">https://doi.org/10.1002/0471725153</a></li>
<li>Fox, J. D. (2020). Regression diagnostics: An introduction (2nd ed.). SAGE. <a href="https://dx.doi.org/10.4135/9781071878651" class="uri">https://dx.doi.org/10.4135/9781071878651</a></li>
</ul>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="observational-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["index.pdf", "index.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
