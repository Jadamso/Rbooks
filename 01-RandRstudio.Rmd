# Preface {#index}

In this book, there are three R primers that should get you using R in econometrics research.

 * *Part   I*: Introduction to R
 * *Part  II*: Introduction to Reproducible R
 * *Part III*: Intermediate R

Much of this material was copied or modified from elsewhere, especially https://r4ds.had.co.nz/ and https://adv-r.hadley.nz/ but also many other sources I have found online and elsewhere over the years.


# (PART) Introduction to R {-} 

# First steps on Programming in R 
***


## Install R

First Install [R](https://cloud.r-project.org/).
Then Install [Rstudio](https://www.rstudio.com/products/rstudio/download/).

For help setting up

* https://learnr-examples.shinyapps.io/ex-setup-r/
* https://rstudio-education.github.io/hopr/starting.html
* https://a-little-book-of-r-for-bioinformatics.readthedocs.io/en/latest/src/installr.html
* https://cran.r-project.org/doc/manuals/R-admin.html

* https://courses.edx.org/courses/UTAustinX/UT.7.01x/3T2014/56c5437b88fa43cf828bff5371c6a924/
* https://owi.usgs.gov/R/training-curriculum/installr/
* https://www.earthdatascience.org/courses/earth-analytics/document-your-science/setup-r-rstudio/


Make sure you have the latest version of R and Rstudio for class. If not, then reinstall. 

## Interfacing with the GUI.

Rstudio is easiest to get going with. (There are other GUI's.) There are 4 panes. The top left is where you write and save code

 * Create and save a new `R Script` file *My_First_Script.R*
 * could also use a plain .txt file.

```{r, echo=FALSE}
knitr::include_graphics("./Figures_Manual/Rstudio.svg")
```

The pane below is where your code is executed. For all following examples, make sure to both execute and store your code.


Note that 


```{r, eval=TRUE, echo=TRUE}
CodeInput_String <- c('code output looks like this')
CodeInput_String
## while this is just a comment
```

# Mathematical Objects
***


## Scalars and Vectors

```{r}
x0 <- 1 ## Your first scalar
x0 ## Print the scalar
(x0+1)^2 ## Perform and print a simple calculation
x0 + NA ## often used for missing values
x0*2
```

```{r}
x <- c(0,1,3,10,6) ## Your First Vector
x ## Print the vector
x[2] ## Print the 2nd Element; 1
x+2 ## Print simple calculation; 2,3,5,8,12
x*2
(x+x)^2 ## Another simple calculation with two vectors
```







In R, you use multiple functions on different types of data objects. Moreover, ``typically solve complex problems by decomposing them into simple functions, not simple objects.'' (H. Wickham)



##  Functions of Scalars and Vectors

Define function sum_squared
```{r}
sum_squared <- function(x1, x2) {
	y <- (x1 + x2)^2
	return(y)
} 
```
```{r}
sum_squared(1, 3) ## 16
sum_squared(x, 2) ## 0,4,9,36,144,400
sum_squared(x, NA) ## NA,NA,NA,NA,NA
sum_squared(x, x) ## 0,4,36,144,400
sum_squared(x, 2*x)
```

Random variables are vectors created by functions
```{r}
## random standard-normal
rnorm(10) 
rnorm(10)

## random uniform
x2 <- runif(1000)
head(x2)
length(x2)
```

## Functionals

Functions that take functions as arguments 

```{r}
fun_of_rv <- function(f){
    y <- f( runif(1e3) )
    return(y)
}
```

```{r}
fun_of_rv(mean)

fun_of_rv(mean)

fun_of_rv(sum)
```


```{r}
fun_of_rv <- function(f=mean, n=20){
    y <- f( runif(n) )
    return(y)    
}
fun_of_rv()
```

Very useful for applying a function over and over again

```{r}
## sapply(1:3, f) is equivalent to c(f(1), f(2), f(3)).
## mapply takes multiple vectors
mapply(sum, 1:3, runif(3) )
```

##  Matrices and Matrix-Functions

```{r}
x_mat <- cbind(x,x)
x_mat ## Print full matrix
x_mat[2,] ## Print Row 2 Elements
x_mat[,2] ## Print Column 2 Elements

y <- apply(x_mat, 1, sum)^2 ## Apply function to each row
## ?apply  #checks the function details
y - sum_squared(x, x) ## tests if there are any differences
```

Many Other Functions
```{r}
#col1 <- x_mat[,1]
#col1
#col2 <- x_mat[,2]
#col2
x_mat * x_mat

crossprod(x_mat)

tcrossprod(x_mat) ##x_mat %*% t(x_mat)

outer(x,x) ##x %o% x
```


Example Calculations

```{r}
## Return Y-value with minimum absolute difference from 3
abs_diff_y <- abs( y - 3 ) 
abs_diff_y ## is this the luckiest number?

min(abs_diff_y)
which.min(abs_diff_y)
y[ which.min(abs_diff_y) ]
```



## Arrays and Array Functions

Generalization of matrices used in spatial econometrics

```{r}
a <- array(data = 1:24, dim = c(2, 3, 4))
a

a[1, , , drop = FALSE]  # Row 1
a[, 1, , drop = FALSE]  # Column 1
a[, , 1, drop = FALSE]  # Layer 1

a[ 1, 1,  ]  # Row 1, column 1
a[ 1,  , 1]  # Row 1, "layer" 1
a[  , 1, 1]  # Column 1, "layer" 1
a[1 , 1, 1]  # Row 1, column 1, "layer" 1
```

Apply extends to arrays

```{r}
apply(a, 1, mean)    # Row means
apply(a, 2, mean)    # Column means
apply(a, 3, mean)    # "Layer" means
apply(a, 1:2, mean)  # Row/Column combination 
```





##  Other Commom Types of Data

```{r}
l1 <- 1:10 ## cardinal numbers
l2 <- factor(c(1,2,3), ordered=T) ## ordinal numbers
l2 <- factor(c(1,2,3), ordered=F) ## "indicators", "names", 'etc'
l3 <- 'hello world'  ## character strings
l4 <- list(l1, l2, list(l3, 'way too late')) ## lists

## data.frames: your most common data type
    ## matrix of different data-types
    ## well-ordered lists
l5 <- data.frame(x=l1, y=l1)
```


# Plots
***


## Basics

Create and Plot a Toy Dataset

```{r}
x <- seq(1,10) ## create values for x
e <- rnorm(length(x), mean=0, sd=1) ## store 
y <- .25*x + e ## create values for y
xy_dat <- data.frame(x=x, y=y)

## your first plot is pretty standard
plot(y~x, xy_dat)  ## pretty and standard
```



Create and Plot a Larger Toy Dataset

```{r}
x <- seq(1, 10, by=.0002)
e <- rnorm(length(x), mean=0, sd=1)
y <- .25*x + e
xy_dat <- data.frame(x=x, y=y)
head(xy_dat)

plot(y~x, xy_dat, pch=16, col=rgb(0,0,0,.1), cex=.5)
```





##  Equation Fitting Example


Run and Plot an OLS Regression

```{r}
## OLS Regression
reg <- lm(y~x, data=xy_dat)
summary(reg)

## Add the line of best fit
plot(y~x, xy_dat, pch=16, col=rgb(0,0,0,.1), cex=.5)
abline(reg)

## Can Also Add Confidence Intervals
## https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals
```



Polish and Export Your Plot

```{r}
plot(y~x, xy_dat, pch=16, col=rgb(0,0,0,.1), cex=.5,
    xlab='', ylab='') ## Format Axis Labels Seperately
mtext('y=0.25 x + e\n e ~ standard-normal', 2, line=2)
mtext('x=[1,...,10]', 1, line=2)
title('Plot like a Boss')
title('boss: american slang for excellent; outstanding',
    cex.main=.5, font=1, line=1)
legend('topleft', legend='single data point',
    title='do you see the normal distribution?',
    pch=16, col=rgb(0,0,0,.1), cex=.5)
```


Can export figure with specific dimensions
```{r, eval=F}
pdf( 'Figures/plot_example.pdf', height=5, width=5)
plot(y~x, xy_dat, pch=16, col=rgb(0,0,0,.1), cex=.5)
dev.off()
```


# Moving beyond the basics
***


Use expansion `packages` for common procedures and more functionality
```{r, eval=FALSE}
## Other packages used in this primer
install.packages("stargazer")
install.packages("reshape2")
install.packages("purrr")
```


The most common tasks have [cheatsheets](https://www.rstudio.com/resources/cheatsheets/) you can use. E.g., 

* https://github.com/rstudio/cheatsheets/blob/main/rstudio-ide.pdf


Sometimes you will want to install a package from GitHub. For this, you can use [devtools](https://devtools.r-lib.org/) or the lighter [remotes](https://remotes.r-lib.org/)
```{r, eval=F}
install.packages("devtools")
install.packages("remotes")
```

For example, to color terminal output on Linux you can 
```{r, eval=F}
library(remotes)
# Install https://github.com/jalvesaq/colorout
# to .libPaths()[1]
install_github('jalvesaq/colorout')
```


## Task Views

Task views list relevant packages. 

For all students and early researchers, 

* https://cran.r-project.org/web/views/ReproducibleResearch.html

For microeconometrics,

* https://cran.r-project.org/web/views/Econometrics.html

For spatial econometrics 

* https://cran.r-project.org/web/views/Spatial.html
* https://cran.r-project.org/web/views/SpatioTemporal.html


Multiple packages may have the same function name for different commands. In this case use the syntax ``package::function`` to specify the package. For example
```{r, eval=F}
devtools::install_github
remotes::install_github
```


**Don't fret** Sometimes there is not a specific package for your data.

Odds are, you can do most of what you want with base code.

* Packages just wrap base code in convient formats
* see https://cran.r-project.org/web/views/ for topical overviews

Statisticians might have different naming conventions

* if the usual software just spits out a nice plot
you might have to dig a little to know precisely what you want
* your data are fundamentally numbers, strings, etc...
You only have to figure out how to read it in.

But remember that many of the best plots are custom made (see https://www.r-graph-gallery.com/), and can also be interactive or animated

* https://plotly.com/r/
* https://shiny.rstudio.com/gallery/


## Introductions to R

There are many good yet free programming books online. E.g., 

* https://cran.r-project.org/doc/manuals/R-intro.html
* R Graphics Cookbook, 2nd edition. Winston Chang. 2021. https://r-graphics.org/
* Spatial Data Science with R: Introduction to R. Robert J. Hijmans. 2021. https://rspatial.org/intr/index.html
* R for Data Science. H. Wickham and G. Grolemund. 2017. https://r4ds.had.co.nz/index.html
* An Introduction to R. W. N. Venables, D. M. Smith, R Core Team. 2017. https://colinfay.me/intro-to-r/
* https://bookdown.org/kieranmarray/intro_to_r_for_econometrics/

There are also many good yet free-online tutorials and courses. E.g., \\

* https://rafalab.github.io/dsbook/
* https://moderndive.com/foreword.html
* https://rstudio.cloud/learn/primers/1.2
* https://cran.r-project.org/manuals.html
* https://stats.idre.ucla.edu/stat/data/intro_r/intro_r_interactive_flat.html
* https://cswr.nrhstat.org/app-r

What we cover in this primer should be enough to get you going.




## Custom figures

<!-- ## CONVERT IMAGES
for pdfile in *.pdf ; do 
convert -verbose -density 500  "${pdfile}" "${pdfile%.*}".png;
done
-->


```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Vegetation.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Balances_Trial.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/PopulationDensity2.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/SampleExample.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/SemiInclusive_Example.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Stability_3.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/EvolutionaryDynamics.png")
```

```{r, echo=FALSE}
 knitr::include_graphics("./Figures_Manual/Experiment_Timeline.png")
```






# Data scientism
***

## US Gov't Spending on Science

Lets inspect some data from https://tylervigen.com/spurious-correlations

```{r}
## Your data is not made up in the computer (hopefully!)
## will normally be an address on your PC
vigen_csv <- read.csv( paste0(
'https://raw.githubusercontent.com/the-mad-statter/',
'whysospurious/master/data-raw/tylervigen.csv') ) 
class(vigen_csv)
names(vigen_csv)
vigen_csv[1:5,1:5]

## similar `apply' functions
lapply(vigen_csv[,1:5], class) ## like apply, but for lists
sapply(vigen_csv[,1:5], class) ## lapply, formatted to a vector
```

The US government spending on science is ruining cinema
(p<.001)!?

```{r}
## Drop Data before 1999
vigen_csv <- vigen_csv[vigen_csv$year >= 1999,] 

## Run OLS Regression $
reg1 <-  lm(cage_films ~ -1 + science_spending,
    data=vigen_csv)
summary(reg1)
```


It's not all bad, people in maine stay married longer?

```{r}
plot.new()
plot.window(xlim=c(1999, 2009), ylim=c(7,9))
lines(log(maine_divorce_rate*1000)~year, data=vigen_csv)
lines(log(science_spending/10)~year, data=vigen_csv, lty=2)
axis(1)
axis(2)
legend('topright', lty=c(1,2), legend=c(
    'log(maine_divorce_rate*1000)',
    'log(science_spending/10)'))
```






For more intuition on spurious correlations, try http://shiny.calpoly.sh/Corr_Reg_Game/

```{r}
par(mfrow=c(1,2), mar=c(2,2,2,1))
plot.new()
plot.window(xlim=c(1999, 2009), ylim=c(5,9)*1000)
lines(science_spending/3~year, data=vigen_csv, lty=1, col=2, pch=16)
text(2003, 8200, 'US spending on science, space, technology (USD/3)', col=2, cex=.6, srt=30)
lines(hanging_suicides~year, data=vigen_csv, lty=1, col=4, pch=16)
text(2004, 6500, 'US Suicides by hanging, strangulation, suffocation (Deaths)', col=4, cex=.6, srt=30)
axis(1)
axis(2)


plot.new()
plot.window(xlim=c(2002, 2009), ylim=c(0,5))
lines(cage_films~year, data=vigen_csv[vigen_csv$year>=2002,], lty=1, col=2, pch=16)
text(2006, 0.5, 'Number of films with Nicolas Cage (Films)', col=2, cex=.6, srt=0)
lines(pool_fall_drownings/25~year, data=vigen_csv[vigen_csv$year>=2002,], lty=1, col=4, pch=16)
text(2006, 4.5, 'Number of drownings by falling into pool (US Deaths/25)', col=4, cex=.6, srt=0)
axis(1)
axis(2)
```



```{r, results='asis', eval=F}
## Include an intercept to regression 1
#reg2 <-  lm(cage_films ~ science_spending, data=vigen_csv)
#suppressMessages(library(stargazer))
#stargazer(reg1, reg2, type='html')
```

Nevertheless, data transformation is often necessary before regression analysis. For downloading tips, see https://raw.githubusercontent.com/rstudio/cheatsheets/main/data-import.pdf


<!--\url{https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf}-->


## OLS in the age of big data

Consider random datasets

```{r}
make_noisy_data <- function(n){
    x <- seq(1,10, length.out=n)
    e <- rnorm(length(x), mean=0, sd=10)
    y <- .25*x + e
    xy_mat <- data.frame(ID=seq(x), x=x, y=y)
    return(xy_mat)
}
dat1 <- make_noisy_data(6)
dat1
```



Data merging
```{r, eval=F}
## Some spurious results are driven by errors with cleaning/merging

## Try out a small example
dat2 <- make_noisy_data(6)
## merging data in wide format
dat_merged_wide <- merge(dat1, dat2,
    by='ID', suffixes=c('.1','.2'))

## merging data in long format and reshaping to wide
dat_merged_long <- rbind( cbind(dat1,DF=1),cbind(dat2,DF=2))
library(reshape2)
dat_melted <- melt(dat_merged_long, id.vars=c('ID', 'DF'))
dat_merged_wide2 <- dcast(dat_melted, ID~DF+variable)

## CHECK!
dat_merged_wide == dat_merged_wide2
```


Regression Machines
```{r}
n <- 50
p <- 1
i <- 0

## P-hacking
while(p >= .001){
    set.seed(i)
    rdf <- data.frame( sapply(1:2, function(i) runif(n) ) )
    reg_h <- lm(X1~X2, rdf)
    p <- summary(reg_h)$coefficients[2,4]
    i <- i+1
}

plot(X1~X2, data=rdf,
    pch=16, col=grey(.5,.5),
    main=paste0('Random Dataset ', i))
reg_h <- lm(X1~X2, rdf)
abline(a=coef(reg_h)[1], b=coef(reg_h)[2])
```


## Causal effects *sans theory*

There is currently a boom in empirical research. This is not for the first time, and we'd be wise to recall some earlier wisdom from economists on the matter. Here are just two simple examples for the ''latest and greatest'' empirical recipes.

> if you torture the data long enough, it will confess
>
> --- Ronald Coase


RDD

```{r, message=F, warning=F}
n <- 1000
n_index <- seq(n)

set.seed(1)
random_walk1 <- cumsum(runif(n,-1,1))

set.seed(2)
random_walk2 <- cumsum(runif(n,-1,1))

par(mfrow=c(1,2))
plot(random_walk1, pch=16, col=grey(.5,.5))
plot(random_walk2, pch=16, col=grey(.5,.5))
```

```{r, message=F, warning=F}
## Let the data take shape
## (around the large differences before and after)
n1 <- 290
wind1 <- c(n1-300,n1+300)
dat1 <- data.frame(t=n_index, y=random_walk1, d=1*(n_index > n1))
dat1_sub <- dat1[ n_index>wind1[1] & n_index < wind1[2],]

## Then find your big break
reg0 <- lm(y~t, data=dat1_sub[dat1_sub$d==0,])
reg1 <- lm(y~t, data=dat1_sub[dat1_sub$d==1,])

## The evidence should show openly (it's just science)
plot(random_walk1, pch=16, col=grey(.5,.5), xlim=wind1)
abline(v=n1, lty=2)
lines(reg0$model$t, reg0$fitted.values, col=2)
lines(reg1$model$t, reg1$fitted.values, col=4)
```

```{r, message=F, warning=F, results='asis'}
## Dress with some statistics for added credibility
rdd_sub <- lm(y~d+t+d*t, data=dat1_sub)
rdd_full <- lm(y~d+t+d*t, data=dat1)
stargazer::stargazer(rdd_sub, rdd_full, 
    type='html',
    title='Recipe RDD',
    header=F,
    omit=c('Constant'),
    notes=c('First column uses a dataset around the discontinuity.',
    'Smaller windows are more causal, and where the effect is bigger.'))
```


DID

```{r, message=F, warning=F}
## Find a reversal of fortune
## (A good story always goes well with a nice pre-trend)
n2 <- 318
wind2 <- c(n2-20,n2+20)
plot(random_walk2, pch=16, col=4, xlim=wind2, ylim=c(-15,15))
points(random_walk1, pch=16, col=2)
abline(v=n2, lty=2)
```

```{r, message=F, warning=F, results='asis'}
## Knead out any effects that are non-causal 
## (or even just correlation)
dat2A <- data.frame(t=n_index, y=random_walk1, d=1*(n_index > n2), RWid=1)
dat2B <- data.frame(t=n_index, y=random_walk2, d=0, RWid=2)
dat2  <- rbind(dat2A, dat2B)
dat2$RWid <- as.factor(dat2$RWid)
dat2$tid <- as.factor(dat2$t)
dat2_sub <- dat2[ dat2$t>wind2[1] & dat2$t < wind2[2],]

## Report the stars for all to enjoy
## (and remind that stable coefficients are the good ones)
did_fe1 <- lm(y~d+tid, data=dat2_sub)
did_fe2 <- lm(y~d+RWid, data=dat2_sub)
did_fe3 <- lm(y~d*RWid+tid, data=dat2_sub)
stargazer::stargazer(did_fe1, did_fe2, did_fe3,
    type='html',
    title='Recipe DID',
    header=F,
    omit=c('tid','RWid', 'Constant'),
    notes=c(
     'Fixed effects for time in column 1, for id in column 2, and both in column 3.',
     'Fixed effects control for most of your concerns.',
     'Anything else creates a bias in the opposite direction.'))
```



