{
  "hash": "c310bb370d01a3a306349d9e3ab58055",
  "result": {
    "engine": "knitr",
    "markdown": "# Advanced Probability\n\n## Drawing Samples\n\nTo generate a random variable from known distributions, you can use some type of physical machine. E.g., you can roll a fair die to generate Discrete Uniform data or you can roll weighted die to generate Categorical data.\n\nThere are also several ways to computationally generate random variables from a probability distribution. Perhaps the most common one is \"inverse sampling\". To generate a random variable using inverse sampling, first sample $p$ from a uniform distribution and then find the associated quantile  quantile function $\\hat{F}^{-1}(p)$.^[Drawing random uniform samples with computers is actually quite complex and beyond the scope of this course.]\n\n\n#### **Using Data**. {-}\n\nYou can generate a random variable from a known empirical distribution. Inverse sampling randomly selects observations from the dataset with equal probabilities. To implement this, we \n\n* order the data and associate each observation with an ECDF value\n* draw $p \\in [0,1]$ as a uniform random variable\n* find the associated quantile via the ECDF\n\n:::{.callout-tip icon=false collapse=\"true\"}\nHere is an example of generating random murder rates for US states.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Empirical Distribution\nX <- USArrests[,'Murder']\nFX_hat <- ecdf(X)\nplot(FX_hat, lwd=2, xlim=c(0,20),\n    pch=16, col=grey(0,.5), main='')\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Generating random variables via inverse ECDF\np <- runif(3000) ## Multiple Draws\nQX_hat <- quantile(FX_hat, p, type=1)\nQX_hat[c(1,2,3)]\n## 78.35394882% 72.08486337% 20.29156811% \n##         12.1         11.1          3.4\n\n## Can also do directly from the data\nQX_hat <- quantile(X, p, type=1)\nQX_hat[c(1,2,3)]\n## 78.35394882% 72.08486337% 20.29156811% \n##         12.1         11.1          3.4\n```\n:::\n\n:::\n\n#### **Using Math**. {-}\n\nIf you know the distribution function that generates the data, then you can derive the quantile function and do inverse sampling. \nThat is how computers generate random data from a distribution.\n\n::: {.cell}\n\n```{.r .cell-code}\n# 4 random data points from 3 different distributions\nqunif(4)\n## [1] NaN\nqexp(4)\n## [1] NaN\nqnorm(4)\n## [1] NaN\n```\n:::\n\n\nHere is an in-depth example of the [Dagum distribution](https://en.wikipedia.org/wiki/Dagum_distribution). The distribution function is $F(x)=(1+(x/b)^{-a})^{-c}$. For a given probability $p$, we can then solve for the quantile as $F^{-1}(p)=\\frac{ b p^{\\frac{1}{ac}} }{(1-p^{1/c})^{1/a}}$. Afterwhich, we sample $p$ from a uniform distribution and then find the associated quantile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Theoretical Quantile Function (from VGAM::qdagum)\nqdagum <- function(p, scale.b=1, shape1.a, shape2.c) {\n  # Quantile function (theoretically derived from the CDF)\n  ans <- scale.b * (expm1(-log(p) / shape2.c))^(-1 / shape1.a)\n  # Special known cases\n  ans[p == 0] <- 0\n  ans[p == 1] <- Inf\n  # Safety Checks\n  ans[p < 0] <- NaN\n  ans[p > 1] <- NaN\n  if(scale.b <= 0 | shape1.a <= 0 | shape2.c <= 0){ ans <- ans*NaN }\n  # Return\n  return(ans)\n}\n\n# Generate Random Variables (VGAM::rdagum)\nrdagum <-function(n, scale.b=1, shape1.a, shape2.c){\n    p <- runif(n) # generate random probabilities\n    x <- qdagum(p, scale.b=scale.b, shape1.a=shape1.a, shape2.c=shape2.c) #find the inverses\n    return(x)\n}\n\n# Example\nset.seed(123)\nX <- rdagum(3000,1,3,1)\nX[c(1,2,3)]\n## [1] 0.7390476 1.5499868 0.8845006\n```\n:::\n\n\n## Factorial Distributions\n\n#### **Binomial**. {-}\n\nThe sum of $n$ Bernoulli trials (number of successes)\n\n* Discrete, support $\\{0,1,\\ldots,n\\}$\n* Probability Mass Function: $Prob(X_{i}=x)=\\binom{n}{x}p^{x}(1-p)^{n-x}$\n* See <https://en.wikipedia.org/wiki/Binomial_distribution>\n* A common use case: How many heads will I get when I flip a coin twice?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Minimal example\nn <- 15\np <- 0.3\n\n# PMF plot\nx <- seq(0, n)\nf_x <- dbinom(x, n, p)\nplot(x, f_x, type = \"h\", col = \"blue\",\n    main='',  xlab = \"x\", ylab = \"Prob(X = x)\")\ntitle(bquote(paste('Binom(',.(n),', ',.(p), ')' ) ))\npoints(x, f_x, pch = 16, col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Simulate:  Compare empirical vs theoretical\n#X <- rbinom(1e4, size = n, prob = p)\n#c(emp_mean = mean(X), th_mean = n*p)\n#c(emp_var  = var(X),  th_var  = n*p*(1-p))\n```\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nSuppose that employees at a company are $70%$ female and $30%$ male. If we select a random sample of eight employees, what is the probability that more than $2$ in the sample are female?\n:::\n\n:::{.callout-tip icon=false collapse=\"true\"}\nShow that \n$\\mathbb{E}[X_{i}]=np$ and $\\mathbb{V}[X_{i}]=np(1-p)$. Start with the case $n=1$, then the case $n=2$, then case $n=3$, then the general case of any $n$.\n:::\n\nThe Binomial Limit Theorem (de Moivre–Laplace theorem) says that as $n$ grows large, with $p \\in (0,1)$ staying fixed, the Binomial distribution is approximately normal with mean $np$ and variance $np(1-p)$\n\n:::{.callout-tip icon=false collapse=\"true\"}\nThe unemployment rate is $10%$. Suppose that $100$ employable people are selected randomly. What is the probability that this sample contains between $9$ and $12$ unemployed people. Use the normal approximation to binomial probabilities.\n\nParameters are \n$\\mu \\approx n p = 10$\n$\\sigma^2= n p (1−p) = 100 (0.1)(0.9)=9$\n$\\sigma=\\sqrt{9}=3$).\n:::\n\n#### **Poisson**. {-}\n\nThe number of events in a fixed interval\n\n* Discrete, support $\\{0,1,2,\\ldots\\}$\n* Probability Mass Function: $Prob(X_{i}=x)=e^{-\\lambda}\\lambda^x/x!$\n* See <https://en.wikipedia.org/wiki/Poisson_distribution>\n* A common use case: How many cars will show up in the lot tomorrow?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Minimal example\nlambda <- 3.5\n\n# PMF plot\nx <- seq(0, 15)\nf_x <- dpois(x, lambda)\nplot(x, f_x, type=\"h\", col=\"blue\",\n     xlab = \"x\", ylab = \"Prob(X = x)\")\npoints(x, f_x, pch = 16, col = \"blue\")\ntitle(bquote(paste('Pois(',.(lambda), ')')))\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n\n# Simulate: Compare empirical vs theoretical\n#X <- rpois(1e4, lambda)\n#c(emp_mean = mean(X), th_mean = lambda)\n#c(emp_var  = var(X),  th_var  = lambda)\n```\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nShow that $\\mathbb{E}[X_{i}] = \\mathbb{V}[X_{i}]= \\lambda$.\n:::\n\n\n#### **Irwin–Hall**. {-}\n\nThe sum of $n$ i.i.d. $\\text{Uniform}(0,1)$.  \n\n* Continuous, support $[0,n]$\n* Probability Density Function: $f(x) = \\dfrac{1}{(n-1)!}\n\\displaystyle\\sum_{k=0}^{\\lfloor x \\rfloor} (-1)^k\n\\binom{n}{k} (x - k)^{n-1}$ for $x \\in [0,n]$, and $0$ otherwise\n* See <https://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution>\n* A common use case: representing the sum of many small independent financial shocks\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Minimal example (base R)\n# Irwin–Hall PDF function\ndirwinhall <- function(x, n) {\n    f_x <- vector(length=length(x))\n    for(i in seq(x)) {\n        xx <- x[i]\n        if(xx < 0 | xx > n){\n            f_x[i] <- 0 \n        } else {\n            k <- seq(0, floor(xx))\n            f_k <- sum((-1)^k*choose(n, k)*(xx-k)^(n-1))/factorial(n-1)\n            f_x[i] <- f_k\n        }\n    }\n    return(f_x)\n}\n\n# Parameters\nn <- 2\nx <- seq(0, n, length.out = 500)\n\n# Compute and plot PDF\nf_x <- dirwinhall(x, n)\nplot(x, f_x, type=\"l\", col=\"blue\",\n    main='', xlab = \"x\", ylab = \"f(x)\")\ntitle(bquote(paste('IrwinHall(',.(n), ')')))\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nSee also the [Bates](https://en.wikipedia.org/wiki/Bates_distribution) distribution, which is for the mean  of $n$ i.i.d. $\\text{Uniform}(0,1)$ random variables. It essentially rescales the Irwin-Hall distribution to range between $0$ and $1$.\n\n\n#### **Beta**. {-}\nThe sample space is any number on the unit interval, $X_{i} \\in [0,1]$, but with non-uniform probabilities. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX4 <- rbeta(2000,2,2) ## two shape parameters\nhist(X4, breaks=20, border=NA, main=NA, freq=F)\n\n#See the underlying probabilities\n#f_25 <- dbeta(.25, 2, 2)\n\nx <- seq(0,1,by=.01)\nfx <- dbeta(x, 2, 2)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThe [Beta](https://en.wikipedia.org/wiki/Beta_distribution) distribution is mathematically complicated to write, and so we omit it. However, we can find the probability graphically using either the probability density function or cumulative distribution function. \n\n:::{.callout-tip icon=false collapse=\"true\"}\nSuppose $X_{i}$ is a random variable with a beta distribution. Intuitively depict $Prob(X_{i} \\in [0.2, 0.8])$ by drawing an area under the density function. Numerically estimate that same probability using the CDF.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( ecdf(X4), main=NA) # Empirical\n\nx <- seq(0,1,by=.01) # Theoretical\nFx <- pbeta(x, 2, 2)\nlines(x, Fx, col='blue')\n\n# Middle Interval Example \nF2 <- pbeta(0.2, 2, 2)\nF8 <- pbeta(0.8, 2, 2)\nF_2_8 <- F8 - F2\nF_2_8\n## [1] 0.792\n\n# Visualize\ntitle('Middle between 0.2 and 0.8')\nsegments( 0.2, F2, -1, F2, col='red')\nsegments( 0.8, F8, -1, F8, col='red')\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\nThis distribution is often used, as the probability density function has two parameters that allow it to take many different shapes.\n\n:::{.callout-tip icon=false collapse=\"true\"}\nFor each example below, intuitively depict $Prob(X_{i} \\leq 0.5)$ using the PDF. Repeat the exercise using a CDF instead of a PDF to calculate a numerical value.\n\n::: {.cell}\n\n```{.r .cell-code}\nop <- par(no.readonly = TRUE); on.exit(par(op), add = TRUE)\nx <- seq(0,1,by=.01)\npars <- expand.grid( c(.5,1,2), c(.5,1,2) )\npar(mfrow=c(3,3))\napply(pars, 1, function(p){\n    fx <- dbeta( x,p[1], p[2])\n    plot(x, fx, type='l', xlim=c(0,1), ylim=c(0,4), lwd=2, col='blue')\n    #hist(rbeta(2000, p[1], p[2]), breaks=50, border=NA, main=NA, freq=F)\n})\ntitle('Beta densities', outer=T, line=-1)\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n:::\n\n\n## Set Theory\n\nLet the sample space contain events $A$ and $B$, with their probability denoted as $Prob(A)$ and $Prob(B)$. Then\n\n- the *union*: $A\\cup B$, refers to either event occurring\n- the *intersection*: $A\\cap B$, refers to both events occurring\n- the events $A$ and $B$ are *mutually exclusive* if and only if $A\\cap B$ is empty\n- the *inclusion–exclusion* rule is: $Prob(A\\cup B)=Prob(A)+Prob(B)-Prob(A\\cap B)$\n- the events $A$ and $B$ are *mutually independent* if and only if $Prob(A\\cap B)=Prob(A) Prob(B)$\n- the *conditional probability* is $Prob(A \\mid B) = Prob(A \\cap B)/ P(B)$\n\nFor example, consider a six sided die where events are the number $>2$ or the number is even.\n\n- The sets are $A=\\{3,4,5,6\\}$ and $B=\\{2,4,6\\}$\n- To check mutually exclusive: notice $A\\cap B=\\{4,6\\}$ which is not empty. So event $A$ and event $B$ are not mutually exclusive\n\nFurther assuming the die are fair, each side has an equal $1/6$ probability. This lets us compute\n\n- $Prob(A)=4/6=2/3$ and $Prob(B)=3/6=1/2$\n- $A\\cup B=\\{2,3,4,5,6\\}$, which implies $Prob(A\\cup B)=5/6$\n- $A\\cap B=\\{4,6\\}$, which implies $Prob(A\\cap B)=2/6=1/3$\n- To check independence: notice $Prob(A\\cap B)=1/3 = (2/3) (1/2) = Prob(A)Prob(B)$. So event $A$ and event $B$ are mutually independent\n- To check inclusion–exclusion: notice $Prob(A) + Prob(B) - Prob(A\\cap B) = 2/3 + 1/2 - 1/3 = 4/6 + 3/6 - 2/6 = 5/6 = Prob(A\\cup B)$\n- Finally, the conditional probability of $Prob(\\text{die is} >2 \\mid \\text{die shows even number}) = Prob(A \\mid B) = \\frac{Prob(A \\cap B)}{P(B)} = \\frac{1/3}{1/2} = 2/3$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulation verification\nset.seed(123)\nx <- seq(1,6)\nrolls <- sample(x, 1e6, replace = TRUE)\nA <- rolls > 2\nB <- rolls %% 2 == 0\nP_AcondB <- mean(A & B) / mean(B)\nround(P_AcondB, 3)\n## [1] 0.667\n```\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nConsider a six sided die with sample space $\\{1,2,3,4,5,6\\}$ where each outcome is each equally likely. What is $Prob(\\text{die is odd or }<5)$?\nDenote the odd events as $A=\\{1,3,5\\}$ and the less than five events as  $B=\\{1,2,3,4\\}$. Then\n\n- $A\\cup B=\\{1,3\\}$, which implies $Prob(A\\cap B)=2/6=1/3$.\n- $Prob(A)=3/6=1/2$ and $Prob(B)=4/6=2/3$.\n- By inclusion–exclusion: $Prob(A\\cup B)=Prob(A)+Prob(B)-Prob(A\\cap B)=1/2+2/3-1/3=5/6$.\n\nNow find $Prob(\\text{die is even and }<5)$. Verify your answer with a computer simulation.\n:::\n\n#### **Law of Total Probability**. {-}\n\nThis law states that $Prob(A)=Prob(A \\mid B) P(B) + Prob(A \\mid \\lnot B) P(\\lnot B)$, where $\\lnot B$ is the event \"not $B$\".\n\nFor example, consider a six sided die where events are the number $>2$ or the number is even.\n- The sets are $A=\\{3,4,5,6\\}$ and $B=\\{2,4,6\\}$ and $\\lnot B = \\{1,3,5\\}$ \nFrom before, we know that $Prob(A)=2/3$, $Prob(B)=1/2$, and $Prob(A \\mid B) = 2/3$.\nThen see that $Prob(A \\mid B) Prob(B) = \\frac{2}{3} \\frac{1}{2} = 2/6$ \n\nWe can also directly compute $Prob(\\lnot B)=1/2$, or infer it from $Prob(\\lnot B)=1-Prob(B)$.\nThe conditional probability of $Prob(\\text{die is} >2 \\mid \\text{die shows odd number}) = Prob(A \\mid \\lnot B) = \\frac{Prob(A \\cap \\lnot B)}{P(\\lnot B)} = 2/3$.\n\nThen we can see that\n$Prob(A \\mid B) Prob(B) + Prob(A \\mid \\lnot B) Prob(\\lnot B) = 2/6 + 2/6 = 2/3 = Prob(A)$.\n\n## Beyond Basic Programming\n\n#### **Packages**. {-}\nExpansion \"packages\" allow for more functionality.\n\nMost packages can be easily installed from the internet via [CRAN](https://cran.r-project.org/web/packages/available_packages_by_name.html).\n\n::: {.cell}\n\n```{.r .cell-code}\n# common packages for tables/figures\ninstall.packages(\"plotly\")\ninstall.packages(\"reactable\")\ninstall.packages(\"stargazer\")\n\n# common packages for data/teaching\ninstall.packages(\"AER\")\ninstall.packages(\"Ecdat\")\ninstall.packages('wooldridge')\n\n# other packages for statistics and data handling\ninstall.packages(\"extraDistr\")\ninstall.packages(\"twosamples\")\ninstall.packages(\"data.table\")\n```\n:::\n\n\nYou only need to install packages once. But you need to load the package via `library` every time you want the extended functionality. For example, to generate exotic probability distributions\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"extraDistr\"), once ever\nlibrary(extraDistr) # every time you need it\n\npar(mfrow=c(1,2))\nfor(p in c(-.5,0)){\n    x <- rgev(2000, mu=0, sigma=1, xi=p)\n    hist(x, breaks=50, border=NA, main=NA, freq=F)\n}\ntitle('GEV densities', outer=T, line=-1)\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(extraDistr)\n\npar(mfrow=c(1,3))\nfor(p in c(-1, 0,2)){\n    x <- rtlambda(2000, p)\n    hist(x, breaks=100, border=NA, main=NA, freq=F)\n}\ntitle('Tukey-Lambda densities', outer=T, line=-1)\n```\n\n::: {.cell-output-display}\n![](01_09_MiscTopics_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nThe most common packages also have [cheatsheets](https://www.rstudio.com/resources/cheatsheets/) you can use. \n\nWe can also load other datasets using \"packages\". For example, the \"wooldridge\" package contains datasets on crime. To use this data, we must first install the package on our computer. Then, to access the data, we must first load the package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install R Data Package and Load in\ninstall.packages('wooldridge') # only once\nlibrary('wooldridge') # anytime you want to use the data\n\ndata('crime2') \ndata('crime4')\n```\n:::\n\n\n#### **Updating**. {-}\nMake sure R and your packages are up to date. The current version of R and any packages used can be found (and recorded) with \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n:::\n\n\nTo update your R packages, use \n\n::: {.cell}\n\n```{.r .cell-code}\nupdate.packages()\n```\n:::\n\n\nAfter updating R, you can update *all* packages stored on your computer (in all `.libPaths()`)\n\n::: {.cell}\n\n```{.r .cell-code}\nupdate.packages(checkBuilt=T, ask=F)\n# install.packages(old.packages(checkBuilt=T)[,\"Package\"])\n```\n:::\n\n\n\n#### **Base**. {-}\nWhile additional packages can make your code faster, they also create dependencies that can lead to problems. So learn base R well before becoming dependent on other packages\n\n* <https://bitsofanalytics.org/posts/base-vs-tidy/>\n* <https://jtr13.github.io/cc21fall2/comparison-among-base-r-tidyverse-and-datatable.html>\n\n\n#### **Github Packages**. {-}\n\n<details>\n<summary> Advanced and Optional </summary>\n  <p>\n\nSometimes you will want to install a package from GitHub. For this, you can use [devtools](https://devtools.r-lib.org/) or its light-weight version [remotes](https://remotes.r-lib.org/)\n\nTo color terminal output on Linux systems, for example, you can use the colorout package\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"remotes\")\nlibrary(remotes)\n# Install <https://github.com/jalvesaq/colorout\n# to .libPaths()[1]\ninstall_github('jalvesaq/colorout')\nlibrary(colorout)\n```\n:::\n\n\nTo use `devtools` instead, you also need to have software developer tools installed on your computer.\n\n* Windows: [Rtools](https://cran.r-project.org/bin/windows/Rtools/)\n* Mac: [Xcode](https://apps.apple.com/us/app/xcode/id497799835)\n\n\n  </p>\n</details>\n\n",
    "supporting": [
      "01_09_MiscTopics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}