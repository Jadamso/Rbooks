{
  "hash": "dc96cfb3ca7b6b106587685c465a07f5",
  "result": {
    "engine": "knitr",
    "markdown": "# Hypothesis Tests\n***\n\n## Basic Ideas\n\nIn this section, we test hypotheses using *data-driven* methods that assume much less about the data generating process. There are two main ways to conduct a hypothesis test to do so: inverting a confidence interval and imposing the null.\n\n#### **Invert a CI**.{-}\nOne main way to conduct hypothesis tests is to examine whether a confidence interval contains a hypothesized value. We then use this decision rule\n\n* reject the null if value falls outside of the interval\n* fail to reject the null if value falls inside of the interval\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_dat <- USArrests$Murder\nsample_mean <- mean(sample_dat)\n\nn <- length(sample_dat)\nJmeans <- sapply(1:n, function(i){\n    dati <- sample_dat[-i]\n    mean(dati)\n})\nhist(Jmeans, breaks=25,\n    border=NA, xlim=c(7.5,8.1),\n    main='', xlab=expression( bar(X)[-i]))\n# CI\nci_95 <- quantile(Jmeans, probs=c(.025, .975))\nabline(v=ci_95, lwd=2)\n# H0: mean=8\nabline(v=8, col=2, lwd=2)\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n#### **Impose the Null**. {-}\nWe can also compute a *null distribution*: the sampling distribution of the statistic under the null hypothesis (assuming your null hypothesis was true). We use the bootstrap to loop through a large number of \"resamples\". In each iteration of the loop, we impose the null hypothesis and re-estimate the statistic of interest. We then calculate the range of the statistic across all resamples and compare how extreme the original value we observed is. We use a 95% confidence interval of the null distribution to create a *rejection region*.\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_dat <- USArrests$Murder\nsample_mean <- mean(sample_dat)\n\n# Bootstrap NULL: mean=8\nset.seed(1)\nBmeans0 <- sapply(1:10^4, function(i) {\n    dat_b <- sample(sample_dat, replace=T) \n    mean_b <- mean(dat_b) + (8 - sample_mean) # impose the null by recentering\n    return(mean_b)\n})\nhist(Bmeans0, breaks=25, border=NA,\n    main='', xlab=expression( bar(X)[b]) )\nci_95 <- quantile(Bmeans0, probs=c(.025, .975)) # critical region\nabline(v=ci_95, lwd=2)\nabline(v=sample_mean, lwd=2, col=2)\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n## Default Statistics\n\n#### **p-values**.{-}\nThis is the frequency you would see something as extreme as your statistic when sampling from the null distribution.\n\nThere are three associated tests: the two-sided test (observed statistic is extremely high or low) or one of the one-sided tests (observed statistic is extremely low, observed statistic is extremely high). E.g.\n\n* $HA​: \\bar{X} > 8$ implies a right tail test\n* $HA: \\bar{X} < 8$ implies a left tail test\n* $HA​: \\bar{X} \\neq 8$ implies a two tail test\n\nIn any case, typically \"p<.05: statistically significant\" and \"p>.05: not statistically significant\".\n\n\nOne sided example\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-Sided Test, ALTERNATIVE: mean > 8\n# Prob( boot0_means > sample_mean) \nFhat0 <- ecdf(Bmeans0) # Right tail\nplot(Fhat0,\n    xlab=expression( beta[b] ),\n    main='Null Bootstrap Distribution for means', font.main=1)\nabline(v=sample_mean, col='red')\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- 1- Fhat0(sample_mean) #Right Tail\nif(p >.05){\n    message('fail to reject the null that sample_mean=8, at the 5% level')\n} else {\n    message('reject the null that sample_mean=8 in favor of >8, at the 5% level')\n}\n```\n:::\n\n\nTwo sided example\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-Sided Test, ALTERNATIVE: mean < 8 or mean >8\n# Prob(boot0_means > sample_mean or -boot0_means < sample_mean)\n\nFhat0 <- ecdf(Bmeans0)\np_left <- Fhat0(sample_mean) #Left Tail\np_right <- 1 - Fhat0(sample_mean) #Right Tail\np <- 2*min(p_left, p_right)\n\nif(p >.05){\n    message('fail to reject the null that sample_mean=8 at the 5% level')\n} else {\n    message('reject the null that sample_mean=8 in favor of either <8 or >8 at the 5% level')\n}\n```\n:::\n\n\n\n#### **t-values**. {-}\nA t-value standardizes the statistic you are using for hypothesis testing:\n$$ t = (\\hat{\\mu} - \\mu_{0}) / \\hat{s_{\\mu}} $$\n\n::: {.cell}\n\n```{.r .cell-code}\njack_se <- sd(Jmeans)\nmean0 <- 8\njack_t <- (sample_mean - mean0)/jack_se\n\n# Note that you can also use a corrected se\n# jack_se <- sqrt((n-1)/n) * sd(Jmeans)\n```\n:::\n\nThere are several benefits to this:\n\n* makes the statistic comparable across different studies\n* makes the null distribution not depend on theoretical parameters ($\\sigma$)\n* makes the null distribution theoretically known asymptotically (approximately)\n\nThe last point implies we are dealing with a symmetric distributions: $Prob( t_{boot} > t ~\\text{or}~ t_{boot} < -t) = Prob( |t| < |t_{boot}| )$.^[In another statistics class, you will learn the math behind the null t-distribution. In this class, we skip this because we can simply bootstrap the t-statistic too.]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nboot_t0 <- sapply(1:10^3, function(i) {\n    dat_b <- sample(sample_dat, replace=T) \n    mean_b <- mean(dat_b) + (8 - sample_mean) # impose the null by recentering\n    # jack ses\n    jack_se_b <- sd( sapply(1:length(dat_b), function(i){\n        mean(dat_b[-i])\n    }) )\n    jack_t <- (mean_b - mean0)/jack_se_b\n})\n\n# Two Sided Test\nFhat0 <- ecdf(abs(boot_t0))\nplot(Fhat0, xlim=range(boot_t0, jack_t),\n    xlab=expression( abs(hat(t)[b]) ),\n    main='Null Bootstrap Distribution for t', font.main=1)\nabline(v=abs(jack_t), col='red')\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\np <- 1 - Fhat0( abs(jack_t) ) \np\n## [1] 0.727\n\nif(p >.05){\n    message('fail to reject the null that sample_mean=8, at the 5% level')\n} else {\n    message('reject the null that sample_mean=8 in favor of either <8 or >8, at the 5% level')\n}\n```\n:::\n\n\n\n## Two-Sample Differences\n\nSuppose we have 2 samples of data. \n\nEach $X_{is}$ is an individual observation $i$ from the sample $s=1,2$. (For example, the wages for men and women in Canada. For another example, homicide rates in two different American states.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(wooldridge)\nx1 <- wage1[wage1$educ == 15, 'wage']\nx2 <- wage1[wage1$educ == 16, 'wage']\n```\n:::\n\n\nFor simplicity, we will assume that each observation is an independent observation. We will further assume the data from each group are normally distributed, but the mean and variance can be different across groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample 1 (e.g., males)\nn1 <- 100\nx1 <- rnorm(n1, 0, 2)\n# Sample 2 (e.g., females)\nn2 <- 80\nx2 <- rnorm(n2, 1, 1)\n\npar(mfrow=c(1,2))\nbks <- seq(-7,7, by=.5)\nhist(x1, border=NA, breaks=bks,\n    main='Sample 1', font.main=1)\n\nhist(x2, border=NA, breaks=bks, \n    main='Sample 2', font.main=1)\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\nThere may be several differences between these samples. Often, the first summary statistic we investigate is the difference in means. \n\n#### **Equal Means**. {-}\nWe often want to know if the means of different sample are different in . To test this hypothesis, we compute the sample mean $\\overline{X}_{s}$ over all observations in each sample and then examine the differences term\n\\begin{eqnarray} \nD = \\overline{X}_{1} - \\overline{X}_{2},\n\\end{eqnarray}\nwith a null hypothesis of $D=0$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Differences between means\nm1 <- mean(x1)\nm2 <- mean(x2)\nd <- m1-m2\n    \n# Bootstrap Distribution\nboot_d <- sapply(1:10^4, function(b){\n    x1_b <- sample(x1, replace=T)\n    x2_b <- sample(x2, replace=T)\n    m1_b <- mean(x1_b)\n    m2_b <- mean(x2_b)\n    d_b <- m1_b - m2_b\n    return(d_b)\n})\nhist(boot_d, border=NA, font.main=1,\n    main='Difference in Means')\n\n# 2-Sided Test\nboot_ci <- quantile(boot_d, probs=c(.025, .975))\nabline(v=boot_ci, lwd=2)\nabline(v=0, lwd=2, col=2)\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# p-value\n1 - ecdf(boot_d)(0)\n## [1] 0\n```\n:::\n\n\n***Standardized Differences.***\nJust as with one sample tests, we can standardize $D$ into a $t$ statistic. In which case, we can easily compute one or two sided hypothesis tests. Note, however, that we have to compute the standard error for the difference statistic, which is a bit more complicated. \n\n::: {.cell}\n\n```{.r .cell-code}\nse_hat <- sqrt(var(x1)/n1 + var(x2)/n2);\nt_obs <- d/se_hat\n```\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n\n#### **Other Differences**. {-}\nThe above procedure generalized from differences in \"means\" to other statistics like \"quantiles\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bootstrap Distribution Function\nboot_fun <- function( fun, B=10^4, ...){\n    boot_d <- sapply(1:B, function(b){\n        x1_b <- sample(x1, replace=T)\n        x2_b <- sample(x2, replace=T)\n        f1_b <- fun(x1_b, ...)\n        f2_b <- fun(x2_b, ...)\n        d_b <- f1_b - f2_b\n        return(d_b)\n    })\n    return(boot_d)\n}\n\n# 2-Sided Test for Median Differences\n# d <- median(x2) - median(x1)\nboot_d <- boot_fun(median)\nhist(boot_d, border=NA, font.main=1,\n    main='Difference in Medians')\nabline(v=quantile(boot_d, probs=c(.025, .975)), lwd=2)\nabline(v=0, lwd=2, col=2)\n```\n\n::: {.cell-output-display}\n![](01_07_HypothesisTests_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n1 - ecdf(boot_d)(0)\n## [1] 0\n```\n:::\n\n\nNote that these estimates suffer from a finite-sample bias, which we can correct for. Also note that bootstrap tests can perform poorly with highly unequal variances or skewed data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 2-Sided Test for SD Differences\n#d <- sd(x2) - sd(x1)\nboot_d <- boot_fun(sd)\nhist(boot_d, border=NA, font.main=1,\n    main='Difference in Standard Deviations')\nabline(v=quantile(boot_d, probs=c(.025, .975)), lwd=2)\nabline(v=0, lwd=2, col=2)\n1 - ecdf(boot_d)(0)\n\n\n# Try any function!\n# boot_fun( function(xs) { IQR(xs)/median(xs) } )\n```\n:::\n\n\n## Further Reading\n\n* https://learningstatisticswithr.com/book/hypothesistesting.html\n* https://okanbulut.github.io/rbook/part5.html\n",
    "supporting": [
      "01_07_HypothesisTests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}