{
  "hash": "18c4c8a9edf2939ea79c871f1fe4f055",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Random Variables\n***\n\nIn the last section we computed a distribution given the data, whereas now we generate individual data points given the distribution. \n\nRandom variables are vectors whose values occur according to a frequency distribution. As such, random variables have a\n\n* *sample space* which refers to the set of all possible outcomes, and\n* *probability* for each particular set of outcomes, which is the proportion that those outcomes occur in the long run.\n\nThere are two basic types of sample spaces: discrete (encompassing cardinal-discrete, factor-ordered, and factor-unordered data) and continuous. This leads to two types of random variables: discrete and continuous.  However, each type has many different \n[probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions).\n\n#### **Probability**. {-}\nThe most common random variables are [easily accessible](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Distributions.html) and can be described using the Cumulative Distribution Function (CDF)\n\\begin{eqnarray}\nF(x) &=& Prob(X_{i} \\leq x).\n\\end{eqnarray}\nNote that this is just like the empirical ECDF, $\\widehat{F}(x)$, except that it is now theoretically known. You can think of $F(x)$ as the ECDF for a dataset with an infinite number of observations.\n\nAfter introducing different random variables, we will also cover some basic implications of their CDF. Intuitively, probabilities must sum up to one. So we can compute $Prob(X_{i} > x) = 1- F(x)$. We also have two \"in\" and \"out\" probabilities.\n\nThe probability of $X_{i}\\leq b$ and $X_{i}\\geq a$ can be written in terms of falling into a range $Prob(X_{i} \\in [a,b])=Prob(a \\leq X_{i} \\leq b) = F(b) - F(a)$. \n\nThe opposite probability of $X_{i} > b$ or $X_{i} < a$ is $Prob(X_{i} < a \\text{ or } X_{i} > b) = F(a) + [1- F(b)]$. Notice that this opposite probability $F(a) + [1- F(b)] =1 - [F(b) - F(a)]$, so that $Prob(X_{i} \\text{ out of } [a,b]) = 1 - Prob( X_{i} \\in [a,b])$\n\n\n## Discrete\nA discrete random variable can take one of several values in a set. E.g., any number in $\\{1,2,3,...\\}$ or any letter in $\\{A,B,C,...\\}$. Theoretical proportions are referred to as a *probability mass function*.\n\n#### **Bernoulli**. {-}\nThink of a Coin Flip: Heads=1 or Tails=0, with equal probability. In general, the probability of heads can vary.\n\\begin{eqnarray}\nX_{i} &\\in& \\{0,1\\} \\\\\nProb(X_{i} =0) &=& 1-p \\\\\nProb(X_{i} =1) &=& p \\\\\nF(x) &=& \\begin{cases}\n    0   & x<0 \\\\\n    1-p & x \\in [0,1) \\\\\n    1   & x\\geq 1\n\\end{cases}\n\\end{eqnarray}\n\nHere is an example of the [Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_distribution) distribution\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(0,1)\nx_probs <- c(3/4, 1/4)\n\nsample(x, 1, prob=x_probs, replace=T) # 1 Flip\n## [1] 0\nsample(x, 4, prob=x_probs, replace=T) # 4 Flips \n## [1] 1 0 0 0\nX0 <- sample(x, 400, prob=x_probs, replace=T)\n\n# Plot Cumulative Proportion\nX0_t <- seq_len(length(X0)) #head(X0_t)\nX0_mt <- cumsum(X0)/X0_t #head(X0_mt)\npar(mar=c(4,4,1,4))\nplot(X0_t, X0_mt, type='l',\n    ylab='Cumulative Proportion (p)',\n    xlab='Flip #', \n    ylim=c(0,1), \n    lwd=2)\n# Show individual flip outcomes\npoints(X0_t, X0, col=grey(0,.5),\n    pch='|', cex=.3)\n# Show theoretical proportions\nabline(h=0.25, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Plot Long run proportions\nproportions <- table(X0)/length(X0)\nplot(proportions, col=grey(0,.5),\n    xlab='Flip Outcome', ylab='Proportion', main=NA)\npoints(c(0,1), c(.75, .25), pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Plot CDF\nplot( ecdf(X0), col=grey(0,.5),\n    pch=16, main=NA) #Empirical\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#points(c(0,1), c(.75, 1), pch=16, col='blue') # Theoretical\n```\n:::\n\n\n\n#### **Discrete Uniform**. {-}\nDiscrete numbers with equal probability\n\\begin{eqnarray}\nX_{i} &\\in& \\{1,...N\\} \\\\\nProb(X_{i} =1) &=& Prob(X_{i} =2) = ... = 1/N\\\\\nF(x) &=& \\begin{cases}\n    0   & x<1 \\\\\n    1/N & x \\in [1,2) \\\\\n    2/N & x \\in [2,3) \\\\\n    \\vdots & \\\\\n    1   & x\\geq N\n\\end{cases}\n\\end{eqnarray}\n\n:::{.callout-note icon=false collapse=\"true\"}\nHere is an example with $N=4$. \n\nThe probability of a value smaller than or equal to $3$ is $Prob(X_{i} \\leq 3)=1/4 + 1/4 + 1/4 = 3/4$.\n\nThe probability of a value larger than $3$ is $Prob(X_{i} > 3) = 1-Prob(X_{i} \\leq 3)=1/4$.\n\nThe probability of a value of a value $>$ 1 and $\\leq 3$ is $Prob(1 < X_{i} \\leq 3) = Prob(X_{i} \\leq 3) - \\left[ 1- Prob(X_{i} \\leq 1) \\right] = 3/4 - 1/4 = 2/4$.^[This is the general formula using CDFs, and you can verify it works in this instance by directly adding the probability of each 2 or 3 event: $Prob(X_{i} = 2) +  Prob(X_{i} = 3) = 1/4 + 1/4 = 2/4$.]\n\nThe probability of a value of a value $\\leq$ 1 or $> 3$ is $Prob(X_{i} \\leq 1 \\text{ or } X_{i} > 3) =  Prob(X_{i} \\leq 1) +  \\left[ 1- Prob(X_{i} \\leq 3) \\right] = 1/4 + [1 - 3/4]=2/4$.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c(1,2,3,4)\nx_probs <- c(1/4, 1/4, 1/4, 1/4)\n# sample(x, 1, prob=x_probs, replace=T) # sample of 1\nX1 <- sample(x, 2000, prob=x_probs, replace=T)\n\n# Plot Long run proportions\nproportions <- table(X1)/length(X1)\nplot(proportions, col=grey(0,.5),\n    xlab='Outcome', ylab='Proportion', main=NA)\npoints(x, x_probs, pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Hist w/ Theoretical Counts\n# hist(X1, breaks=50, border=NA, main=NA, ylab='Count')\n# points(x, x_probs*length(X1), pch='-') \n\n# Alternative Plot\nplot( ecdf(X1), pch=16, col=grey(0,.5), main=NA)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Alternative Plot 2\n#props <- table(X1)\n#barplot(props, ylim = c(0, 0.35), ylab = \"Proportion\", xlab = \"Value\")\n#abline(h = 1/4, lty = 2)\n```\n:::\n\n        \nNote that the [Discrete Uniform](https://en.wikipedia.org/wiki/Discrete_uniform_distribution) distribution generalizes to arbitrary intervals, although we will not exploit the generalization in this class.\n\n#### **Multinoulli (aka Categorical)**. {-}\nNumbers 1,...N with unequal probabilities.\n\\begin{eqnarray}\nX_{i} &\\in& \\{1,...N\\} \\\\\nProb(X_{i} =1) &=& p_{1} \\\\\nProb(X_{i} =2) &=& p_{2} \\\\\n        &\\vdots& \\\\\np_{1} + p_{2} + ... &=& 1\\\\\nF(x) &=& \\begin{cases}\n    0   & x<1 \\\\\n    p_{1} & x \\in [1,2) \\\\\n    p_{1} + p_{2} & x \\in [2,3) \\\\\n    \\vdots & \\\\\n    1   & x\\geq N\n\\end{cases}\n\\end{eqnarray}\n\nWe can also replace numbers with letters (A,...Z) or names (John, Jamie, ...) although we must be careful with the CDF when there is no longer a natural ordering. Here is an empirical example with three outcomes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c('A', 'B', 'C')\nx_probs <- c(3/10, 1/10, 6/10)\nsum(x_probs)\n## [1] 1\nX2 <- sample(x, 2000, prob=x_probs, replace=T) # sample of 2000\n\n# Plot Long run proportions\nproportions <- table(X2)/length(X2)\nplot(proportions, col=grey(0,.5),\n    xlab='Outcome', ylab='Proportion', main=NA)\npoints(x_probs, pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Histogram version\n# X2_alt <- X1\n# X2_alt[X2_alt=='A'] <- 1\n#X2_alt[X2_alt=='B'] <- 2\n#X2_alt[X2_alt=='C'] <- 3\n#X2_alt <- as.numeric(X1_alt)\n#hist(X2_alt, breaks=50, border=NA, \n#    main=NA, ylab='Count')\n#points(x, x_probs*length(X2_alt), pch=16) ## Theoretical Counts\n\n# Alternative Plot\n# plot( ecdf(X2), pch=16, col=grey(0,.5), main=NA)\n```\n:::\n\n\n:::{.callout-note icon=false collapse=\"true\"}\nAn experiment with three possible outcomes, {E1, E2, E3}. It was repeated 50 times and discovered that E1 occurred 10 times, E2 occurred 13 times, and E3 occurred 27 times. Estimate the probability of each outcome. Then estimate Prob(E1 or E2), Prob(E2 or E3), and Prob(E1 or E3).\n:::\n\n## Continuous\nA continuous random variable can take one value out of an uncountably infinite number. E.g., any number between $0$ and $1$ with any number of decimal points. With a continuous random variable, the probability of any individual point is zero, so we describe these variables with the cumulative distribution function (CDF), $F$, or the probability density function (PDF), $f$. Just as $F$ can be thought of as the ECDF $\\widehat{F}$ with an infinite amount of data, $f$ can be thought of as a histogram $\\widehat{f}$ with an infinite amount of data. Often, the PDF helps you intuitively understand a random variable whereas the CDF helps you calculate numerical values.\n\n#### **Continuous Uniform**. {-}\nAny number on a unit interval allowing for any number of decimal points, with every interval of the same size having the same probability.\n\\begin{eqnarray}\nX_{i} &\\in& [0,1] \\\\\nf(x) &=& \\begin{cases}\n    1 & x \\in [0,1] \\\\\n    0 & \\text{Otherwise}\n\\end{cases}\\\\\nF(x) &=& \\begin{cases} \n    0 & x < 0 \\\\\n    x & x \\in [0,1] \\\\\n    1 & x > 1.\n\\end{cases}\n\\end{eqnarray}\n\n:::{.callout-note icon=false collapse=\"true\"}\nThe probability of a value being exactly $0.25$ is $Prob(X_{i} =0.25)=0$.\n\nThe probability of a value smaller that $0.25$ is $F(0.25)=0.25$.\n\nThe probability of a value larger than $0.25$ is $1-F(0.25)=0.75$.\n\nThe probability of a value in $(0.25,0.75]$ is $Prob(0.25 < X_{i} \\leq 0.75) = Prob(X_{i} \\leq 0.75) - \\left[ 1- Prob(X_{i} \\leq 0.25) \\right] = 0.75 - 0.25 = 0.5$. \n\nThe probability of a value in $(0.2,0.7]$ is $Prob(0.2 < X_{i} \\leq 0.7) = Prob(X_{i} \\leq 0.7) - \\left[ 1- Prob(X_{i} \\leq 0.2) \\right] = 0.7 - 0.2 = 0.5$.\n\nThe probability of a value outside of $(0.2,0.7]$ is $Prob(X_{i} \\leq 0.2 \\text{ or } x > 0.7) = 0.2 + [1-0.7]=0.5$.\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrunif(3) # 3 draws\n## [1] 0.3896691 0.2178243 0.6273801\n\n# Empirical Density \nX3 <- runif(2000)\nhist(X3, breaks=20, border=NA, main=NA, freq=F)\n# Theoretical Density\nx <- seq(0,1,by=.01)\nfx <- dunif(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# CDF examples\nP_low <- punif(0.25)\nP_low\n## [1] 0.25\nP_high <- 1-punif(0.25)\nP_high\n## [1] 0.75\nP_mid <- punif(0.75) - punif(0.25)\nP_mid\n## [1] 0.5\n```\n:::\n\n\n\nNote that the [Continuous Uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) distribution generalizes to an arbitrary interval, $X_{i} \\in [a,b]$. In this case, $f(x)=1/[b-a]$ if $x \\in [a,b]$ and $F(x)=[x-a]/[b-a]$ if $x \\in [a,b]$.\n\n:::{.callout-note icon=false collapse=\"true\"}\nWhat is the probability of a value larger than $0.25$ when $a=-b=2$? First use the computer to suggest an answer and then show the answer mathematically. Verify the answer is intuitively correct in figures for the PDF and for the CDF, with correct axes labels and marks.\n:::\n\n:::{.callout-note icon=false collapse=\"true\"}\nSuppose the flight time (in minutes) between Calgary and Kamloops has Uniform distribution with parameters a = 68 and b = 78. According to Air Canada the flight takes 70 minutes. What is the probability that the flight will be late? What is the probability that a flight takes between 65 and 70 minutes?\n:::\n\n#### **Beta**. {-}\nThe sample space is any number on the unit interval, $X_{i} \\in [0,1]$, but with non-uniform probabilities. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX4 <- rbeta(2000,2,2) ## two shape parameters\nhist(X4, breaks=20, border=NA, main=NA, freq=F)\n\n#See the underlying probabilities\n#f_25 <- dbeta(.25, 2, 2)\n\nx <- seq(0,1,by=.01)\nfx <- dbeta(x, 2, 2)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThe [Beta](https://en.wikipedia.org/wiki/Beta_distribution) distribution is mathematically complicated to write, and so we omit it. However, we can find the probability graphically using either the probability density function or cumulative distribution function. \n\n:::{.callout-tip icon=false collapse=\"true\"}\nSuppose $X_{i}$ is a random variable with a beta distribution. Intuitively depict $Prob(X_{i} \\in [0.2, 0.8])$ by drawing an area under the density function. Numerically estimate that same probability using the CDF.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( ecdf(X4), main=NA) # Empirical\n\nx <- seq(0,1,by=.01) # Theoretical\nFx <- pbeta(x, 2, 2)\nlines(x, Fx, col='blue')\n\n# Middle Interval Example \nF2 <- pbeta(0.2, 2, 2)\nF8 <- pbeta(0.8, 2, 2)\nF_2_8 <- F8 - F2\nF_2_8\n## [1] 0.792\n\n# Visualize\ntitle('Middle between 0.2 and 0.8')\nsegments( 0.2, F2, -1, F2, col='red')\nsegments( 0.8, F8, -1, F8, col='red')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n:::\n\nThis distribution is often used, as the probability density function has two parameters that allow it to take many different shapes.\n\n:::{.callout-tip icon=false collapse=\"true\"}\nFor each example below, intuitively depict $Prob(X_{i} \\leq 0.5)$ using the PDF. Repeat the exercise using a CDF instead of a PDF to calculate a numerical value.\n\n::: {.cell}\n\n```{.r .cell-code}\nop <- par(no.readonly = TRUE); on.exit(par(op), add = TRUE)\nx <- seq(0,1,by=.01)\npars <- expand.grid( c(.5,1,2), c(.5,1,2) )\npar(mfrow=c(3,3))\napply(pars, 1, function(p){\n    fx <- dbeta( x,p[1], p[2])\n    plot(x, fx, type='l', xlim=c(0,1), ylim=c(0,4), lwd=2, col='blue')\n    #hist(rbeta(2000, p[1], p[2]), breaks=50, border=NA, main=NA, freq=F)\n})\ntitle('Beta densities', outer=T, line=-1)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-7-1.png){width=768}\n:::\n:::\n\n:::\n\n#### **Exponential**. {-}\nThe sample space is any positive number.^[In other classes, you may further distinguish types of random variables based on whether their maximum value is theoretically finite or infinite.] An [Exponential](https://en.wikipedia.org/wiki/Exponential_distribution) random variable has a single parameter, $\\lambda>0$, that governs its shape\n\\begin{eqnarray}\nX_{i} &\\in& [0,\\infty) \\\\\nf(x) &=& \\lambda exp\\left\\{ -\\lambda x \\right\\} \\\\\nF(x) &=& \\begin{cases} \n    0 & x < 0 \\\\\n    1-  exp\\left\\{ -\\lambda x \\right\\} & x \\geq 0.\n\\end{cases}\n\\end{eqnarray}\n\n::: {.cell}\n\n```{.r .cell-code}\nrexp(3) # 3 draws\n## [1] 0.03679114 3.92672936 1.38630412\n\nX5 <- rexp(2000)\nhist(X5, breaks=20,\n    border=NA, main=NA,\n    freq=F, ylim=c(0,1), xlim=c(0,10))\n    \nx <- seq(0,10,by=.1)\nfx <- dexp(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nSuppose the lifetime of a battery is an exponential random variable with $\\lambda=1/50$. Using the computer, find the probability that the lifetime is $< 10$ hours.\nFind the probability that the lifetime is $\\geq 100$ hours. Use the computer to find the probability that the lifetime is between $10$ and $100$ hours.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npexp(10, 1/50)\n## [1] 0.1812692\n```\n:::\n\n:::\n\n#### **Normal (Gaussian)**. {-}\nThis distribution is for any number on the real line, with bell shaped probabilities. The [Normal](https://en.wikipedia.org/wiki/Normal_distribution) distribution is mathematically complex and sometimes called the Gaussian distribution. We call it \"Normal\" because we will encounter it again and again and again. The probability density function $f$ has two parameters $\\mu \\in (\\infty,\\infty)$ and $\\sigma > 0$.\n\\begin{eqnarray}\nX_{i} &\\in& (\\infty,\\infty) \\\\\nf(x) &=& \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left\\{ \\frac{-(x-\\mu)^2}{2\\sigma^2} \\right\\}\n\\end{eqnarray}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrnorm(3) # 3 draws\n## [1] -0.93801119 -0.28138608  0.06381353\n\nX6 <- rnorm(2000)\nhist(X6, breaks=20,\n    border=NA, main=NA,\n    freq=F, ylim=c(0,.4), xlim=c(-4,4))\n\nx <- seq(-10,10,by=.025)\nfx <- dnorm(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nEven thought the distribution function is complex, we can compute CDF values using the computer.\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm( c(-1.645, 1.645) ) # 10%\n## [1] 0.04998491 0.95001509\npnorm( c(-2.576, 2.576) ) #  1%\n## [1] 0.004997532 0.995002468\n```\n:::\n\n\n\n:::{.callout-note icon=false collapse=\"true\"}\nSuppose $X_{i}$ is a random variable with a normal distribution with $\\mu=0$ and $\\sigma=1$. Intuitively depict $Prob(X_{i} \\in [0.2, 0.8])$ by drawing an area under the density function. Numerically estimate that same probability using the CDF.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( ecdf(X6), main=NA) # Empirical\n\nx <- seq(0,1,by=.01) # Theoretical\nFx <- pnorm(x, 0, 1)\nlines(x, Fx, col='blue')\n\n# Middle Interval Example \nF2 <- pnorm(0.2, 0, 1)\nF8 <- pnorm(0.8, 0, 1)\nF_2_8 <- F8 - F2\nF_2_8\n## [1] 0.2088849\n\n# Visualize\ntitle('Middle between 0.2 and 0.8')\nsegments( 0.2, F2, -5, F2, col='red')\nsegments( 0.8, F8, -5, F8, col='red')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n:::\n\n:::{.callout-tip icon=false collapse=\"true\"}\nDraw the Middle 90% of a normal distribution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# PDF\nx <- seq(-10,10,by=.025)\nfx <- dnorm(x)\nplot(x, fx, col='blue', type='l', main='Middle 90%')\n# Show Middle 90%\nx_90 <- seq(-1.645,1.645,by=.025)\nfx_90 <- dnorm(x_90)\npolygon( c(x_90, rev(x_90)), c(fx_90,fx_90*0),\n    col=rgb(0,0,1,.25), border=NA)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\npnorm(1.645)-pnorm(-1.645)\n## [1] 0.9000302\n```\n:::\n\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nSuppose scores in math class are approximately normally distributed with $\\mu=50, \\sigma=1$. If you selected one student randomly, what is the probability their score is higher than $90$. Is $Prob(X_{i}\\geq 90)$ higher if $\\mu=25, \\sigma=2$?\n:::\n\n## Further Reading\n\nNote that many random variables are related to each other\n\n* <https://en.wikipedia.org/wiki/Relationships_among_probability_distributions>\n* <https://www.math.wm.edu/~leemis/chart/UDR/UDR.html>\n* <https://qiangbo-workspace.oss-cn-shanghai.aliyuncs.com/2018-11-11-common-probability-distributions/distab.pdf>\n\nAlso note that numbers randomly generated on your computer cannot be truly random, they are \"Pseudorandom\".\n\n",
    "supporting": [
      "01_04_RandomVariables_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}