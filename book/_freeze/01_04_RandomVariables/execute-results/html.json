{
  "hash": "9f1fc7b016c200c9c8fd86f42771b122",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Random Variables\n***\n\nIn the last section we computed a distribution given the data, whereas now we generate data given the distribution. \n\nRandom variables are vectors that are generated from a known Cumulative Distribution Function or Probability Distribution Function, which describes the long run frequencies of all possible outcomes. Random variables have a\n\n* *sample space* which refers to the set of all possible outcomes, and\n* *probability* for each particular set of outcomes, which is the proportion that those outcomes occur in the long run.\n\nThere are only two basic types of sample spaces: discrete (encompassing cardinal-discrete, factor-ordered, and factor-unordered data) and continuous, which lead to two types of random variables. In any case, probabilities must sum up to 1.\n\nHowever, each type of random variable has many different \n[probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions). The most common ones are [easily accessible](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/Distributions.html) and can be described using the Cumulative Distribution Function\n\\begin{eqnarray}\nF(x) &=& Prob(X_{i} \\leq x).\n\\end{eqnarray}\nNote that this is just like the ECDF, $\\widehat{F}(x)$, except that it is now theoretically known instead of estimated.^[Alternatively, you can think of $F(x)$ as the ECDF for a dataset with an infinite number of observations.]  \n\nAfter introducing different random variables, we will also cover some basic implications of their CDF. Generally, we have $Prob(X_{i} > x) = 1- F(x)$. We also have two \"in\" and \"out\" probabilities.\n\nThe probability of $X_{i}\\leq b$ and $X_{i}\\geq a$ can be written in terms of falling into a range $Prob(X_{i} \\in [a,b])=Prob(a \\leq X_{i} \\leq b) = F(b) - F(a)$. \n\nThe opposite probability of $X_{i} > b$ or $X_{i} < a$ is $Prob(X_{i} < a \\text{ or } X_{i} > b) = F(a) + [1- F(b)]$. Notice that this opposite probability $F(a) + [1- F(b)] =1 - [F(b) - F(a)]$, so that $Prob(X_{i} \\text{ out of } [a,b]) = 1 - Prob( X_{i} \\in [a,b])$\n\n\n## Discrete\nThe random variable can take one of several values in a set. E.g., any number in $\\{1,2,3,...\\}$ or any letter in $\\{A,B,C,...\\}$.\n\n#### **Bernoulli**. {-}\nThink of a Coin Flip: Heads=1 or Tails=0, with equal probability. In general, the probability of heads can vary.\n\\begin{eqnarray}\nX_{i} &\\in& \\{0,1\\} \\\\\nProb(X_{i} =0) &=& 1-p \\\\\nProb(X_{i} =1) &=& p \\\\\nF(x) &=& \\begin{cases}\n    0   & x<0 \\\\\n    1-p & x \\in [0,1) \\\\\n    1   & x\\geq 1\n\\end{cases}\n\\end{eqnarray}\n\nHere is an example of the [Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_distribution) distribution\n\n::: {.cell}\n\n```{.r .cell-code}\nrbinom(1, 1, 0.25) # 1 Flip\n## [1] 1\nrbinom(4, 1, 0.25) # 4 Flips\n## [1] 0 0 1 0\nX0 <- rbinom(400, 1, 0.25)\n\n# Plot Cumulative Proportion\nX0_t <- seq_len(length(X0)) #head(X0_t)\nX0_mt <- cumsum(X0)/X0_t #head(X0_mt)\npar(mar=c(4,4,1,4))\nplot(X0_t, X0_mt, type='l',\n    ylab='Cumulative Proportion (p)',\n    xlab='Flip #', \n    ylim=c(0,1), \n    lwd=2)\n# Add individual flip outcomes\npoints(X0_t, X0, col=grey(0,.5),\n    pch='|', cex=.3)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Plot Long run proportions\nproportions <- table(X0)/length(X0)\nplot(proportions, col=grey(0,.5),\n    xlab='Flip Outcome', ylab='Count', main=NA)\npoints(c(0,1), c(.75, .25), pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Plot CDF\nplot( ecdf(X0), pch=16, col=grey(0,.5), main=NA) #Empirical\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-1-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#points(c(0,1), c(.75, 1), pch=16, col='blue') # Theoretical\n```\n:::\n\n\n\n#### **Discrete Uniform**. {-}\nDiscrete numbers with equal probability\n\\begin{eqnarray}\nX_{i} &\\in& \\{1,...N\\} \\\\\nProb(X_{i} =1) &=& Prob(X_{i} =2) = ... = 1/N\\\\\nF(x) &=& \\begin{cases}\n    0   & x<1 \\\\\n    1/N & x \\in [1,2) \\\\\n    2/N & x \\in [2,3) \\\\\n    \\vdots & \\\\\n    1   & x\\geq N\n\\end{cases}\n\\end{eqnarray}\n\nHere is an example with $N=4$. \n\nThe probability of a value smaller than or equal to $3$ is $Prob(X_{i} \\leq 3)=1/4 + 1/4 + 1/4 = 3/4$.\n\nThe probability of a value larger than $3$ is $Prob(X_{i} > 3) = 1-Prob(X_{i} \\leq 3)=1/4$.\n\nThe probability of a value of a value $>$ 1 and $\\leq 3$ is $Prob(1 < X_{i} \\leq 3) = Prob(X_{i} \\leq 3) - \\left[ 1- Prob(X_{i} \\leq 1) \\right] = 3/4 - 1/4 = 2/4$.^[This is the general formula using CDFs, and you can verify it works in this instance by directly adding the probability of each 2 or 3 event: $Prob(X_{i} = 2) +  Prob(X_{i} = 3) = 1/4 + 1/4 = 2/4$.]\n\nThe probability of a value of a value $\\leq$ 1 or $> 3$ is $Prob(X_{i} \\leq 1 \\text{or} X_{i} > 3) =  Prob(X_{i} \\leq 1) +  \\left[ 1- Prob(X_{i} \\leq 3) \\right] = 1/4 + [1 - 3/4]=2/4$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- 1:4\nx_probs <- rep(1/4,4)\n# sample(x, 1, replace=T, prob=x_probs) # sample of 1\nX1 <- sample(x, 2000, replace=T, prob=rep(1/4,4))\n\n# Plot Long run proportions\nproportions <- table(X1)/length(X1)\nplot(proportions, col=grey(0,.5),\n    xlab='Outcome', ylab='Proportion', main=NA)\npoints(x, x_probs, pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Hist w/ Theoretical Counts\n# hist(X1, breaks=50, border=NA, main=NA, ylab='Count')\n# points(x, x_probs*length(X1), pch='-') \n\n# Alternative Plot\nplot( ecdf(X1), pch=16, col=grey(0,.5), main=NA)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Alternative Plot 2\n#props <- table(X1)\n#barplot(props, ylim = c(0, 0.35), ylab = \"Proportion\", xlab = \"Value\")\n#abline(h = 1/4, lty = 2)\n```\n:::\n\n        \nNote that the [Discrete Uniform](https://en.wikipedia.org/wiki/Discrete_uniform_distribution) distribution generalizes to arbitrary intervals, although we will not exploit the generalization in this class.\n\n#### **Multinoulli (aka Categorical)**. {-}\nNumbers 1,...N with unequal probabilities.\n\\begin{eqnarray}\nX_{i} &\\in& \\{1,...N\\} \\\\\nProb(X_{i} =1) &=& p_{1} \\\\\nProb(X_{i} =2) &=& p_{2} \\\\\n        &\\vdots& \\\\\np_{1} + p_{2} + ... &=& 1\\\\\nF(x) &=& \\begin{cases}\n    0   & x<1 \\\\\n    p_{1} & x \\in [1,2) \\\\\n    p_{1} + p_{2} & x \\in [2,3) \\\\\n    \\vdots & \\\\\n    1   & x\\geq N\n\\end{cases}\n\\end{eqnarray}\n\nWe can also replace numbers with letters (A,...Z) or names (John, Jamie, ...) although we must be careful with the CDF when there is no longer a natural ordering. Here is an empirical example with three outcomes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- c('A', 'B', 'C')\nx_probs <- c(3,6,1)/10\nsum(x_probs)\n## [1] 1\nX1 <- sample(x, 2000, replace=T, prob=x_probs) # sample of 2000,\n\n# Plot Long run proportions\nproportions <- table(X1)/length(X1)\nplot(proportions, col=grey(0,.5),\n    xlab='Outcome', ylab='Proportion', main=NA)\npoints(x_probs, pch=16, col='blue') # Theoretical values\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Histogram version\n# X1_alt <- X1\n# X1_alt[X1_alt=='A'] <- 1\n#X1_alt[X1_alt=='B'] <- 2\n#X1_alt[X1_alt=='C'] <- 3\n#X1_alt <- as.numeric(X1_alt)\n#hist(X1_alt, breaks=50, border=NA, \n#    main=NA, ylab='Count')\n#points(x, x_probs*length(X1_alt), pch=16) ## Theoretical Counts\n\n# Alternative Plot\n# plot( ecdf(X1), pch=16, col=grey(0,.5), main=NA)\n```\n:::\n\n\nAn experiment with three possible outcomes (E1, E2, E3) has been repeated 50 times, and it was learned that E1 occurred 10 times, E2 occurred 13 times, and E3 occurred 27 times. Assign probabilities to the outcomes.\n \n## Continuous\nThe random variable can take one value out of an uncountably infinite number. We describe these variables with the cumulative distribution function $F$, or the probability density function $f$. With a continuous random variable, the probability of any individual point is zero.\n\n#### **Continuous Uniform**. {-}\nAny number on a unit interval allowing for any number of decimal points, with every number having the same probability.\n\\begin{eqnarray}\nX_{i} &\\in& [0,1] \\\\\nf(x) &=& \\begin{cases}\n    1 & x \\in [0,1] \\\\\n    0 & \\text{Otherwise}\n\\end{cases}\\\\\nF(x) &=& \\begin{cases} \n    0 & x < 0 \\\\\n    x & x \\in [0,1] \\\\\n    1 & x > 1.\n\\end{cases}\n\\end{eqnarray}\n\nThe probability of a value being exactly $0.25$ is $Prob(X_{i} =0.25)=0$.\n\nThe probability of a value smaller that $0.25$ is $F(0.25)=0.25$.\n\nThe probability of a value larger than $0.25$ is $1-F(0.25)=0.75$.\n\nThe probability of a value in $(0.25,0.75]$ is $Prob(0.25 < X_{i} \\leq 0.75) = Prob(X_{i} \\leq 0.75) - \\left[ 1- Prob(X_{i} \\leq 0.25) \\right] = 0.75 - 0.25 = 0.5$. \n\nThe probability of a value outside of $(0.25,0.75]$ is $Prob(X_{i} \\leq 0.25 \\text{ or } x > 0.75) = 0.25 + [1-0.75]=0.5$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrunif(3) # 3 draws\n## [1] 0.41897580 0.86104446 0.05647309\n\n# Empirical Density \nX2 <- runif(2000)\nhist(X2, breaks=20, border=NA, main=NA, freq=F)\n# Theoretical Density\nx <- seq(0,1,by=.01)\nfx <- dunif(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# CDF examples\npunif(0.25)\n## [1] 0.25\n1-punif(0.25)\n## [1] 0.75\npunif(0.75) - punif(0.25)\n## [1] 0.5\n```\n:::\n\n\n\nNote that the [Continuous Uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution) distribution generalizes to an arbitrary interval, $X_{i} \\in [a,b]$. What is the probability of a value larger than $0.25$ when $a=-b=2$? First use the computer to suggest an answer and then show the answer mathematically.\n\n\nSuppose the flight time (in minutes) between Calgary and Kamloops has Uniform distribution with parameters a = 68 and b = 78. According to Air Canada the flight takes 70 minutes. What is the probability that the flight will be late? What is the probability that a flight takes between 65 and 70 minutes?\n\n\n#### **Beta**. {-}\nAny number on the unit interval, $X_{i} \\in [0,1]$, but with *unequal* probabilities. \n\n::: {.cell}\n\n```{.r .cell-code}\nX3 <- rbeta(2000,2,2) ## two shape parameters\nhist(X3, breaks=20, border=NA, main=NA, freq=F)\n\n#See the underlying probabilities\n#f_25 <- dbeta(.25, 2, 2)\n\nx <- seq(0,1,by=.01)\nfx <- dbeta(x, 2, 2)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nThe [Beta](https://en.wikipedia.org/wiki/Beta_distribution) distribution is mathematically complicated to write, and so we omit it. But it is often used, as the density function has two parameters that allow it to take many different shapes.\n\n::: {.cell}\n\n```{.r .cell-code}\nop <- par(no.readonly = TRUE); on.exit(par(op), add = TRUE)\nx <- seq(0,1,by=.01)\npars <- expand.grid( c(.5,1,2), c(.5,1,2) )\npar(mfrow=c(3,3))\napply(pars, 1, function(p){\n    fx <- dbeta( x,p[1], p[2])\n    plot(x, fx, type='l', xlim=c(0,1), ylim=c(0,4), lwd=2, col='blue')\n    #hist(rbeta(2000, p[1], p[2]), breaks=50, border=NA, main=NA, freq=F)\n})\ntitle('Beta densities', outer=T, line=-1)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-6-1.png){width=768}\n:::\n:::\n\n\n\n#### **Exponential**. {-}\nAny positive number.^[In other classes, you may further distinguish types of random variables based on whether their maximum value is theoretically finite or infinite.] The [Exponential](https://en.wikipedia.org/wiki/Exponential_distribution) distribution has a single parameter, $\\lambda>0$, that governs its shape\n\\begin{eqnarray}\nX_{i} &\\in& [0,\\infty) \\\\\nf(x) &=& \\lambda exp\\left\\{ -\\lambda x \\right\\} \\\\\nF(x) &=& \\begin{cases} \n    0 & x < 0 \\\\\n    1-  exp\\left\\{ -\\lambda x \\right\\} & x \\geq 0.\n\\end{cases}\n\\end{eqnarray}\n\n::: {.cell}\n\n```{.r .cell-code}\nrexp(3) # 3 draws\n## [1] 1.1415113 0.3682949 1.9939697\n\nX3 <- rexp(2000)\nhist(X3, breaks=20,\n    border=NA, main=NA,\n    freq=F, ylim=c(0,1), xlim=c(0,10))\n    \nx <- seq(0,10,by=.1)\nfx <- dexp(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nSuppose the lifetime of a battery is an exponential random variable with $\\lambda=1/50$. Find the probability that the lifetime is $\\geq 100$ hours. Find the probability that the lifetime is between $50$ and $100$ hours.\n\n#### **Normal (Gaussian)**. {-}\nThis distribution is for any number on the real line, with bell shaped probabilities. The [Normal](https://en.wikipedia.org/wiki/Normal_distribution) distribution is mathematically complex and sometimes called the Gaussian distribution. We call it \"Normal\" because we will encounter it again and again and again. The density function $f$ has two parameters $\\mu \\in (\\infty,\\infty)$ and $\\sigma > 0$.\n\\begin{eqnarray}\nX_{i} &\\in& (\\infty,\\infty) \\\\\nf(x) &=& \\frac{1}{\\sqrt{2\\pi \\sigma^2}} exp\\left\\{ \\frac{-(x-\\mu)^2}{2\\sigma^2} \\right\\}\n\\end{eqnarray}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrnorm(3) # 3 draws\n## [1] 1.5501548 0.7818682 0.5465561\n\nX4 <- rnorm(2000)\nhist(X4, breaks=20,\n    border=NA, main=NA,\n    freq=F, ylim=c(0,.4), xlim=c(-4,4))\n\nx <- seq(-10,10,by=.025)\nfx <- dnorm(x)\nlines(x, fx, col='blue')\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nEven thought the distribution function is complex, we can compute CDF values using the computer \n\n::: {.cell}\n\n```{.r .cell-code}\npnorm( c(-1.645, 1.645) )\n## [1] 0.04998491 0.95001509\npnorm( c(-2.326, 2.326) )\n## [1] 0.01000928 0.98999072\n```\n:::\n\n\nSuppose scores in math class are approximately normally distributed with $\\mu=50, \\sigma=1$. If you selected one student randomly, what is the probability their score is higher than $90$. Is $Prob(X_{i}\\geq 90)$ higher if $\\mu=25, \\sigma=2$?\n\n## Drawing Samples\n\nTo generate a random variable from known distributions, you can use some type of physical machine. E.g., you can roll a fair die to generate Discrete Uniform data or you can roll weighted die to generate Categorical data.\n\nThere are also several ways to computationally generate random variables from a probability distribution. Perhaps the most common one is \"inverse sampling\". \n\nRandom variables have an associated *quantile function*, which is the inverse of the CDF: the $x$ value where $p$ percent of the data fall below it.\n\\begin{eqnarray}\nQ(p) = F^{-1}(p), \\quad p\\in [0,1]\n\\end{eqnarray}\n(Recall that the median is the value $x$ where $50\\%$ of the data fall below $x$, for example.) \nTo generate a random variable using inverse sampling, first sample $p$ from a uniform distribution and then find the associated quantile.^[Drawing random uniform samples with computers is actually quite complex and beyond the scope of this course.]\n\n\n#### **Using Data**. {-}\n\nYou can generate a random variable from a known empirical distribution. Inverse sampling randomly selects observations from the dataset with equal probabilities. To implement this, we \n\n* order the data and associate each observation with an ECDF value\n* draw an ECDF probability $p$ as a random variable with equal probabilities\n* finding the associated data point\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Empirical Distribution\nX <- USArrests$Murder\nFX_hat <- ecdf(X)\nplot(FX_hat, lwd=2, xlim=c(0,20),\n    pch=16, col=grey(0,.5), main='')\n\n# Two Examples of generating a random variable\np <- c(.25, .9) # pretended to be random\ncols <- c(2,4)\nQX_hat <- quantile(X, p, type=1)\nsegments(QX_hat, p, -10, p, col=cols)\nsegments(QX_hat, p, QX_hat, 0, col=cols)\nmtext( round(QX_hat,2), 1, at=QX_hat, col=cols)\n```\n\n::: {.cell-output-display}\n![](01_04_RandomVariables_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# Multiple Draws\np <- runif(3000)\nQX_hat <- quantile(x, p,type=1)\nQX_hat[1:5]\n## 58.8231606% 73.4648883% 52.9525661% 41.9261910% 19.9049962% \n##       1.775       4.700       0.600      -1.625      -6.025\n```\n:::\n\n\n#### **Using Math**. {-}\n\nIf you know the distribution function that generates the data, then you can derive the quantile function and do inverse sampling. Here is an in-depth example of the [Dagum distribution](https://en.wikipedia.org/wiki/Dagum_distribution). The distribution function is $F(x)=(1+(x/b)^{-a})^{-c}$. For a given $p=F(x)$, we can then solve for the quantile $Q(p)=\\frac{ b p^{\\frac{1}{ac}} }{(1-p^{1/c})^{1/a}}$. Afterwhich, we sample $p$ from a uniform distribution and then find the associated quantile.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Theoretical Quantile Function (from VGAM::qdagum)\nqdagum <- function(p, scale.b=1, shape1.a, shape2.c) {\n  # Quantile function (theoretically derived from the CDF)\n  ans <- scale.b * (expm1(-log(p) / shape2.c))^(-1 / shape1.a)\n  # Special known cases\n  ans[p == 0] <- 0\n  ans[p == 1] <- Inf\n  # Safety Checks\n  ans[p < 0] <- NaN\n  ans[p > 1] <- NaN\n  if(scale.b <= 0 | shape1.a <= 0 | shape2.c <= 0){ ans <- ans*NaN }\n  # Return\n  return(ans)\n}\n\n# Generate Random Variables (VGAM::rdagum)\nrdagum <-function(n, scale.b=1, shape1.a, shape2.c){\n    p <- runif(n) # generate random probabilities\n    x <- qdagum(p, scale.b=scale.b, shape1.a=shape1.a, shape2.c=shape2.c) #find the inverses\n    return(x)\n}\n\n# Example\nset.seed(123)\nX <- rdagum(3000,1,3,1)\nX[1:5]\n## [1] 0.7390476 1.5499868 0.8845006 1.9616251 2.5091656\n```\n:::\n\n\n",
    "supporting": [
      "01_04_RandomVariables_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}