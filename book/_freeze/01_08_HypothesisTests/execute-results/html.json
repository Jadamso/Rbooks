{
  "hash": "26d55a2a4320aec37debc81deb401a0a",
  "result": {
    "engine": "knitr",
    "markdown": "# $p$-values\n***\n\n \n## $p$-values\n\nA $p$-value is the frequency you see something as extreme as your statistic when sampling from the null distribution. We want the probability mass in both tails: the random variable $M$ that is at least as extreme (far from the null mean of $9$) as our observed sample mean $\\hat{M}$.\n\\begin{eqnarray}\nProb( |M - \\mu| \\geq |\\hat{M} - \\mu| \\mid \\mu = 9 )\n&\\approx& Prob( |M^{\\text{boot}}- \\mu^{\\text{boot}}| \\geq |\\hat{M}- \\mu^{\\text{boot}}|  \\mid \\mu^{\\text{boot}} = 9) \\\\\n&=& 1-\\hat{F}^{|\\text{boot}|}_{0}(|\\hat{M}-9|),\n\\end{eqnarray}\nwhere $\\hat{F}^{|\\text{boot}|}_{0}$ is the ECDF of $|M^{\\text{boot}}- \\mu^{\\text{boot}}|$.\n\nThe bootstrap idea here is to approximate $M-\\mu$, the difference between the sample mean $M$ and the unknown theoretical mean $\\mu$, with the difference between the bootstrap mean $M^{\\text{boot}}$ and the sample mean, $M^{\\text{boot}}-M$.\n\n:::{.callout-note icon=false collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_dat <- USArrests[,'Murder']\nsample_mean <- mean(sample_dat)\n\nset.seed(1)\n# Bootstrap NULL: mean=9\n# Bootstrap shift: center each bootstrap resample so that the distribution satisfies the null hypothesis on average.\nmu <- 9\nbootstrap_means_null <- vector(length=999)\nfor(b in seq_along(bootstrap_means_null)){\n    dat_b <- sample(sample_dat, replace=T) \n    mean_b <- mean(dat_b) + (mu - sample_mean) # impose the null via Bootstrap shift\n    bootstrap_means_null[b] <- mean_b\n}\nhist(bootstrap_means_null, breaks=25, border=NA,\n    main='',\n    xlab='Null Bootstrap Samples')\nci_95 <- quantile(bootstrap_means_null, probs=c(.025, .975)) # critical region\nabline(v=ci_95, lwd=2)\nabline(v=sample_mean, lwd=2, col=4)\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two-Sided Test, ALTERNATIVE: mean < 9 or mean >9\n# Visualize Two Sided Prob. & reject region boundary\npar(mfrow=c(1,2))\nhist(bootstrap_means_null-mu,\n    freq=F, breaks=20,\n    border=NA,\n    main='',\n    xlab=expression('Null Bootstrap for M - '~mu))\nabline(v=sample_mean-mu, col=4)\nci_95 <- quantile(bootstrap_means_null-mu, probs=c(0.025,.975))\nabline(v=ci_95, lwd=2)\n\n# Equivalent Visualization\nboot_absval <- abs(bootstrap_means_null-mu)\nFhat_abs0 <- ecdf(boot_absval)\nplot(Fhat_abs0,\n    main='',\n    xlab=expression('Null Bootstrap for |M - '~mu~'|'))\nabline(v=abs(sample_mean-mu), col=4)\n# with Two Sided Probability\np2 <- 1 - Fhat_abs0( abs(sample_mean-mu) )\ntitle( paste0('p=', round(p2,3)))\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n:::\n\n#### **Caveats**. {-}\n\nBeware that a common misreading of the $p$-value as \"the probability the null is true\". That is false.\n\nOften, one may also see or hear \"$p<.05$: statistically significant\" and \"$p>.05$: not statistically significant\". That is decision making on purely statistical grounds, and it may or may not be suitable for your context. You simply need to know that whoever says those things is using $5\\%$ as a critical value to reject an alternative hypothesis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Purely-Statistical Decision Making \n# via Two Sided Test\nif(p2 >.05){\n    print('fail to reject the null that mean=9, at the 5% level')\n} else {\n    print('reject the null that mean=9 in favor of either <9 or >9, at the 5% level')\n}\n## [1] \"reject the null that mean=9 in favor of either <9 or >9, at the 5% level\"\n```\n:::\n\n\n\nAlso note that the $p$-value is itself a function of data, and hence a random variable that changes from sample to sample. Given that the $5\\%$ level is somewhat arbitrary, and that the $p$-value both varies from sample to sample and is often misunderstood, it makes sense to give $p$-values a limited role in decision making. \n\n\n::: {.cell}\n\n```{.r .cell-code}\np_values <- vector(length=300)\nfor(b2 in seq(p_values)){\n    bootstrap_means_null_p <- vector(length=999)\n    for(b in seq_along(bootstrap_means_null_p)){\n        dat_b <- sample(sample_dat, replace=T) \n        mean_b <- mean(dat_b) + (mu - sample_mean) # impose the null\n        bootstrap_means_null_p[b] <- mean_b\n    }\n    Fhat_abs0 <- ecdf( abs(bootstrap_means_null_p-mu) )\n    p2 <- 1- Fhat_abs0( abs(sample_mean-mu) )\n    p_values[b2] <- p2\n}\n\nhist(p_values, freq=F,\n    border=NA, main='')\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Other Statistics\n\n#### **$t$-values**. {-}\nA *$t$-value* standardizes the approach for hypothesis tests of the mean. For any specific sample, we compute the estimate\n\\begin{eqnarray}\n\\hat{t}=(\\hat{M}-\\mu)/\\hat{S},\n\\end{eqnarray}\nwhich corresponds to the estimator $t = (M - \\mu) / \\mathbb{s}(M)$, which varies from sample to sample. We use bootstrapping to estimate the variability of the $t$ statistic, just like we did with the mean.\n\n:::{.callout-tip icon=false collapse=\"true\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#null hypothesis\nmu <- 9\n\n# t statistic \njackknife_means <- vector(length=length(sample_dat))\nfor(i in seq_along(jackknife_means)){\n    jackknife_means[i] <- mean(dat_b[-i])\n}\nsample_t <- (sample_mean - mu)/sd(jackknife_means)\n\n# Boostrap Null Distribution\nbootstrap_t_null <- vector(length=999)\nfor(b in seq_along(bootstrap_t_null)){\n    dat_b <- sample(sample_dat, replace=T) \n    mean_b <- mean(dat_b) + (mu - sample_mean) # impose the null by recentering\n    # Compute t stat using jackknife ses (same as above)\n    jackknife_means_b <- vector(length=length(dat_b))\n    for(i in seq_along(jackknife_means_b)){\n        jackknife_means_b[i] <- mean(dat_b[-i])\n    }\n    jackknife_se_b <- sd( jackknife_means_b )\n    jackknife_t_b <- (mean_b - mu)/jackknife_se_b\n    bootstrap_t_null[b] <- jackknife_t_b\n}\n\n# Plot the null distribution and CI\npar(mfrow=c(1,2))\nhist(bootstrap_t_null, border=NA, breaks=50,\n    freq=F, main=NA, xlab='Null Bootstrap for t')\nabline(v=sample_t, col=4)\nci_95 <- quantile(bootstrap_t_null, probs=c(0.025,0.975) )\nabline(v=ci_95, lwd=2)\n\n# Compute the p-value for two-sided test\nFhat0 <- ecdf(abs(bootstrap_t_null))\nplot(Fhat0, \n    xlim=range(bootstrap_t_null, sample_t),\n    xlab='Null Bootstrap for |t|',\n    main='')\nabline(v=abs(sample_t), col=4)\np <- 1 - Fhat0( abs(sample_t) )\ntitle( paste0('p=', round(p,3)) )\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\nif(p >.05){\n    print('fail to reject the null that mean=9, at the 5% level')\n} else {\n    print('reject the null that mean=9 in favor of either <9 or >9, at the 5% level')\n}\n## [1] \"reject the null that mean=9 in favor of either <9 or >9, at the 5% level\"\n```\n:::\n\n:::\n\n\nThere are several benefits to this statistic:\n\n* uses the same statistic for different hypothesis tests\n* makes the statistic comparable across different studies\n* removes dependence on unknown parameters by normalizing with a standard error\n* makes the null distribution theoretically known asymptotically (approximately)\n\nThe last point implies we are typically dealing with a normal distribution that is well-studied, or another well-studied distribution derived from it.^[In another statistics class, you will learn the math behind the null t-distribution. In this class, we skip this because we can simply bootstrap the $t$ statistic too.]\n\n#### **Quantiles and Shape Statistics**. {-}\n\nBootstrap allows hypothesis tests for any statistic, not just the mean, without relying on parametric theory. For example, the above procedures generalize from means to quantile statistics like medians.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test for Median Differences (Impose the Null)\n# Bootstrap Null Distribution for the median\n# Each Bootstrap shifts medians so that median = q_null\n\nq_obs <- quantile(sample_dat, probs=.5)\nq_null <- 7.8\nbootstrap_quantile_null <- vector(length=999)\nfor(b in seq_along(bootstrap_quantile_null)){\n    x_b <- sample(sample_dat, replace=T) #bootstrap sample\n    q_b <- quantile(x_b, probs=.5) # median\n    d_b <- q_b - (q_obs-q_null) #impose the null\n    bootstrap_quantile_null[b] <- d_b \n}\n\n    # Note that you could also standardize like the t value. E.g., \n    # jackknife_quantiles_b <- vector(length=length(dat_b))\n    # se_b <- sd(jackknife_quantiles_b)\n    # d_b <- d_b/se_b\n    \n# 2-Sided Test for Medians\nhist(bootstrap_quantile_null-q_null, \n    border=NA, freq=F, xlab='Null Bootstrap',\n    font.main=1, main='Medians (Impose Null)')\nmedian_ci <- quantile(bootstrap_quantile_null-q_null, probs=c(.025, .975))\nabline(v=median_ci, lwd=2)\nabline(v=q_obs-q_null, lwd=2, col=4)\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# 2-Sided Test for Median Difference\n## Null: No Median Difference\n1 - ecdf( abs(bootstrap_quantile_null-q_null))( abs(q_obs-q_null) ) \n## [1] 0.5695696\n```\n:::\n\n\n\n\n## One-Sided Tests\n\nAbove, we tested whether the observed statistic is either extremely high or low. This is known as a two-sided test. There are also two one-sided tests (left tail: observed statistic is extremely low, right tail: observed statistic is extremely high). For a concrete example, consider whether the mean statistic, $M$, is centered on a theoretical value of $\\mu=9$ for the population. If your null hypothesis is that the theoretical mean is nine, $H_{0}: \\mu =9$, and you calculated the mean for your sample as $\\hat{M}$, then you can consider any one of these three alternative hypotheses:\n\n* $H_{A}​: \\mu \\neq 9$, a two-tail test\n* $H_{A}: \\mu < 9$, a left-tail test\n* $H_{A​}: \\mu > 9$, a right-tail test\n\n\n#### **One-Sided Intervals**. {-}\n\nA one-sided test is associated with an interval that shifted to one side, containing one tail rather than the middle. For example, a left tail test that \"inverts a CI\" uses the interval $(-\\infty, q_{0.95}]$, where $q_{0.95}$ is the $95^{\\text{th}}$ percentile of the bootstrap distribution. If the hypothesized value falls inside that interval, then we fail to reject the null (at the $5\\%$ level), otherwise we reject the null (it seems extremely unlikely that we would find such a large value). A left tail test that \"inverts a CI\" uses the interval $[q_{0.05}, \\infty)$, where $q_{0.05}$ is the $5^{\\text{th}}$ percentile of the bootstrap distribution.\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nHere is right-tail Test example\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bootstrap Distribution\nset.seed(1) # to be replicable\nbootstrap_means <- vector(length=9999)\nfor(b in seq_along(bootstrap_means)){\n    dat_id <- seq(1,length(sample_dat))\n    boot_id <- sample(dat_id, replace=T)\n    dat_b  <- sample_dat[boot_id] # c.f. jackknife\n    mean_b <- mean(dat_b)\n    bootstrap_means[b] <-mean_b\n}\n\n# ALTERNATIVE: mean > 9\n# Visualize One Sided Prob. & reject region boundary\nhist(bootstrap_means, border=NA, breaks=50,\n    freq=F, main=NA, xlab='Null Bootstrap')\nabline(v=sample_mean, col=4)\nci_95 <- quantile(bootstrap_means, probs=c(0.05,1) )\nabline(v=ci_95, lwd=2)\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n:::\n\n\n<details>\n<summary> Advanced and Optional </summary>\n  <p>\nFor me at least, “invert a CI” is the most intuitive way to conduct hypothesis test using intervals. \nHowever, there are \"Impose the Null\" intervals, which are reversed, that correspond more closely to $p$-values.\n\nA right tail test that \"imposes the null\" uses the interval $(-\\infty, q_{0.95}]$, where $q_{0.95}$ is the $95^{\\text{th}}$ percentile of the null bootstrap distribution: If the observed value falls inside that interval, then we fail to reject the null (at the $5\\%$ level), otherwise we reject the null (it seems extremely unlikely that we would find such a small value). A left tail test that \"imposes the null\" uses the interval $[q_{0.05}, \\infty)$, where $q_{0.05}$ is the $5^{\\text{th}}$ percentile of the null bootstrap distribution. Referring to the hypothetical value generally as $\\mu_0$ instead of the particular number $9$, we can summarize the one-sided decision rules as\n\n| | Tail | Reject when | Fail to reject when |\n| --- | --- | --- | --- |\n| **Impose the Null**<br>(shifted/bootstrap-null) | *Right-tail*<br> $H_A: \\mu > \\mu_0$ | $\\hat{M} > q^{\\text{null}}_{0.95}$ | $\\hat{M} \\le q^{\\text{null}}_{0.95}$ |\n|                                                                  | *Left-tail*<br>$H_A: \\mu < \\mu_0$   | $\\hat{M} < q^{\\text{null}}_{0.05}$ | $\\hat{M} \\ge q^{\\text{null}}_{0.05}$ |\n| **Invert a CI**<br>(percentile CI)               | *Right-tail*<br>$H_A: \\mu > \\mu_0$  | $\\mu_0 < q^{\\text{boot}}_{0.05}$   | $\\mu_0 \\ge q^{\\text{boot}}_{0.05}$   |\n|                                                                  | *Left-tail*<br> $H_A: \\mu < \\mu_0$  | $\\mu_0 > q^{\\text{boot}}_{0.95}$   | $\\mu_0 \\le q^{\\text{boot}}_{0.95}$  |\n  </p>\n</details>\n\n\n#### **One-Sided $p$-values**. {-}\n\nThe $p$-value for a one-sided test is more straightforward to implement via a bootstrap null distribution. \n\nFor a left-tail test, we examine \\begin{eqnarray}\np = Prob( M < \\hat{M} \\mid \\mu = 9 )\n    &\\approx& Prob( M^{\\text{boot}} < \\hat{M} \\mid  \\mu^{\\text{boot}} = 9 ) = \\hat{F}^{\\text{boot}}_{0}(\\hat{M}),\n\\end{eqnarray}\nwhere $\\hat{F}^{\\text{boot}}_{0}$ is the ECDF of the bootstrap null distribution. We reject the null if $p < 0.05$ at the $5\\%$ level, and otherwise fail to reject.\n\nFor a right-tail test, we examine $p=Prob( M > \\hat{M} \\mid \\mu = 9 ) \\approx 1-\\hat{F}^{\\text{boot}}_{0}(\\hat{M})$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Right-tail Test, ALTERNATIVE: mean > 9\n# Equivalent Visualization with p-value\nFhat0 <- ecdf(bootstrap_means_null) # Look at right tail\nplot(Fhat0,\n    main='',\n    xlab='Null Bootstrap')\nabline(v=sample_mean, col=4)\np1 <- 1- Fhat0(sample_mean) #Compute right tail prob: 0.987\ntitle( paste0('p=', round(p1,3)))\n```\n\n::: {.cell-output-display}\n![](01_08_HypothesisTests_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\nif(p1 >.05){\n    print('fail to reject the null that mean=9, at the 5% level')\n} else {\n    print('reject the null that mean=9 in favor of >9, at the 5% level')\n}\n## [1] \"fail to reject the null that mean=9, at the 5% level\"\n```\n:::\n\n\n:::{.callout-tip icon=false collapse=\"true\"}\nNotice that the recentering adjustment affects two-sided tests (because they depend on distance from the null mean) but not one-sided tests (because adding a constant does not change rank order). Specifically, $p = Prob( M < \\hat{M} \\mid \\mu = 9 ) =  Prob( M - \\mu < \\hat{M} - \\mu \\mid \\mu = 9 )$. That is intuitively also why the $t$-value can be used for both one and two-sided hypothesis tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# See that the \"recentering\" matters for two-sided tests\necdf( abs(bootstrap_means_null-mu) )( abs(sample_mean-mu) )\n## [1] 0.966967\necdf( abs(bootstrap_means_null) )( abs(sample_mean) )\n## [1] 0.01301301\n\n# See that the \"recentering\" doesn't matter for one-sided ones\necdf( bootstrap_means_null-mu)( sample_mean-mu)\n## [1] 0.01301301\necdf( bootstrap_means_null )( sample_mean)\n## [1] 0.01301301\n```\n:::\n\n:::\n\n## Further Reading\n\n* <https://learningstatisticswithr.com/book/hypothesistesting.html>\n* <https://okanbulut.github.io/rbook/part5.html>\n",
    "supporting": [
      "01_08_HypothesisTests_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}