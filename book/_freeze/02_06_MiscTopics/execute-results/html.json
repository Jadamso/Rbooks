{
  "hash": "61b69e813d089adf732cf5cc38b43e97",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Misc. Bivariate Topics\n***\n\n## Predictions\n\n#### **Describe vs. Explain vs. Predict**.{-}\n\n#### **Prediction Intervals**. {-}\n\nIn addition to confidence intervals, we can also compute a *prediction interval* which estimate the variability of new data rather than a statistic\n\nIn this example, we consider a single variable and compute the frequency each value was covered.\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- runif(1000)\n# Middle 90% of values\nxq0 <- quantile(x, probs=c(.05,.95))\n\nbks <- seq(0,1,by=.01)\nhist(x, breaks=bks, border=NA,\n    main='Prediction Interval', font.main=1)\nabline(v=xq0)\n```\n\n::: {.cell-output-display}\n![](02_06_MiscTopics_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\npaste0('we are 90% confident that the a future data point will be between ', \n    round(xq0[1],2), ' and ', round(xq0[2],2) )\n## [1] \"we are 90% confident that the a future data point will be between 0.06 and 0.95\"\n```\n:::\n\nIn this example, we consider a range for $y_{i}(x)$ rather than for $m(x)$. These intervals also take into account the residuals --- the variability of individuals around the mean. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Bivariate Data from USArrests\nxy <- USArrests[,c('Murder','UrbanPop')]\ncolnames(xy) <- c('y','x')\nxy0 <- xy[order(xy$x),]\n```\n:::\n\n\nFor a nice overview of different types of intervals, see https://www.jstor.org/stable/2685212. For an in-depth view, see \"Statistical Intervals: A Guide for Practitioners and Researchers\" or \"Statistical Tolerance Regions: Theory, Applications, and Computation\". See https://robjhyndman.com/hyndsight/intervals/ for constructing intervals for future observations in a time-series context. See Davison and Hinkley, chapters 5 and 6 (also Efron and Tibshirani, or Wehrens et al.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# From \"Basic Regression\"\nxy0 <- xy[order(xy$x),]\nX0 <- unique(xy0$x)\nreg_lo <- loess(y~x, data=xy0, span=.8)\npreds_lo <- predict(reg_lo, newdata=data.frame(x=X0))\n\n\n# Jackknife CI\njack_lo <- sapply(1:nrow(xy), function(i){\n    xy_i <- xy[-i,]\n    reg_i <- loess(y~x, dat=xy_i, span=.8)\n    predict(reg_i, newdata=data.frame(x=X0))\n})\n\nboot_regs <- lapply(1:399, function(b){\n    b_id <- sample( nrow(xy), replace=T)\n    xy_b <- xy[b_id,]\n    reg_b <- lm(y~x, dat=xy_b)\n})\n\nplot(y~x, pch=16, col=grey(0,.5),\n    dat=xy0, ylim=c(0, 20))\nlines(X0, preds_lo,\n    col=hcl.colors(3,alpha=.75)[2],\n    type='o', pch=2)\n\n# Estimate Residuals CI at design points\nres_lo <- sapply(1:nrow(xy), function(i){\n    y_i <- xy[i,'y']\n    preds_i <- jack_lo[,i]\n    resids_i <- y_i - preds_i\n})\nres_cb <- apply(res_lo, 1, quantile,\n    probs=c(.025,.975), na.rm=T)\n\n# Plot\nlines( X0, preds_lo +res_cb[1,],\n    col=hcl.colors(3,alpha=.75)[2], lt=2)\nlines( X0, preds_lo +res_cb[2,],\n    col=hcl.colors(3,alpha=.75)[2], lty=2)\n\n\n\n# Smooth estimates \nres_lo <- lapply(1:nrow(xy), function(i){\n    y_i <- xy[i,'y']\n    x_i <- xy[i,'x']\n    preds_i <- jack_lo[,i]\n    resids_i <- y_i - preds_i\n    cbind(e=resids_i, x=x_i)\n})\nres_lo <- as.data.frame(do.call(rbind, res_lo))\n\nres_fun <- function(x0, h, res_lo){\n    # Assign equal weight to observations within h distance to x0\n    # 0 weight for all other observations\n    ki <- dunif(res_lo$x, x0-h, x0+h) \n    ei <- res_lo[ki!=0,'e']\n    res_i <- quantile(ei, probs=c(.025,.975), na.rm=T)\n}\nres_lo2 <- sapply(X0, res_fun, h=15, res_lo=res_lo)\n\nlines( X0, preds_lo + res_lo2[1,],\n    col=hcl.colors(3,alpha=.75)[2], lty=1, lwd=2)\nlines( X0, preds_lo + res_lo2[2,],\n    col=hcl.colors(3,alpha=.75)[2], lty=1, lwd=2)\n```\n\n::: {.cell-output-display}\n![](02_06_MiscTopics_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bootstrap Prediction Interval\nboot_resids <- lapply(boot_regs, function(reg_b){\n    e_b <- resid(reg_b)\n    x_b <- reg_b$model$x\n    res_b <- cbind(e_b, x_b)\n})\nboot_resids <- as.data.frame(do.call(rbind, boot_resids))\n# Homoskedastic\nehat <- quantile(boot_resids$e_b, probs=c(.025, .975))\nx <- quantile(xy$x,probs=seq(0,1,by=.1))\nboot_pi <- coef(reg)[1] + x*coef(reg)['x']\nboot_pi <- cbind(boot_pi + ehat[1], boot_pi + ehat[2])\n\n# Plot Bootstrap PI\nplot(y~x, dat=xy, pch=16, main='Prediction Intervals',\n    ylim=c(-5,20), font.main=1)\npolygon( c(x, rev(x)), c(boot_pi[,1], rev(boot_pi[,2])),\n    col=grey(0,.2), border=NA)\n\n# Parametric PI (For Comparison)\n#pi <- predict(reg, interval='prediction', newdata=data.frame(x))\n#lines( x, pi[,'lwr'], lty=2)\n#lines( x, pi[,'upr'], lty=2)\n```\n:::\n\n\n\n#### **Crossvalidation**.{-}\n\nPerhaps the most common approach to selecting a bandwidth is to minimize \\textit{prediction} error. *Leave-one-out Cross-validation* minimizes the average \"leave-one-out\" mean square prediction errors:\n\\begin{eqnarray}\nCV &=& \\min_{\\mathbf{H}} \\quad \\frac{1}{n} \\sum_{i=1}^{n} \\left[ Y_{i} - \\widehat{Y_{[i]}}(\\mathbf{X},\\mathbf{H}) \\right]^2,\n% \\widehat{Y_{[i]}}(\\mathbf{X},\\mathbf{H}) &=& \\sum_{j\\neq i} k(\\mathbf{X}_{j},\\mathbf{X}_{i},\\mathbf{H}) \\left[ \\widehat{\\alpha}(\\mathbf{X}_{j}) +  \\widehat{\\beta}(\\mathbf{X}_{j}) \\mathbf{X}_{i} \\right]\n\\end{eqnarray}\nwhere $\\widehat{Y_{[i]}}(\\mathbf{X},\\mathbf{H})$ is the predicted value at $\\mathbf{X}_{i}$ based on a dataset that excludes $\\mathbf{X}_{i}$.\n\nThere are many types of cross-validation \\parencite{ArlotCelisse2010, BatesEtAl2023}. For example, one extension is \\textit{k-fold cross-validation}, which splits $N$ datapoints into $k=1...K$ groups, each sized $B$, and predicts values for the left-out group. \\textit{Generalized cross-validation} adjusts for the degrees of freedom, whereas the \\texttt{npreg} function in R uses \\textit{least-squares cross-validation} \\parencite[p.74]{racine2019} by default. You can refer to extensions on a case by case basis.\n\nMinimizing out-sample prediction error is perhaps the simplest computational approach to choose bandwidths, and it also addresses an issue that plagues observational studies in the social sciences of explanations without predictions. It is a problem if your model explains everything and predicts nothing, but minimizing prediction error is not necessarily \"best\". \n\n\n::: {.cell}\n\n```{.r .cell-code}\n##################                                         \n# Crossvalidated bandwidth for regression\n##################\ny <- (CASchools$read + CASchools$math) / 2\nxy_mat <- data.frame(y=y, x1=CASchools$income)\nlibrary(np)\n\n## Grid Search\nBWS <- seq(1,10,length.out=20)\nBWS_CV <- sapply(BWS, function(bw){\n    E_bw <- sapply(1:nrow(xy_mat), function(i){\n        llls <- npreg(y~x1, data=xy_mat[-i,], \n            bws=bw, regtype=\"ll\",\n            ckertype='epanechnikov', bandwidth.compute=F)\n        pred_i <- predict(llls, newdata=xy_mat[i,])\n        e <-  (pred_i- xy_mat[i,'y'])\n        return(e)\n    })\n    return( mean(E_bw^2) )\n})\n\n## Plot MSE\npar(mfrow=c(1,2))\nplot(BWS, BWS_CV, ylab='CV', pch=16, \n    xlab='bandwidth (h)',)\n## Plot Resulting Predictions\nbw <- BWS[which.min(BWS_CV)]\nllls <- npreg(y~x1, data=xy_mat, \n    ckertype='epanechnikov',\n    bws=bw, regtype=\"ll\")\nplot(xy_mat$x, predict(llls), pch=16, col=grey(0,.5),\n    xlab='X', ylab='Predictions')\nabline(a=0,b=1, lty=2)\n\n## Built in algorithmic Optimziation\nllls2 <- npreg(y~x1, data=xy_mat, ckertype='epanechnikov', regtype=\"ll\")\npoints(xy_mat$x, predict(llls2), pch=2, col=rgb(1,0,0,.25))\n\n## Add legend\nadd_legend <- function(...) {\n  opar <- par(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), \n              mar=c(0, 0, 0, 0), new=TRUE)\n  on.exit(par(opar))\n  plot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\n  legend(...)\n}\nadd_legend('topright',\n    col=c(grey(0,.5),rgb(1,0,0,.25)), \n    pch=c(16,2),\n    bty='n', horiz=T,\n    legend=c('Grid Search', 'NP-algorithm'))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##################\n# CV Application\n##################\n\n## Smoothly Estimate X & Y Density\ny <- sort(xy_mat$y)\nfy <- npudens(y, bandwidth.compute=TRUE)\nx1 <- sort(xy_mat$x1)\nfx <- npudens(x1, bandwidth.compute=TRUE)\n## Smoothly Estimate How Y changes with X\nllls2 <- npreg(y~x1,data=xy_mat,\n    ckertype='epanechnikov',\n    regtype=\"ll\", bandwidth.compute=TRUE)\n\n\nlayout( matrix(c(2,0,1,3), ncol=2, byrow=TRUE),\n    widths=c(4/5,1/5), heights=c(1/5,4/5))\n## Joint Distribution\npar(mar=c(4,4,1,1))\nplot(y~x1, data=xy_mat,\n    pch=16, col=grey(0,.25),\n    xlab=\"District Income (1000$)\", \n    ylab=\"Test Score\")\nlines( sort(xy_mat$x), predict(llls2)[order(xy_mat$x1)],\n    pch=16, col=1)\n## Marginal Distribution\npar(mar=c(0,4,1,1))\nplot(x1, predict(fx),\n    col=grey(0,1), type='l', axes=F,\n    xlab='', ylab='')\nrug(x1, col=grey(0,.25))\npar(mar=c(4,0,1,1))\nplot(predict(fy), y,\n    col=grey(0,1), type='l', axes=F,\n    xlab='', ylab='')\nrug(y, col=grey(0,.25), side=2)\n```\n:::\n\n\n#### **Bias vs. Variance** {-}\n\n\n\n## Decision Theory\n\n#### **Type II Errors and Statistical Power**. {-}\n\n#### **Quality Control**. {-}\n\n#### **Optimal Experiment Designs**. {-}\n\n",
    "supporting": [
      "02_06_MiscTopics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}