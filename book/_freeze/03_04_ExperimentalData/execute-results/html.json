{
  "hash": "f4723a3e93dcab2d2d0ee7147fb44053",
  "result": {
    "engine": "knitr",
    "markdown": "# Experimental Data\n***\n\n## Design Basics\n\nWe will consider with our example from the last chaper\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Demand Curve Simulator\nqd_fun <- function(p, Ad=8, Bd=-.8, Ed_sigma=.25){\n    Qd <- Ad + Bd*p + rnorm(1,0,Ed_sigma)\n    return(Qd)\n}\n\n# Supply Curve Simulator\nqs_fun <- function(p, As=-8, Bs=1, Es_sigma=.25){\n    Qs <- As + Bs*p + rnorm(1,0,Es_sigma)\n    return(Qs)\n}\n\n# Quantity Supplied and Demanded at 3 Prices\ncbind(P=8:10, D=qd_fun(8:10), S=qs_fun(8:10))\n##       P          D          S\n## [1,]  8 1.65909899 -0.1005547\n## [2,]  9 0.85909899  0.8994453\n## [3,] 10 0.05909899  1.8994453\n\n# Market Equilibrium Finder\neq_fun <- function(demand, supply, P){\n    # Compute EQ (what we observe)\n    eq_id <- which.min( abs(demand-supply) )\n    eq <- c(P=P[eq_id], Q=demand[eq_id]) \n    return(eq)\n}\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nN <- 300 # Number of Market Interactions\nP <- seq(5,10,by=.01) # Price Range to Consider\nEQ1 <- sapply(1:N, function(n){\n    # Market Data Generating Process\n    demand <- qd_fun(P)\n    supply <- qs_fun(P)\n    eq <- eq_fun(demand, supply, P)    \n    return(eq)\n})\ndat1 <- data.frame(t(EQ1), cost='1', T=1:N)\n```\n:::\n\n\n#### **Control and Randomize**. {-}\n\n*Blocking* and *Clustering*\n\n#### **Competitive Equilibrium Example**. {-}\nIf you have exogenous variation on one side of the market, you can get information on the other. For example, lower costs shift out supply (more is produced at given price), allowing you to trace out part of a demand curve. \n\nTo see this, consider an experiment where student subjects are recruited to a classroom and randomly assigned to be either buyers or sellers in a market for little red balls. In this case, the classroom environment allows the experimenter to control for various factors (e.g., the temperature of the room is constant for all subjects) and the explicit randomization of subjects means that there are not typically systematic differences in different groups of students.\n\nIn the experiment, sellers are given linear \"cost functions\" that theoretically yield individual supplies like \\eqref{eqn:market_supply} and are paid \"price - cost\". Buyers are given linear \"benefit functions\" that theoretically yield individual demands like \\eqref{eqn:market_demand}, and are paid \"benefit - price\". The theoretical predictions are theorefore given in \\eqref{eqn:market_supply}. Moreover, experimental manipulation of $A_{S}$ leads to \n\\begin{eqnarray}\n\\label{eqn:comp_market_statics}\n\\frac{d P^{*}}{d A_{S}} = \\frac{-1}{B_{D}+B_{S}}, \\\\\n\\frac{d Q^{*}}{d A_{S}} = \\frac{B_{D}}{B_{D}+B_{S}}.\n\\end{eqnarray}\nIn this case, the supply shock has identified the demand slope: $-B_{D}=d Q^{*}/d P^{*}$.\n\n::: {.cell}\n\n```{.r .cell-code}\n# New Observations After Cost Change\nEQ2 <- sapply(1:N, function(n){\n    demand <- qd_fun(P)\n    supply2 <- qs_fun(P, As=-6.5) # More Supplied at Given Price\n    eq <- eq_fun(demand, supply2, P)\n    return(eq)\n    # lines(supply2, P, col=rgb(0,0,1,.01))\n    #points(eq[2], eq[1], col=rgb(0,0,1,.05), pch=16)\n})\ndat2 <- data.frame(t(EQ2), cost='2', T=(1:N) + N)\ndat2 <- rbind(dat1, dat2)\n\n# Plot Simulated Market Data\ncols <- ifelse(as.numeric(dat2$cost)==2, rgb(0,0,1,.2), rgb(0,0,0,.2))\nplot.new()\nplot.window(xlim=c(0,2), ylim=range(P))\npoints(dat2$Q, dat2$P, col=cols, pch=16)\naxis(1)\naxis(2)\nmtext('Quantity',1, line=2)\nmtext('Price',2, line=2)\n```\n\n::: {.cell-output-display}\n![](03_04_ExperimentalData_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIf the function forms for supply and demand are different from what we predicted, we can still measure how much the experimental manipulation of production costs affects the equilibrium quantity sold (and compare that to what was predicted).^[Notice that even in this linear model, however, all effects are conditional: *The* effect of a cost change on quantity or price depends on the demand curve. A change in costs affects quantity supplied but not quantity demanded (which then affects equilibrium price) but the demand side of the market still matters! The change in price from a change in costs depends on the elasticity of demand.]\n\n\n\n## Comparisons Over Time\n\n#### **Regression Discontinuities/Kinks**. {-}\n\nThe basic idea of RDD/RKD is to examine how a variable changes just before and just after a treatment. RDD estimates the difference in the levels of an outcome variable, whereas RKD estimates the difference in the slope. Turning to our canonical competitive market example, the RDD estimate is the difference between the lines at $T=300$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Locally Linear Regression \n# (Compare means near break)\n\ncols <- ifelse(as.numeric(dat2$cost)==2, rgb(0,0,1,.5), rgb(0,0,0,.5))\nplot(P~T, dat2, main='Effect of Cost Shock on Price', \n    font.main=1, pch=16, col=cols)\nregP1 <- loess(P~T, dat2[dat2$cost==1,]) \nx1 <- regP1$x\n#lm(): x1 <- regP1$model$T \nlines(x1, predict(regP1), col=rgb(0,0,0), lwd=2)\nregP2 <- loess(P~T, dat2[dat2$cost==2,])\nx2 <- regP2$x #regP1$model$T\nlines(x2, predict(regP2), col=rgb(0,0,1), lwd=2)\n```\n\n::: {.cell-output-display}\n![](03_04_ExperimentalData_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\nplot(Q~T, dat2, main='Effect of Cost Shock on Quantity',\n    font.main=1, pch=16, col=cols)\nregQ1 <- loess(Q~T, dat2[dat2$cost==1,]) \nlines(x1, predict(regQ1), col=rgb(0,0,0), lwd=2)\nregQ2 <- loess(Q~T, dat2[dat2$cost==2,])\nx2 <- regP2$x #regP1$model$T\nlines(x2, predict(regQ2), col=rgb(0,0,1), lwd=2)\n```\n\n::: {.cell-output-display}\n![](03_04_ExperimentalData_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\n\n```{.r .cell-code}\n# Linear Regression Alternative\nsub_id <- (dat2$cost==1 & dat2$T > 250) | (dat2$cost==2 & dat2$T < 300)\ndat2W <- dat2[sub_id,  ]\nregP <- lm(P~T*cost, dat2)\nregQ <- lm(Q~T*cost, dat2)\nstargazer::stargazer(regP, regQ, \n    type='html',\n    title='Recipe RDD',\n    header=F)\n```\n\n\n<table style=\"text-align:center\"><caption><strong>Recipe RDD</strong></caption>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable:</em></td></tr>\n<tr><td></td><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n<tr><td style=\"text-align:left\"></td><td>P</td><td>Q</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">T</td><td>0.00002</td><td>0.0001</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.0001)</td><td>(0.0001)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">cost2</td><td>-0.905<sup>***</sup></td><td>0.716<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.061)</td><td>(0.057)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">T:cost2</td><td>0.0001</td><td>-0.0001</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.0002)</td><td>(0.0002)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">Constant</td><td>8.883<sup>***</sup></td><td>0.863<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.022)</td><td>(0.020)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Observations</td><td>600</td><td>600</td></tr>\n<tr><td style=\"text-align:left\">R<sup>2</sup></td><td>0.837</td><td>0.787</td></tr>\n<tr><td style=\"text-align:left\">Adjusted R<sup>2</sup></td><td>0.836</td><td>0.786</td></tr>\n<tr><td style=\"text-align:left\">Residual Std. Error (df = 596)</td><td>0.186</td><td>0.175</td></tr>\n<tr><td style=\"text-align:left\">F Statistic (df = 3; 596)</td><td>1,022.455<sup>***</sup></td><td>735.855<sup>***</sup></td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"><em>Note:</em></td><td colspan=\"2\" style=\"text-align:right\"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>\n</table>\n\nRemember that this is effect is *local*: different magnitudes of the cost shock or different demand curves generally yield different estimates.\n\nMoreover, note that more than just costs have changed over time: subjects in the later periods have history experience behind them while they do not in earlier periods. So hidden variables like \"beliefs\" are implicitly treated as well. This is one concrete reason to have an explicit control group.\n\n#### **Difference in Differences**. {-}\nThe basic idea of DID is to examine how a variable changes in response to an exogenous shock, *compared to a control group*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nEQ3 <- sapply(1:(2*N), function(n){\n\n    # Market Mechanisms\n    demand <- qd_fun(P)\n    supply <- qs_fun(P)\n\n    # Compute EQ (what we observe)\n    eq_id <- which.min( abs(demand-supply) )\n    eq <- c(P=P[eq_id], Q=demand[eq_id]) \n\n    # Return Equilibrium Observations\n    return(eq)\n})\ndat3 <- data.frame(t(EQ3), cost='1', T=1:ncol(EQ3))\ndat3_pre  <- dat3[dat3$T <= N ,]\ndat3_post <- dat3[dat3$T > N ,]\n\n# Plot Price Data\npar(mfrow=c(1,2))\nplot(P~T, dat2, main='Effect of Cost Shock on Price', \n    font.main=1, pch=16, col=cols, cex=.5)\nlines(x1, predict(regP1), col=rgb(0,0,0), lwd=2)\nlines(x2, predict(regP2), col=rgb(0,0,1), lwd=2)\n# W/ Control group\npoints(P~T, dat3, pch=16, col=rgb(1,0,0,.5), cex=.5)\nregP3a <- loess(P~T, dat3_pre)\nx3a <- regP3a$x\nlines(x3a, predict(regP3a), col=rgb(1,0,0), lwd=2)\nregP3b <- loess(P~T, dat3_post)\nx3b <- regP3b$x\nlines(x3b, predict(regP3b), col=rgb(1,0,0), lwd=2)\n\n\n# Plot Quantity Data\nplot(Q~T, dat2, main='Effect of Cost Shock on Quantity',\n    font.main=1, pch=17, col=cols, cex=.5)\nlines(x1, predict(regQ1), col=rgb(0,0,0), lwd=2)\nlines(x2, predict(regQ2), col=rgb(0,0,1), lwd=2)\n# W/ Control group\npoints(Q~T, dat3, pch=16, col=rgb(1,0,0,.5), cex=.5)\nregQ3a <- loess(Q~T, dat3_pre) \nlines(x3a, predict(regQ3a), col=rgb(1,0,0), lwd=2)\nregQ3b <- loess(Q~T, dat3_post) \nlines(x3b, predict(regQ3b), col=rgb(1,0,0), lwd=2)\n```\n\n::: {.cell-output-display}\n![](03_04_ExperimentalData_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nLinear Regression Estimates\n\n```{.r .cell-code}\n# Pool Data\ndat_pooled <- rbind(\n    cbind(dat2, EverTreated=1, PostPeriod=(dat2$T > N)),\n    cbind(dat3, EverTreated=0, PostPeriod=(dat3$T > N)))\ndat_pooled$EverTreated <- as.factor(dat_pooled$EverTreated)\ndat_pooled$PostPeriod <- as.factor(dat_pooled$PostPeriod)\n\n# Estimate Level Shift for Different Groups after T=300\nregP <- lm(P~PostPeriod*EverTreated, dat_pooled)\nregQ <- lm(Q~PostPeriod*EverTreated, dat_pooled)\nstargazer::stargazer(regP, regQ, \n    type='html',\n    title='Recipe DiD',\n    header=F)\n```\n\n\n<table style=\"text-align:center\"><caption><strong>Recipe DiD</strong></caption>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable:</em></td></tr>\n<tr><td></td><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n<tr><td style=\"text-align:left\"></td><td>P</td><td>Q</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">PostPeriod</td><td>-0.002</td><td>0.027<sup>*</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.016)</td><td>(0.014)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">EverTreated1</td><td>0.013</td><td>-0.001</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.016)</td><td>(0.014)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">PostPeriodTRUE:EverTreated1</td><td>-0.839<sup>***</sup></td><td>0.642<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.022)</td><td>(0.020)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">Constant</td><td>8.873<sup>***</sup></td><td>0.874<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.011)</td><td>(0.010)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Observations</td><td>1,200</td><td>1,200</td></tr>\n<tr><td style=\"text-align:left\">R<sup>2</sup></td><td>0.778</td><td>0.725</td></tr>\n<tr><td style=\"text-align:left\">Adjusted R<sup>2</sup></td><td>0.777</td><td>0.725</td></tr>\n<tr><td style=\"text-align:left\">Residual Std. Error (df = 1196)</td><td>0.193</td><td>0.176</td></tr>\n<tr><td style=\"text-align:left\">F Statistic (df = 3; 1196)</td><td>1,396.986<sup>***</sup></td><td>1,052.117<sup>***</sup></td></tr>\n<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"><em>Note:</em></td><td colspan=\"2\" style=\"text-align:right\"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>\n</table>\n\n\n## \"Natural\" Experiments\n\nNatural experiments are historical case studies that remedy the endogeneity issues in observational data. They assume that a historical events is quasi (or psuedo) random. In addition to \"RDD\" and \"DID\" methods discussed above, instrumental variables are used in historical event studies. The elementary versions use linear regression, so I can cover them here using our competitive equilibrium example from before.\n\n#### **Two Stage Least Squares (2SLS)**. {-}\nConsider the market equilibrium example, which contains a cost shock. We can simply run another regression, but there will still be a problem. \n\n::: {.cell}\n\n```{.r .cell-code}\n# Not exactly right, but at least right sign\nreg2 <- lm(Q~P, data=dat2)\nsummary(reg2)\n## \n## Call:\n## lm(formula = Q ~ P, data = dat2)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.70249 -0.14517  0.00104  0.14749  0.74487 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  6.72597    0.17305   38.87   <2e-16 ***\n## P           -0.65177    0.02041  -31.93   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.2298 on 598 degrees of freedom\n## Multiple R-squared:  0.6304,\tAdjusted R-squared:  0.6297 \n## F-statistic:  1020 on 1 and 598 DF,  p-value: < 2.2e-16\n```\n:::\n\nIt turns out that rhe noisiness of the process within each group affects our OLS estimate: $\\widehat{\\beta}_{OLS}=Cov(Q^{*}, P^{*}) / Var(P^{*})$. For details, see\n<details>\n<summary><i>Within Group Variance</i></summary>\nYou can experiment with the effect of different variances on both OLS and IV in the code below. And note that if we had multiple supply shifts and recorded their magnitudes, then we could recover more information about demand, perhaps tracing it out entirely.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Examine\nEgrid <- expand.grid(Ed_sigma=c(.001, .25, 1), Es_sigma=c(.001, .25, 1))\n\nEgrid_regs <- lapply(1:nrow(Egrid), function(i){\n    Ed_sigma <- Egrid[i,1]\n    Es_sigma <- Egrid[i,2]    \n    EQ1 <- sapply(1:N, function(n){\n        demand <- qd_fun(P, Ed_sigma=Ed_sigma)\n        supply <- qs_fun(P, Es_sigma=Es_sigma)\n        return(eq_fun(demand, supply, P))\n    })\n    EQ2 <- sapply(1:N, function(n){\n        demand <- qd_fun(P,Ed_sigma=Ed_sigma)\n        supply2 <- qs_fun(P, As=-6.5,Es_sigma=Es_sigma)\n        return(eq_fun(demand, supply2, P))\n    })\n    dat <- rbind(\n        data.frame(t(EQ1), cost='1'),\n        data.frame(t(EQ2), cost='2'))\n    return(dat)\n})\nEgrid_OLS <- sapply(Egrid_regs, function(dat) coef( lm(Q~P, data=dat)))\nEgrid_IV <- sapply(Egrid_regs, function(dat) coef( feols(Q~1|P~cost, data=dat)))\n\n#cbind(Egrid, coef_OLS=t(Egrid_OLS)[,2], coef_IV=t(Egrid_IV)[,2])\nlapply( list(Egrid_OLS, Egrid_IV), function(ei){\n    Emat <- matrix(ei[2,],3,3)\n    rownames(Emat) <- paste0('Ed_sigma.',c(.001, .25, 1))\n    colnames(Emat) <- paste0('Es_sigma.',c(.001, .25, 1))\n    return( round(Emat,2))\n})\n```\n:::\n\n</details>\nTo overcome this issue, we can compute the change in the expected values $d \\mathbb{E}[Q^{*}] / d \\mathbb{E}[P^{*}] =-B_{D}$. Empirically, this is estimated via the change in average value.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wald (1940) Estimate\ndat_mean <- rbind(\n    colMeans(dat2[dat2$cost==1,1:2]),\n    colMeans(dat2[dat2$cost==2,1:2]))\ndat_mean\n##             P         Q\n## [1,] 8.886667 0.8732294\n## [2,] 8.045767 1.5426921\nB_est <- diff(dat_mean[,2])/diff(dat_mean[,1])\nround(B_est, 2)\n## [1] -0.8\n```\n:::\n\n\n\n\n\n\nWe can also separately recover $d \\mathbb{E}[Q^{*}] / d \\mathbb{E}[A_{S}]$ and $d \\mathbb{E}[P^{*}] / d \\mathbb{E}[A_{S}]$ from separate regressions.^[Mathematically, we can also do this in a single step by exploiting linear algebra: $\\frac{\\frac{ Cov(Q^{*},A_{S})}{ V(A_{S}) } }{\\frac{ Cov(P^{*},A_{S})}{ V(A_{S}) }} = \\frac{Cov(Q^{*},A_{S} )}{ Cov(P^{*},A_{S})}.$]\n\n::: {.cell}\n\n```{.r .cell-code}\n# Heckman (2000, p.58) Estimate\nols_1 <- lm(P~cost, data=dat2)\nols_2 <- lm(Q~cost, data=dat2)\nB_est2 <- coef(ols_2)/coef(ols_1)\nround(B_est2[[2]],2)\n## [1] -0.8\n```\n:::\n\nAlternatively, we can recover the same estimate using an 2SLS regression with two equations:\n\\begin{eqnarray}\nP &=& \\alpha_{1} + A_{S} \\beta_{1} + \\epsilon_{1} \\\\\nQ &=& \\alpha_{2} + \\hat{P} \\beta_{2} + \\epsilon_{2}.\n\\end{eqnarray}\nIn the first regression, we estimate the average effect of the cost shock on prices. In the second equation, we estimate how the average effect of prices *which are exogenous to demand* affect quantity demanded. To see this, first substitute the equilibrium condition into the supply equation: $Q_{D}=Q_{S}=A_{S}+B_{S} P + E_{S}$, lets us rewrite $P$ as a function of $Q_{D}$. This yields two theoretical equations\n\\begin{eqnarray}\n\\label{eqn:linear_supply_iv}\nP &=& -\\frac{A_{S}}{{B_{S}}} + \\frac{Q_{D}}{B_{S}} - \\frac{E_{S}}{B_{S}} \\\\\n\\label{eqn:linear_demand_iv}\nQ_{D} &=&  A_{D} + B_{D} P  + E_{D}.\n\\end{eqnarray}\n\n::: {.cell}\n\n```{.r .cell-code}\n# Two Stage Least Squares Estimate\nols_1 <- lm(P~cost, data=dat2)\ndat2_new  <- cbind(dat2, Phat=predict(ols_1))\nreg_2sls <- lm(Q~Phat, data=dat2_new)\nsummary(reg_2sls)\n## \n## Call:\n## lm(formula = Q ~ Phat, data = dat2_new)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.46168 -0.11623 -0.00432  0.11137  0.55247 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  7.94814    0.14352   55.38   <2e-16 ***\n## Phat        -0.79613    0.01693  -47.02   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1744 on 598 degrees of freedom\n## Multiple R-squared:  0.7871,\tAdjusted R-squared:  0.7868 \n## F-statistic:  2211 on 1 and 598 DF,  p-value: < 2.2e-16\n\n# One Stage Instrumental Variables Estimate\nlibrary(fixest)\nreg2_iv <- feols(Q~1|P~cost, data=dat2)\nsummary(reg2_iv)\n## TSLS estimation - Dep. Var.: Q\n##                   Endo.    : P\n##                   Instr.   : cost\n## Second stage: Dep. Var.: Q\n## Observations: 600\n## Standard-errors: IID \n##              Estimate Std. Error  t value  Pr(>|t|)    \n## (Intercept)  7.948139   0.196867  40.3732 < 2.2e-16 ***\n## fit_P       -0.796126   0.023225 -34.2795 < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## RMSE: 0.238788   Adj. R2: 0.78676\n## F-test (1st stage), P: stat = 3,068.43, p < 2.2e-16, on 1 and 598 DoF.\n##            Wu-Hausman: stat =   449.01, p < 2.2e-16, on 1 and 597 DoF.\n```\n:::\n\n\n\n#### **Caveats**. {-}\n2SLS regression analysis can be very insightful, but I also want to stress some caveats about their practical application.\n\nWe always get coefficients back when running `feols`, and sometimes the computed p-values are very small. The interpretation of those numbers rests on many assumptions:\n\n* *Instrument exogeneity (Exclusion Restriction):* The instrument must affect outcomes only through the treatment variable (e.g., only supply is affected directly, not demand).\n* *Instrument relevance:* The instrument must be strongly correlated with the endogenous regressor, implying the shock creates meaningful variation.\n* *Functional form correctness:* Supply and demand are assumed linear and additively separable.\n* *Multiple hypothesis testing risks:* We were not repeatedly testing different instruments, which can artificially produce significant findings by chance.\n\nWe are rarely sure that all of these assumptions hold, and this is one reason why researchers often also report their OLS results. But that is insufficient, as spatial and temporal dependence also complicate inference:\n\n* *Exclusion restriction violations:* Spatial or temporal spillovers may cause instruments to affect the outcome through unintended channels, undermining instrument exogeneity.\n* *Weak instruments:* Spatial clustering, serial correlation, or network interdependencies can reduce instrument variation, causing weak instruments.\n* *Inference and standard errors:* Spatial or temporal interdependence reduces the effective sample size, making conventional standard errors misleadingly small.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Further Reading\n\n\nYou are directed to the following resources which discusses endogeneity in more detail and how it applies generally.\n\n* Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction\n* <https://www.mostlyharmlesseconometrics.com/>\n* <https://www.econometrics-with-r.org>\n* <https://bookdown.org/paul/applied-causal-analysis/>\n* <https://mixtape.scunning.com/>\n* <https://theeffectbook.net/>\n* <https://www.r-causal.org/>\n* <https://matheusfacure.github.io/python-causality-handbook/landing-page.html>\n\nFor RDD and DID methods in natural experiments, see\n\n* <https://bookdown.org/paul/applied-causal-analysis/rdd-regression-discontinuity-design.html>\n* <https://mixtape.scunning.com/06-regression_discontinuity>\n* <https://theeffectbook.net/ch-RegressionDiscontinuity.html>\n* <https://mixtape.scunning.com/09-difference_in_differences>\n* <https://theeffectbook.net/ch-DifferenceinDifference.html>\n* <http://www.urfie.net/read/index.html#page/226>\n    \n\nFor IV methods in natural experiments, see\n\n* <https://cameron.econ.ucdavis.edu/e240a/ch04iv.pdf>\n* <https://mru.org/courses/mastering-econometrics/introduction-instrumental-variables-part-one>\n* <https://www.econometrics-with-r.org/12-ivr.html>\n* <https://bookdown.org/paul/applied-causal-analysis/estimation-2.html>\n* <https://mixtape.scunning.com/07-instrumental_variables>\n* <https://theeffectbook.net/ch-InstrumentalVariables.html>\n* <http://www.urfie.net/read/index.html#page/247>\n\n\n",
    "supporting": [
      "03_04_ExperimentalData_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}