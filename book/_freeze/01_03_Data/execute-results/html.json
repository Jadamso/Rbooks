{
  "hash": "010615cc892f3c93ab61d673b50b0854",
  "result": {
    "engine": "knitr",
    "markdown": "# Data\n***\n\n## Types\n\n#### **Basic Types**. {-}\nThe two basic types of data are *cardinal* (aka numeric) data and *factor* data. We can further distinguish between whether cardinal data are discrete or continuous. We can also further distinguish between whether factor data are ordered or not\n\n* *Cardinal (Numeric)*: the difference between elements always means the same thing. \n    * Discrete: E.g., $2-1=3-2$.\n    * Continuous: E.g., $2.9-1.4348=3.9-2.4348$\n* *Factor*: the difference between elements does not always mean the same thing.\n    * Ordered: E.g., First place - Second place ?? Second place - Third place.\n    * Unordered (categorical): E.g., A - B ????\n\n\nHere are some examples\n\n::: {.cell}\n\n```{.r .cell-code}\nd1d <- 1:3 # Cardinal data (Discrete)\nd1d\n## [1] 1 2 3\n\nd1c <- c(1.1, 2/3, 3) # Cardinal data (Continuous)\nd1c\n## [1] 1.1000000 0.6666667 3.0000000\n\nd2o <- factor(c('A','B','C'), ordered=T) # Factor data (Ordinal)\nd2o\n## [1] A B C\n## Levels: A < B < C\n\nd2c <- factor(c('Leipzig','Los Angeles','Logan'), ordered=F) # Factor data (Categorical)\nd2c\n## [1] Leipzig     Los Angeles Logan      \n## Levels: Leipzig Logan Los Angeles\n\n# Explicitly check the data types:\n#class(d1d)\n#class(d1c)\n#class(d2o)\n#class(d2c)\n```\n:::\n\n\nNote that for theoretical analysis, the types are sometimes grouped differently as\n\n* continuous (continuous cardinal data)\n* discrete (discrete cardinal, ordered factor, and unordered factor data)\n\nIn any case, these data are often analyzed in data.frame objects\n\n::: {.cell}\n\n```{.r .cell-code}\n# data.frames: your most common data type\n    # matrix of different data-types\n    # well-ordered lists\nd0 <- data.frame(y=d1c, x=d2c)\nd0\n##           y           x\n## 1 1.1000000     Leipzig\n## 2 0.6666667 Los Angeles\n## 3 3.0000000       Logan\n```\n:::\n\n\n#### **Strings**. {-} \nNote that R allows for unstructured plain text, called *strings*, which we can then format as factors\n\n::: {.cell}\n\n```{.r .cell-code}\nc('A','B','C')  # character strings\n## [1] \"A\" \"B\" \"C\"\nc('Leipzig','Los Angeles','Logan')  # character strings\n## [1] \"Leipzig\"     \"Los Angeles\" \"Logan\"\n```\n:::\n\nAlso note that strings are encounter in a variety of settings, and you often have to format them after reading them into R.^[We will not cover the statistical analysis of text in this course, but strings are amenable to statistical analysis.]\n\n::: {.cell}\n\n```{.r .cell-code}\n# Strings\npaste( 'hi', 'mom')\n## [1] \"hi mom\"\npaste( c('hi', 'mom'), collapse='--')\n## [1] \"hi--mom\"\n\nkingText <- \"The king infringes the law on playing curling.\"\ngsub(pattern=\"ing\", replacement=\"\", kingText)\n## [1] \"The k infres the law on play curl.\"\n# advanced usage\n#gsub(\"[aeiouy]\", \"_\", kingText)\n#gsub(\"([[:alpha:]]{3})ing\\\\b\", \"\\\\1\", kingText) \n```\n:::\n\nSee \n\n* <https://meek-parfait-60672c.netlify.app/docs/M1_R-intro_03_text.html>\n* <https://raw.githubusercontent.com/rstudio/cheatsheets/main/regex.pdf>\n\n\n\n\n## Densities and Distributions\n\n#### **Initial Data Inspection**. {-}\nRegardless of the data types you have, you typically begin by inspecting your data by examining the first few observations.\n \nConsider, for example, historical data on crime in the US.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(USArrests)\n##            Murder Assault UrbanPop Rape\n## Alabama      13.2     236       58 21.2\n## Alaska       10.0     263       48 44.5\n## Arizona       8.1     294       80 31.0\n## Arkansas      8.8     190       50 19.5\n## California    9.0     276       91 40.6\n## Colorado      7.9     204       78 38.7\n\n# Check NA values\nx <- c(1,NA,2,3)\nsum(is.na(x))\n## [1] 1\n```\n:::\n\n\nTo further examine a particular variable, we look at its distribution. In what follows, we will often work with data as vector $X=(X_{1}, X_{2}, ....X_{N})$, where there are $N$ observations and $X_{i}$ is the value of the $i$th one.\n\n\n\n\n#### **Histogram Density Estimate**. {-}\nThe histogram divides the range of the data, $X$, into $L$ exclusive bins of equal-width $h$, and count the number of observations within each bin. We often rescale the counts so that the total area of all bins sums to one, which allows us to interpret the numbers as a *density estimate*. Mathematically, for an exclusive bin $\\left[x-\\frac{h}{2}, x+\\frac{h}{2} \\right)$ defined by their midpoint $x$ and width $h$, we compute\n\\begin{eqnarray}\n\\widehat{f}_{HIST}(x) &=& \\frac{  \\sum_{i}^{N} \\mathbf{1}\\left( X_{i} \\in \\left[x-\\frac{h}{2}, x+\\frac{h}{2} \\right) \\right) }{N h}.\n\\end{eqnarray}\nNote that $\\mathbf{1}$ is an indicator function, which equals $1$ if the expression inside is `TRUE` and $0$ otherwise. \nWe compute $\\widehat{f}_{HIST}(x)$ for each bin midpoint $x$.^[If the bins exactly span the range, then $h=[\\text{max}(X_{i}) - \\text{min}(X_{i})]/L$ and $x\\in \\left\\{ \\frac{\\ell h}{2} + \\text{min}(X_{i}) \\right\\}_{\\ell=1}^{L}$.]\n\nFor example, let $X=(3,3.1,0.02)$ and use bins $[0,1), [1,2), [2,3), [3,4)$. In this case, the midpoints are $x=(0.5,1.5,2.5,3.5)$ and $h=1$. Then the counts at each midpoints are $(1,0,0,2)$. Since $\\frac{1}{Nh}=1/3$, we also have $\\widehat{f}(x)=(1/3,0,0,2/3)$. Now intuitively work through an example with three bins instead of four.\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- c(3,3.1,0.02)\nhist(X, breaks=c(0,1,2,3,4), right=F, plot=F)\n# as a default, R uses bins (,] instead of [,)\n\nhist(X, breaks=c(0,4/3,8/3,4), right=F, plot=F)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(USArrests$Murder, freq=F, breaks=10,\n    border=NA, main='', xlab='Murder Arrests')\n# Raw Observations\nrug(USArrests$Murder, col=grey(0,.5))\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nNote that if you your data are factor data, or discrete cardinal data, you can directly plot the counts or proportions: for each unique outcome $k$ we compute $\\widehat{p}_{k}=\\sum_{i=1}^{N}\\mathbf{1}\\left(X_{i}=k\\right)/N$.\n\n::: {.cell}\n\n```{.r .cell-code}\nxr <- floor(USArrests$Murder) #Discretized data (rounded down)\nproportions <- table(xr)/length(xr)\nplot(proportions, xlab='Murder Rate (Discrete)', ylab='Proportions')\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n#### **Empirical *Cumulative* Distribution Function**. {-}\nThe ECDF counts the proportion of observations whose values $X_{i}$ are less than $x$; \n\\begin{eqnarray}\n\\widehat{F}_{ECDF}(x) = \\frac{1}{N} \\sum_{i}^{N} \\mathbf{1}(X_{i} \\leq x).\n\\end{eqnarray}\nTypically, we compute this for each unique value of $x$ in the dataset, but sometimes other values of $x$ too.\n\nFor example, let $X=(3,3.1,0.02)$ and consider the points $x=(0.5,1.5,2.5,3.5)$. Then the counts are $(1,1,1,3)$. Since $N=3$, $\\widehat{F}(x)=(1/3,1/3,1/3,1)$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nF_murder <- ecdf(USArrests$Murder)\n# proportion of murders <= 10\nF_murder(10)\n## [1] 0.7\n# proportion of murders <= x, for all x\nplot(F_murder, main='', xlab='Murder Arrests',\n    pch=16, col=grey(0,.5))\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n#### **Boxplots**. {-}\nBoxplots summarize the distribution of data using *quantiles*: the $q$th quantile is the value where $q$ percent of the data are below and ($1-q$) percent are above.\n\n* The *median* is the point where half of the data has lower values and the other half has higher values.\n* The *lower quartile* is the point where 25% of the data has lower values and the other 75% has higher values.\n* The *min* is the smallest value (or the most negative value if there are any), where 0% of the data has lower values.\n\nFor example, if $X=(0,0,0.02,3,5)$ then the median is $0.02$, the lower quartile is $0$, and the upper quartile is $3$. (The number 0 is also special: the most frequent observation is called the *mode*.) Now work through an intuitive example with 24 data points (hint: split the observations into groups of 6).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- USArrests$Murder\n\n# quantiles\nmedian(x)\n## [1] 7.25\nrange(x)\n## [1]  0.8 17.4\nquantile(x, probs=c(0,.25,.5))\n##    0%   25%   50% \n## 0.800 4.075 7.250\n\n# deciles are quantiles\nquantile(x, probs=seq(0,1, by=.1))\n##    0%   10%   20%   30%   40%   50%   60%   70%   80%   90%  100% \n##  0.80  2.56  3.38  4.75  6.00  7.25  8.62 10.12 12.12 13.32 17.40\n```\n:::\n\n\nTo actually calculate quantiles, we sort the observations from smallest to largest as $X_{(1)}, X_{(2)},... X_{(N)}$, and then compute quantiles as $X_{ (q*N) }$. Note that $(q*N)$ is rounded and there are different ways to break ties.\n\n::: {.cell}\n\n```{.r .cell-code}\nxo <- sort(x)\nxo\n##  [1]  0.8  2.1  2.1  2.2  2.2  2.6  2.6  2.7  3.2  3.3  3.4  3.8  4.0  4.3  4.4\n## [16]  4.9  5.3  5.7  5.9  6.0  6.0  6.3  6.6  6.8  7.2  7.3  7.4  7.9  8.1  8.5\n## [31]  8.8  9.0  9.0  9.7 10.0 10.4 11.1 11.3 11.4 12.1 12.2 12.7 13.0 13.2 13.2\n## [46] 14.4 15.4 15.4 16.1 17.4\n\n# median\nxo[length(xo)*.5]\n## [1] 7.2\nquantile(x, probs=.5, type=4)\n## 50% \n## 7.2\n\n# min\nxo[1]\n## [1] 0.8\nmin(xo)\n## [1] 0.8\nquantile(xo,probs=0)\n##  0% \n## 0.8\n```\n:::\n\n\nThe boxplot shows the median (solid black line) and interquartile range ($IQR=$ upper quartile $-$ lower quartile; filled box).^[Technically, the upper and lower *hinges* use two different versions of the first and third quartile. See <https://stackoverflow.com/questions/40634693/lower-and-upper-quartiles-in-boxplot-in-r>.] As a default, whiskers are shown as $1.5\\times IQR$ and values beyond that are highlighted as outliers---so whiskers do not typically show the data range. You can alternatively show all the raw data points instead of whisker+outliers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxplot(USArrests$Murder, main='', ylab='Murder Arrests',\n    whisklty=0, staplelty=0, outline=F)\n# Raw Observations\nstripchart(USArrests$Murder,\n    pch='-', col=grey(0,.5), cex=2,\n    vert=T, add=T)\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Joint Distributions\n\nScatterplots are used frequently to summarize the joint relationship between two variables. They can be enhanced in several ways. As a default, use semi-transparent points so as not to hide any points (and perhaps see if your observations are concentrated anywhere).\n\nYou can also add other features that help summarize the relationship, although I will defer this until later.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Murder~UrbanPop, USArrests, pch=16, col=grey(0.,.5))\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n#### **Marginal Distributions**.{-}\nYou can also show the distributions of each variable along each axis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Setup Plot\nlayout( matrix(c(2,0,1,3), ncol=2, byrow=TRUE),\n    widths=c(9/10,1/10), heights=c(1/10,9/10))\n\n# Scatterplot\npar(mar=c(4,4,1,1))\nplot(Murder~UrbanPop, USArrests, pch=16, col=rgb(0,0,0,.5))\n\n# Add Marginals\npar(mar=c(0,4,1,1))\nxhist <- hist(USArrests$UrbanPop, plot=FALSE)\nbarplot(xhist$counts, axes=FALSE, space=0, border=NA)\n\npar(mar=c(4,0,1,1))\nyhist <- hist(USArrests$Murder, plot=FALSE)\nbarplot(yhist$counts, axes=FALSE, space=0, horiz=TRUE, border=NA)\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n## Conditional Distributions\n\nWe can show how distributions and densities change according to a second (or even third) variable using data splits. E.g., \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tailored Histogram \nylim <- c(0,8)\nxbks <-  seq(min(USArrests$Murder)-1, max(USArrests$Murder)+1, by=1)\n\n# Also show more information\n# Split Data by Urban Population above/below mean\npop_mean <- mean(USArrests$UrbanPop)\nmurder_lowpop <- USArrests[USArrests$UrbanPop< pop_mean,'Murder']\nmurder_highpop <- USArrests[USArrests$UrbanPop>= pop_mean,'Murder']\ncols <- c(low=rgb(0,0,1,.75), high=rgb(1,0,0,.75))\n\npar(mfrow=c(1,2))\nhist(murder_lowpop,\n    breaks=xbks, col=cols[1],\n    main='Urban Pop >= Mean', font.main=1,\n    xlab='Murder Arrests',\n    border=NA, ylim=ylim)\n\nhist(murder_highpop,\n    breaks=xbks, col=cols[2],\n    main='Urban Pop < Mean', font.main=1,\n    xlab='Murder Arrests',\n    border=NA, ylim=ylim)\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nIt is sometimes it is preferable to show the ECDF instead. And you can glue various combinations together to convey more information all at once\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,2))\n# Full Sample Density\nhist(USArrests$Murder, \n    main='Density Function Estimate', font.main=1,\n    xlab='Murder Arrests',\n    breaks=xbks, freq=F, border=NA)\n\n# Split Sample Distribution Comparison\nF_lowpop <- ecdf(murder_lowpop)\nplot(F_lowpop, col=cols[1],\n    pch=16, xlab='Murder Arrests',\n    main='Distribution Function Estimates',\n    font.main=1, bty='n')\nF_highpop <- ecdf(murder_highpop)\nplot(F_highpop, add=T, col=cols[2], pch=16)\n\nlegend('bottomright', col=cols,\n    pch=16, bty='n', inset=c(0,.1),\n    title='% Urban Pop.',\n    legend=c('Low (<= Mean)','High (>= Mean)'))\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\nYou can also split data into grouped boxplots in the same way\n\n::: {.cell}\n\n```{.r .cell-code}\nlayout( t(c(1,2,2)))\nboxplot(USArrests$Murder, main='',\n    xlab='All Data', ylab='Murder Arrests')\n\n# K Groups with even spacing\nK <- 3\nUSArrests$UrbanPop_Kcut <- cut(USArrests$UrbanPop,K)\nKcols <- hcl.colors(K,alpha=.5)\nboxplot(Murder~UrbanPop_Kcut, USArrests,\n    main='', col=Kcols,\n    xlab='Urban Population', ylab='')\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\n\n# 4 Groups with equal numbers of observations\n#Qcuts <- c(\n#    '0%'=min(USArrests$UrbanPop)-10*.Machine$double.eps,\n#    quantile(USArrests$UrbanPop, probs=c(.25,.5,.75,1)))\n#USArrests$UrbanPop_cut <- cut(USArrests$UrbanPop, Qcuts)\n#boxplot(Murder~UrbanPop_cut, USArrests, col=hcl.colors(4,alpha=.5))\n```\n:::\n\n\nYou can also use size, color, and shape to further distinguish different conditional relationships.\n\n::: {.cell}\n\n```{.r .cell-code}\n# High Assault Areas\nassault_high <- USArrests$Assault > median(USArrests$Assault)\ncols <- ifelse(assault_high, rgb(1,0,0,.5), rgb(0,0,1,.5))\n\n# Scatterplot\n# Show High Assault Areas via 'cex=' or 'pch='\n# Could further add regression lines for each data split\nplot(Murder~UrbanPop, USArrests, pch=16, col=cols)\n```\n\n::: {.cell-output-display}\n![](01_03_Data_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n## Further Reading \n\nFor plotting histograms and marginal distributions, see \n\n* <https://www.r-bloggers.com/2011/06/example-8-41-scatterplot-with-marginal-histograms/>\n* <https://r-graph-gallery.com/histogram.html>\n* <https://r-graph-gallery.com/74-margin-and-oma-cheatsheet.html>\n* <https://jtr13.github.io/cc21fall2/tutorial-for-scatter-plot-with-marginal-distribution.html>\n\n",
    "supporting": [
      "01_03_Data_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}